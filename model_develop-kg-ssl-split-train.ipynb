{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e089b57-b508-49f7-bc17-59ede3c86ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jun/anaconda3/envs/hungvv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.init as init\n",
    "# from torch.nn.init import xavier_normal_, xavier_uniform_\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "from os.path import abspath\n",
    "import random\n",
    "import pandas as pd\n",
    "from util.sampler import  next_batch_pairwise\n",
    "from util.conf import OptionConf\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from scipy.sparse import coo_matrix\n",
    "from util.loss_torch import bpr_loss, l2_reg_loss, EmbLoss, contrastLoss, InfoNCE\n",
    "from util.init import *\n",
    "from base.torch_interface import TorchGraphInterface\n",
    "import os\n",
    "import numpy as np \n",
    "import time \n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from itertools import product\n",
    "import collections  \n",
    "from collections import defaultdict\n",
    "import scipy.sparse as sp\n",
    "from itertools import product\n",
    "\n",
    "from random import shuffle,randint,choice,sample\n",
    "import torch.nn.init as init \n",
    "import csv \n",
    "\n",
    "from util.conf import ModelConf\n",
    "from base.recommender import Recommender\n",
    "from util.algorithm import find_k_largest\n",
    "from time import strftime, localtime\n",
    "from data.loader import FileIO\n",
    "from util.evaluation import ranking_evaluation\n",
    "\n",
    "from data.ui_graph import Interaction\n",
    "from data.augmentor import GraphAugmentor\n",
    "from util.evaluation import early_stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4365d976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac47b4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb0f97",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Base Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc5eef39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GraphRecommender(Recommender):\n",
    "    def __init__(self, conf, data, data_kg,knowledge_set, **kwargs):\n",
    "        super(GraphRecommender, self).__init__(conf, data, data_kg, knowledge_set,**kwargs)\n",
    "        self.data = data\n",
    "        self.data_kg = data_kg \n",
    "        self.bestPerformance = []\n",
    "        top = self.ranking['-topN'].split(',')\n",
    "        self.topN = [int(num) for num in top]\n",
    "        self.max_N = max(self.topN)\n",
    "        \n",
    "        self.dataset = kwargs['dataset']\n",
    "        \n",
    "        # self.output = f\"./results/{self.model_name}/{self.dataset}/@{self.model_name}-inp_emb:{kwargs['input_dim']}-hyper_emb:{kwargs['hyper_dim']}-bs:{self.batch_size}-lr:{kwargs['lr']}-lrd:{kwargs['lr_decay']}-reg:{kwargs['reg']}-leaky:{kwargs['p']}-dropout:{kwargs['drop_rate']}-n_layers:{kwargs['n_layers']}-n_heads:{kwargs['n_heads']}-n_self_att:{kwargs['n_self_att']}/\"\n",
    "        self.output = f\"./results/HGNN_KG_SSL/{self.dataset}/@{self.model_name}-inp_emb:{kwargs['input_dim']}-hyper_emb:{kwargs['hyper_dim']}-bs:{self.batch_size}-lr:{kwargs['lr']}-lrd:{kwargs['lr_decay']}-reg:{kwargs['reg']}-leaky:{kwargs['p']}-dropout:{kwargs['drop_rate']}-n_layers:{kwargs['n_layers']}-cl_rate:{kwargs['cl_rate']}-aug_type:{kwargs['aug_type']}-temp:{kwargs['temp']}/\"\n",
    "        if not os.path.exists(self.output):\n",
    "            os.makedirs(self.output)\n",
    "\n",
    "    def print_model_info(self):\n",
    "        super(GraphRecommender, self).print_model_info()\n",
    "        # # print dataset statistics\n",
    "        print('Training Set Size: (user number: %d, item number %d, interaction number: %d)' % (self.data.training_size()))\n",
    "        print('Test Set Size: (user number: %d, item number %d, interaction number: %d)' % (self.data.test_size()))\n",
    "        print('=' * 80)\n",
    "\n",
    "    def build(self):\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self, u):\n",
    "        pass\n",
    "\n",
    "    def test(self, user_emb, item_emb):\n",
    "        def process_bar(num, total):\n",
    "            rate = float(num) / total\n",
    "            ratenum = int(50 * rate)\n",
    "            r = '\\rProgress: [{}{}]{}%'.format('+' * ratenum, ' ' * (50 - ratenum), ratenum*2)\n",
    "            sys.stdout.write(r)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # predict\n",
    "        rec_list = {}\n",
    "        user_count = len(self.data.test_set)\n",
    "        for i, user in enumerate(self.data.test_set):\n",
    "            # s_find_candidates = time.time()\n",
    "            \n",
    "            # candidates = predict(user)\n",
    "            user_id  = self.data.get_user_id(user)\n",
    "            score = torch.matmul(user_emb[user_id], item_emb.transpose(0, 1))\n",
    "            candidates = score.cpu().numpy()\n",
    "            \n",
    "            # e_find_candidates = time.time()\n",
    "            # print(\"Calculate candidates time: %f s\" % (e_find_candidates - s_find_candidates))\n",
    "            # predictedItems = denormalize(predictedItems, self.data.rScale[-1], self.data.rScale[0])\n",
    "            rated_list, li = self.data.user_rated(user)\n",
    "            for item in rated_list:\n",
    "                candidates[self.data.item[item]] = -10e8\n",
    "            \n",
    "            # s_find_k_largest = time.time()\n",
    "            ids, scores = find_k_largest(self.max_N, candidates)\n",
    "            # e_find_k_largest = time.time()\n",
    "            # print(\"Find k largest candidates: %f s\" % (e_find_k_largest - s_find_k_largest))\n",
    "            item_names = [self.data.id2item[iid] for iid in ids]\n",
    "            rec_list[user] = list(zip(item_names, scores))\n",
    "            if i % 1000 == 0:\n",
    "                process_bar(i, user_count)\n",
    "        process_bar(user_count, user_count)\n",
    "        print('')\n",
    "        return rec_list\n",
    "\n",
    "    def evaluate(self, rec_list):\n",
    "        self.recOutput.append('userId: recommendations in (itemId, ranking score) pairs, * means the item is hit.\\n')\n",
    "        for user in self.data.test_set:\n",
    "            line = str(user) + ':'\n",
    "            for item in rec_list[user]:\n",
    "                line += ' (' + str(item[0]) + ',' + str(item[1]) + ')'\n",
    "                if item[0] in self.data.test_set[user]:\n",
    "                    line += '*'\n",
    "            line += '\\n'\n",
    "            self.recOutput.append(line)\n",
    "        current_time = strftime(\"%Y-%m-%d %H-%M-%S\", localtime(time.time()))\n",
    "        # output prediction result\n",
    "        out_dir = self.output\n",
    "        file_name = self.config['model.name'] + '@' + current_time + '-top-' + str(self.max_N) + 'items' + '.txt'\n",
    "        FileIO.write_file(out_dir, file_name, self.recOutput)\n",
    "        print('The result has been output to ', abspath(out_dir), '.')\n",
    "        file_name = self.config['model.name'] + '@' + current_time + '-performance' + '.txt'\n",
    "        self.result = ranking_evaluation(self.data.test_set, rec_list, self.topN)\n",
    "        self.model_log.add('###Evaluation Results###')\n",
    "        self.model_log.add(self.result)\n",
    "        FileIO.write_file(out_dir, file_name, self.result)\n",
    "        print('The result of %s:\\n%s' % (self.model_name, ''.join(self.result)))\n",
    "\n",
    "    def fast_evaluation(self, epoch, model_cf, model_kg, user_embed, item_embed, kwargs=None):\n",
    "        print('Evaluating the model...')\n",
    "        s_test = time.time()\n",
    "        rec_list = self.test(user_embed, item_embed)\n",
    "        e_test = time.time() \n",
    "        print(\"Test time: %f s\" % (e_test - s_test))\n",
    "        \n",
    "        s_measure = time.time()\n",
    "        measure = ranking_evaluation(self.data.test_set, rec_list, [self.max_N])\n",
    "        e_measure = time.time()\n",
    "        print(\"Measure time: %f s\" % (e_measure - s_measure))\n",
    "        \n",
    "        if len(self.bestPerformance) > 0:\n",
    "            count = 0\n",
    "            performance = {}\n",
    "            for m in measure[1:]:\n",
    "                k, v = m.strip().split(':')\n",
    "                performance[k] = float(v)\n",
    "            for k in self.bestPerformance[1]:\n",
    "                if self.bestPerformance[1][k] > performance[k]:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    count -= 1\n",
    "            if count < 0:\n",
    "                self.bestPerformance[1] = performance\n",
    "                self.bestPerformance[0] = epoch + 1\n",
    "                # try:\n",
    "                #     self.save(kwargs)\n",
    "                # except:\n",
    "                self.save(model_cf, model_kg, user_embed, item_embed)\n",
    "        else:\n",
    "            self.bestPerformance.append(epoch + 1)\n",
    "            performance = {}\n",
    "            for m in measure[1:]:\n",
    "                k, v = m.strip().split(':')\n",
    "                performance[k] = float(v)\n",
    "            self.bestPerformance.append(performance)\n",
    "            # try:\n",
    "            #     self.save(kwargs)\n",
    "            # except:\n",
    "            self.save(model_cf, model_kg, user_embed, item_embed)\n",
    "        print('-' * 120)\n",
    "        print('Real-Time Ranking Performance ' + ' (Top-' + str(self.max_N) + ' Item Recommendation)')\n",
    "        measure = [m.strip() for m in measure[1:]]\n",
    "        print('*Current Performance*')\n",
    "        print('Epoch:', str(epoch + 1) + ',', '  |  '.join(measure))\n",
    "        bp = ''\n",
    "        # for k in self.bestPerformance[1]:\n",
    "        #     bp+=k+':'+str(self.bestPerformance[1][k])+' | '\n",
    "        bp += 'Hit Ratio' + ':' + str(self.bestPerformance[1]['Hit Ratio']) + '  |  '\n",
    "        bp += 'Precision' + ':' + str(self.bestPerformance[1]['Precision']) + '  |  '\n",
    "        bp += 'Recall' + ':' + str(self.bestPerformance[1]['Recall']) + '  |  '\n",
    "        # bp += 'F1' + ':' + str(self.bestPerformance[1]['F1']) + ' | '\n",
    "        bp += 'NDCG' + ':' + str(self.bestPerformance[1]['NDCG'])\n",
    "        print('*Best Performance* ')\n",
    "        print('Epoch:fast_evaluation', str(self.bestPerformance[0]) + ',', bp)\n",
    "        print('-' * 120)\n",
    "        return measure\n",
    "    \n",
    "    def save(self, model_cf, model_kg, best_user_emb, best_item_emb):\n",
    "        self.best_user_emb, self.best_item_emb = best_user_emb, best_item_emb\n",
    "        self.save_model(model_cf, mode='cf')\n",
    "        self.save_model(model_kg, mode='kg')\n",
    "    \n",
    "    def save_model(self, model, mode='cf'):\n",
    "        # save model \n",
    "        current_time = strftime(\"%Y-%m-%d\", localtime(time.time()))\n",
    "        out_dir = self.output\n",
    "        file_name =  self.config['model.name']  + '@' + current_time + '-weight' + f\"-{mode}\"+ '.pth'\n",
    "        weight_file = out_dir + '/' + file_name \n",
    "        torch.save(model.state_dict(), weight_file)\n",
    "        \n",
    "    def save_performance_row(self, ep, data_ep):\n",
    "        # opening the csv file in 'w' mode\n",
    "        csv_path = self.output + 'train_performance.csv'\n",
    "        \n",
    "        # 'Hit Ratio:0.00328', 'Precision:0.00202', 'Recall:0.00337', 'NDCG:0.00292\n",
    "        hit = float(data_ep[0].split(':')[1])\n",
    "        precision = float(data_ep[1].split(':')[1])\n",
    "        recall = float(data_ep[2].split(':')[1])\n",
    "        ndcg = float(data_ep[3].split(':')[1])\n",
    "        \n",
    "        with open(csv_path, 'a+', newline = '') as f:\n",
    "            header = ['ep', 'hit@20', 'prec@20', 'recall@20', 'ndcg@20']\n",
    "            writer = csv.DictWriter(f, fieldnames = header)\n",
    "            # writer.writeheader()\n",
    "            writer.writerow({\n",
    "                 'ep' : ep,\n",
    "                 'hit@20': hit,\n",
    "                 'prec@20': precision,\n",
    "                 'recall@20': recall,\n",
    "                 'ndcg@20': ndcg,\n",
    "            })\n",
    "            \n",
    "    def save_loss_row(self, data_ep):\n",
    "        csv_path = self.output + 'loss.csv'\n",
    "        with open(csv_path, 'a+', newline ='') as f:\n",
    "            header = ['ep', 'train_loss', 'cf_loss', 'kg_loss']\n",
    "            writer = csv.DictWriter(f, fieldnames = header)\n",
    "            # writer.writeheader()\n",
    "            writer.writerow({\n",
    "                'ep' : data_ep[0],\n",
    "                'train_loss': data_ep[1],\n",
    "                 'cf_loss': data_ep[2],\n",
    "                 'kg_loss': data_ep[3]\n",
    "            })\n",
    "\n",
    "    def save_loss(self, train_losses, cf_losses, kg_losses):\n",
    "        df_train_loss = pd.DataFrame(train_losses, columns = ['ep', 'loss'])\n",
    "        df_cf_loss = pd.DataFrame(cf_losses, columns = ['ep', 'loss'])\n",
    "        df_kg_loss = pd.DataFrame(kg_losses, columns = ['ep', 'loss'])\n",
    "        df_train_loss.to_csv(self.output + '/train_loss.csv')\n",
    "        df_cf_loss.to_csv(self.output + '/cf_loss.csv')\n",
    "        df_kg_loss.to_csv(self.output + '/kg_loss.csv')\n",
    "\n",
    "    def save_perfomance_training(self, log_train):\n",
    "        df_train_log = pd.DataFrame(log_train)\n",
    "        df_train_log.to_csv(self.output + '/train_performance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0309f1f-83fb-4f60-9fd9-354fb3d904df",
   "metadata": {},
   "source": [
    "## Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab5a623-26f5-43c8-9b74-d6b56c008ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Knowledge(Interaction):\n",
    "    def __init__(self, conf, training, test, knowledge):\n",
    "        super().__init__(conf, training, test)\n",
    "        self.conf = conf \n",
    "        self.kg_data = knowledge\n",
    "\n",
    "        self.entity = {}\n",
    "        self.id2ent = {}\n",
    "\n",
    "        self.userent = {}\n",
    "        self.itement = {}\n",
    "        \n",
    "        self.u2id = {}\n",
    "        self.id2u = {}\n",
    "        \n",
    "        self.i2id = {}\n",
    "        self.id2i = {}\n",
    "        \n",
    "        self.relation = {}\n",
    "        self.id2rel = {}\n",
    "\n",
    "        self.cf_train_data = np.array(training)\n",
    "        self.training_set_e = defaultdict(dict)\n",
    "\n",
    "        self.construct_data()\n",
    "        \n",
    "        self.laplacian_type = 'random-walk'\n",
    "        self.create_adjacency_dict()\n",
    "        self.create_laplacian_dict()\n",
    "        \n",
    "        self.kg_interaction_mat = self.__create_sparse_knowledge_interaction_matrix()\n",
    "        self.interaction_mat = self.__create_sparse_interaction_matrix()\n",
    "        \n",
    "        \n",
    "    def construct_data(self):\n",
    "        kg_data = self.kg_data\n",
    "        n_relations = max(kg_data['r']) + 1\n",
    "        inverse_kg_data = kg_data.copy()\n",
    "        inverse_kg_data = inverse_kg_data.rename({'h': 't', 't': 'h'}, axis='columns')\n",
    "        inverse_kg_data['r'] += n_relations\n",
    "\n",
    "        kg_data = pd.concat([kg_data, inverse_kg_data], axis=0, ignore_index=True, sort=False)\n",
    "\n",
    "        # remap user_id \n",
    "        kg_data['r'] += 2\n",
    "        \n",
    "        kg_train_data = pd.concat([kg_data, inverse_kg_data], axis=0, ignore_index=True, sort=False)\n",
    "        self.n_entities = max(max(kg_train_data['h']), max(kg_train_data['t'])) + 1\n",
    "        self.n_relations = max(kg_train_data['r']) + 1\n",
    "\n",
    "        # add interactions to kg data\n",
    "        cf2kg_train_data = pd.DataFrame(np.zeros((self.n_cf_train, 3), dtype=np.int32), columns=['h', 'r', 't'])\n",
    "        cf2kg_train_data['h'] = self.cf_train_data[:,0]\n",
    "        cf2kg_train_data['t'] = self.cf_train_data[:,1]\n",
    "\n",
    "        inverse_cf2kg_train_data = pd.DataFrame(np.ones((self.n_cf_train, 3), dtype=np.int32), columns=['h', 'r', 't'])\n",
    "        inverse_cf2kg_train_data['h'] = self.cf_train_data[:,1]\n",
    "        inverse_cf2kg_train_data['t'] = self.cf_train_data[:,0]\n",
    "\n",
    "        self.kg_train_data = pd.concat([kg_train_data, cf2kg_train_data, inverse_cf2kg_train_data], ignore_index=True)\n",
    "        self.n_kg_train = len(self.kg_train_data)\n",
    "\n",
    "        self.n_users_entities = int(max(max(self.kg_train_data['h']), max(self.kg_train_data['t'])) + 1)\n",
    "\n",
    "        # construct kg dict\n",
    "        h_list = []\n",
    "        t_list = []\n",
    "        r_list = []\n",
    "\n",
    "        self.train_kg_dict = collections.defaultdict(list)\n",
    "        self.train_relation_dict = collections.defaultdict(list)\n",
    "\n",
    "        for idx, row in self.kg_train_data.iterrows():\n",
    "            h, r, t = int(row['h']), int(row['r']), int(row['t'])\n",
    "            h_list.append(h)\n",
    "            t_list.append(t)\n",
    "            r_list.append(r)\n",
    "\n",
    "            if h not in self.entity:\n",
    "                self.entity[h] = len(self.entity)\n",
    "                self.id2ent[self.entity[h]] = h\n",
    "                # check h co phai user hay item k\n",
    "                if h in self.user:\n",
    "                    self.userent[h] = len(self.userent)\n",
    "                #     # self.id2userent[self.userent[h]] = h\n",
    "                if h in self.item:\n",
    "                    self.itement[h] = len(self.itement)\n",
    "                #     # self.id2itement[self.itement[h]] = h\n",
    "\n",
    "            if t not in self.entity:\n",
    "                self.entity[t] = len(self.entity)\n",
    "                self.id2ent[self.entity[t]] = t \n",
    "                # check h co phai user hay item k \n",
    "                if t in self.user:\n",
    "                    self.userent[t] = len(self.userent)\n",
    "                #     # self.id2userent[self.userent[t]] = t\n",
    "                if t in self.item:\n",
    "                    self.itement[t] = len(self.itement)\n",
    "                #     # self.id2itement[self.itement[t]] = t\n",
    "            if r not in self.relation:\n",
    "                self.relation[r] = len(self.relation)\n",
    "                self.id2rel[self.relation[r]] = r \n",
    "            \n",
    "            self.training_set_e[t][h] = r\n",
    "            self.train_kg_dict[h].append((t, r))\n",
    "            self.train_relation_dict[r].append((h, t))\n",
    "        \n",
    "        self.h_list = torch.LongTensor(h_list).to(device)\n",
    "        self.t_list = torch.LongTensor(t_list).to(device)\n",
    "        self.r_list = torch.LongTensor(r_list).to(device)\n",
    "        \n",
    "        lst_user_entities = list(self.userent.keys())\n",
    "        lst_item_entities = list(self.itement.keys())\n",
    "\n",
    "        for idx, u in enumerate(lst_user_entities):\n",
    "            self.u2id[u] = idx\n",
    "            self.id2u[idx] = u\n",
    "        for idx, i in enumerate(lst_item_entities):\n",
    "            self.i2id[i] = idx\n",
    "            self.id2i[idx] = i\n",
    "        \n",
    "    def get_entity_id(self, e):\n",
    "        if e in self.entity:\n",
    "            return self.entity[e]\n",
    "    \n",
    "    def __create_sparse_knowledge_interaction_matrix(self):\n",
    "        \"\"\"\n",
    "            return a sparse adjacency matrix with the shape (entity number, entity number)\n",
    "        \"\"\"\n",
    "        row, col, entries = [], [], []\n",
    "        for idx, pair in self.kg_train_data.iterrows():\n",
    "            head, tail = int(pair['h']), int(pair['t'])\n",
    "            row += [head]\n",
    "            col += [tail]\n",
    "            entries += [1.0]\n",
    "        interaction_mat = sp.csr_matrix((entries, (row, col)), shape=(self.n_users_entities, self.n_users_entities),dtype=np.float32)\n",
    "        return interaction_mat\n",
    "    \n",
    "    def __create_sparse_interaction_matrix(self):\n",
    "        row, col, entries = [], [], []\n",
    "        for pair in self.training_data:\n",
    "            head, tail  = int(pair[0]), int(pair[1])\n",
    "            row += [head]\n",
    "            col += [tail]\n",
    "            entries += [1.0]\n",
    "        interaction_mat = sp.csr_matrix((entries, (row, col)), shape=(self.n_users_entities, self.n_users_entities),dtype=np.float32) \n",
    "        return interaction_mat\n",
    "    \n",
    "    def convert_coo2tensor(self, coo):\n",
    "        values = coo.data\n",
    "        indices = np.vstack((coo.row, coo.col))\n",
    "\n",
    "        i = torch.LongTensor(indices)\n",
    "        v = torch.FloatTensor(values)\n",
    "        shape = coo.shape\n",
    "        return torch.sparse.FloatTensor(i, v, torch.Size(shape))\n",
    "    \n",
    "    def create_adjacency_dict(self):\n",
    "        self.adjacency_dict = {}\n",
    "        for r, ht_list in self.train_relation_dict.items():\n",
    "            rows = [e[0] for e in ht_list]\n",
    "            cols = [e[1] for e in ht_list]\n",
    "            vals = [1] * len(rows)\n",
    "            adj = sp.coo_matrix((vals, (rows, cols)), shape=(self.n_users_entities, self.n_users_entities))\n",
    "            self.adjacency_dict[r] = adj\n",
    "    \n",
    "    def create_laplacian_dict(self):\n",
    "        def symmetric_norm_lap(adj):\n",
    "            rowsum = np.array(adj.sum(axis=1))\n",
    "\n",
    "            d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "            d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0\n",
    "            d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "\n",
    "            norm_adj = d_mat_inv_sqrt.dot(adj).dot(d_mat_inv_sqrt)\n",
    "            return norm_adj.tocoo()\n",
    "\n",
    "        def random_walk_norm_lap(adj):\n",
    "            rowsum = np.array(adj.sum(axis=1))\n",
    "\n",
    "            d_inv = np.power(rowsum, -1.0).flatten()\n",
    "            d_inv[np.isinf(d_inv)] = 0\n",
    "            d_mat_inv = sp.diags(d_inv)\n",
    "\n",
    "            norm_adj = d_mat_inv.dot(adj)\n",
    "            return norm_adj.tocoo()\n",
    "\n",
    "        if self.laplacian_type == 'symmetric':\n",
    "            norm_lap_func = symmetric_norm_lap\n",
    "        elif self.laplacian_type == 'random-walk':\n",
    "            norm_lap_func = random_walk_norm_lap\n",
    "        \n",
    "        self.laplacian_dict = {}\n",
    "        for r, adj in self.adjacency_dict.items():\n",
    "            self.laplacian_dict[r] = norm_lap_func(adj)\n",
    "\n",
    "        # A_in = sum(self.laplacian_dict.values())\n",
    "        # self.A_in = self.convert_coo2tensor(A_in.tocoo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af2ff4a-330e-49ba-a45b-dadb1c0994d2",
   "metadata": {},
   "source": [
    "## Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "619baa94-e2e5-4a1d-8e18-f4b9ccaa4e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch_kg(data_kg, batch_size, n_negs=1):\n",
    "    ptr = 0\n",
    "    kg_data = data_kg.kg_train_data.to_numpy()\n",
    "    kg_dict = data_kg.train_kg_dict\n",
    "\n",
    "    exist_heads= kg_dict.keys()\n",
    "    h_list = list(exist_heads)\n",
    "    h_dict = {value: idx for idx, value in enumerate(h_list)}\n",
    "    all_tails = list(set(kg_data[:,2]))\n",
    "    data_size = len(kg_data)\n",
    "    # Pre-compute positive tail sets and negative tails for each head\n",
    "    pos_tail_sets = {head: set([it[0] for it in tails]) for head, tails in kg_dict.items()}\n",
    "    # neg_tail_sets = {head: np.random.choice(list(all_tails - pos_tails), size=n_negs) for head, pos_tails in pos_tail_sets.items()}\n",
    "    \n",
    "    while ptr < data_size:\n",
    "        if ptr + batch_size < data_size:\n",
    "            batch_end = ptr + batch_size\n",
    "        else:   \n",
    "            batch_end = data_size\n",
    "        \n",
    "        heads, relations, tails = kg_data[ptr:batch_end, 0], kg_data[ptr:batch_end, 1], kg_data[ptr:batch_end, 2]\n",
    "        \n",
    "        ptr = batch_end\n",
    "        h_idx, r_idx, pos_t_idx, neg_t_idx = [], [], [], []\n",
    "        # time1 = datetime.datetime.now()\n",
    "        h_idx = [h_dict[head] for head in heads]\n",
    "        \n",
    "        r_idx.extend([int(rel) for rel in relations])\n",
    "        pos_t_idx.extend([int(tail) for tail in tails])\n",
    "        for head in heads:\n",
    "            neg_t = random.choice(all_tails)\n",
    "            while neg_t in pos_tail_sets[head]:\n",
    "                neg_t = random.choice(all_tails)\n",
    "            neg_t_idx.append(h_dict[neg_t])\n",
    "\n",
    "        h_idx  = torch.LongTensor(h_idx).to(device)\n",
    "        r_idx  = torch.LongTensor(r_idx).to(device)\n",
    "        pos_t_idx  = torch.LongTensor(pos_t_idx).to(device)\n",
    "        neg_t_idx  = torch.LongTensor(neg_t_idx).to(device)\n",
    "        yield h_idx, r_idx, pos_t_idx, neg_t_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12f1fa67-d774-470a-981d-d6b2664dbf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch_unified(data, data_kg, batch_size, batch_size_kg, n_negs=1):\n",
    "    ptr = 0\n",
    "\n",
    "    cf_data = data.training_data\n",
    "    cf_size = len(cf_data) \n",
    "    \n",
    "    shuffle(training_data)\n",
    "    \n",
    "    kg_data = data_kg.kg_train_data.to_numpy()\n",
    "    shuffle(kg_data)\n",
    "    \n",
    "    kg_dict = data_kg.train_kg_dict\n",
    "\n",
    "    exist_heads= kg_dict.keys()\n",
    "    h_list = list(exist_heads)\n",
    "    h_dict = {value: idx for idx, value in enumerate(h_list)}\n",
    "    all_tails = list(set(kg_data[:,2]))\n",
    "    data_size = len(kg_data)\n",
    "    # Pre-compute positive tail sets and negative tails for each head\n",
    "    pos_tail_sets = {head: set([it[0] for it in tails]) for head, tails in kg_dict.items()}\n",
    "    # neg_tail_sets = {head: np.random.choice(list(all_tails - pos_tails), size=n_negs) for head, pos_tails in pos_tail_sets.items()}\n",
    "    \n",
    "    while ptr < data_size:\n",
    "        if ptr + batch_size_kg < data_size:\n",
    "            batch_end = ptr + batch_size_kg\n",
    "        else:   \n",
    "            batch_end = data_size\n",
    "        \n",
    "        heads, relations, tails = kg_data[ptr:batch_end, 0], kg_data[ptr:batch_end, 1], kg_data[ptr:batch_end, 2]\n",
    "        \n",
    "        ptr = batch_end\n",
    "        h_idx, r_idx, pos_t_idx, neg_t_idx = [], [], [], []\n",
    "        # time1 = datetime.datetime.now()\n",
    "        h_idx = [h_dict[head] for head in heads]\n",
    "        \n",
    "        r_idx.extend([int(rel) for rel in relations])\n",
    "        pos_t_idx.extend([int(tail) for tail in tails])\n",
    "        for head in heads:\n",
    "            neg_t = random.choice(all_tails)\n",
    "            while neg_t in pos_tail_sets[head]:\n",
    "                neg_t = random.choice(all_tails)\n",
    "            neg_t_idx.append(h_dict[neg_t])\n",
    "\n",
    "        # select random items\n",
    "        selected_indices = np.random.choice(cf_size, batch_size)\n",
    "        users = [training_data[idx][0] for idx in selected_indices]\n",
    "        items = [training_data[idx][1] for idx in selected_indices]\n",
    "        \n",
    "        u_idx, i_idx, j_idx = [], [], []\n",
    "        item_list = list(data.item.keys())\n",
    "        for i, user in enumerate(users):\n",
    "            i_idx.append(data.item[items[i]])\n",
    "            u_idx.append(data.user[user])\n",
    "            for m in range(n_negs):\n",
    "                neg_item = choice(item_list)\n",
    "                while neg_item in data.training_set_u[user]:\n",
    "                    neg_item = choice(item_list)\n",
    "                j_idx.append(data.item[neg_item])\n",
    "\n",
    "        u_idx  = torch.LongTensor(u_idx).to(device)\n",
    "        i_idx  = torch.LongTensor(i_idx).to(device)\n",
    "        j_idx  = torch.LongTensor(j_idx).to(device)\n",
    "\n",
    "        h_idx  = torch.LongTensor(h_idx).to(device)\n",
    "        r_idx  = torch.LongTensor(r_idx).to(device)\n",
    "        neg_t_idx  = torch.LongTensor(neg_t_idx).to(device)\n",
    "        yield u_idx, i_idx, j_idx, h_idx, r_idx, pos_t_idx, neg_t_idx, users, items\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68fb744",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a6ac98-28d2-4f92-938d-6570eda82c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGNNConv(nn.Module):\n",
    "    def __init__(self, leaky, input_dim, hyper_dim, bias=False):\n",
    "        super(HGNNConv, self).__init__()\n",
    "        self.hyper_dim = hyper_dim\n",
    "        self.act = nn.LeakyReLU(negative_slope=leaky).to(device)\n",
    "        self.fc = nn.Linear(input_dim, hyper_dim ,bias=False).to(device) \n",
    "        \n",
    "        self.ln1 = torch.nn.LayerNorm(hyper_dim).to(device)\n",
    "        self.ln2 = torch.nn.LayerNorm(hyper_dim).to(device)\n",
    "        \n",
    "    def forward(self, adj, embeds):\n",
    "        lat1 = self.ln1(self.fc(torch.spmm(adj.t(), embeds)))\n",
    "        output = self.act((self.ln2(torch.spmm(adj, lat1))))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "250a38cc-ab38-4b32-beb9-8effd1168919",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(torch.nn.Module):\n",
    "    # This class module is a simple attention layer.\n",
    "    def __init__(self, in_size, hidden_size=128):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.project = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_size, hidden_size),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(hidden_size, hidden_size, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        w = self.project(z)  # (N, 2, D)\n",
    "        beta = torch.softmax(w, dim=1)  # (N, 2, D)\n",
    "        return (beta * z).sum(1), beta  # (N, D), (N, 2, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7280f55f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6346ae7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, config, data, data_kg, args):\n",
    "        super(Model, self).__init__()\n",
    "        self.data = data\n",
    "        adj = data.interaction_mat\n",
    "        self.data_kg = data_kg \n",
    "        kg_adj = data_kg.kg_interaction_mat\n",
    "        self.adj  = TorchGraphInterface.convert_sparse_mat_to_tensor(adj).to(device)\n",
    "        self.kg_adj = TorchGraphInterface.convert_sparse_mat_to_tensor(kg_adj).to(device)\n",
    "\n",
    "        self.user_indices =  torch.LongTensor(list(data.user.keys())).to(device)\n",
    "        self.item_indices = torch.LongTensor(list(data.item.keys())).to(device)\n",
    "        \n",
    "        self._parse_args(args)\n",
    "        self.embedding_dict = self._init_model()\n",
    "        \n",
    "        self.fc_u = nn.Linear(self.input_dim, self.hyper_dim)\n",
    "        self.fc_i = nn.Linear(self.input_dim, self.hyper_dim)\n",
    "        self.fc_e = nn.Linear(self.input_dim, self.hyper_dim)\n",
    "        \n",
    "        self.hgnn_u = [HGNNConv(leaky=self.p, input_dim=self.hyper_dim, hyper_dim=self.hyper_dim) for i in range(self.layers)]\n",
    "        self.hgnn_i = [HGNNConv(leaky=self.p, input_dim=self.hyper_dim, hyper_dim=self.hyper_dim) for i in range(self.layers) ] \n",
    "        self.hgnn_e = [HGNNConv(leaky=self.p, input_dim=self.hyper_dim, hyper_dim=self.hyper_dim) for i in range(self.layers) ] \n",
    "        \n",
    "        self.relation_emb =   nn.Parameter(init.xavier_uniform_(torch.empty(self.data_kg.n_relations, self.input_dim))).to(device)\n",
    "        self.trans_M = nn.Parameter(init.xavier_uniform_(torch.empty(self.data_kg.n_relations, self.hyper_dim, self.relation_dim))).to(device)\n",
    "\n",
    "        self.non_linear = nn.ReLU()\n",
    "        self.act = nn.LeakyReLU(self.p)\n",
    "        self.dropout = nn.Dropout(self.drop_rate)\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _parse_args(self, args):\n",
    "        self.input_dim = args['input_dim']\n",
    "        self.hyper_dim = args['hyper_dim']\n",
    "        self.p = args['p']\n",
    "        self.drop_rate = args['drop_rate'] \n",
    "        self.layers = args['n_layers']\n",
    "        self.temp = args['temp']\n",
    "        self.aug_type = args['aug_type']\n",
    "        self.relation_dim = args['relation_dim']\n",
    "        \n",
    "    def _init_model(self):\n",
    "        initializer = init.xavier_uniform_\n",
    "        embedding_dict = nn.ParameterDict({\n",
    "            'user_entity_emb': nn.Parameter(initializer(torch.empty(self.data_kg.n_users_entities, self.input_dim)).to(device)),\n",
    "            'entity_emb': nn.Parameter(initializer(torch.empty(self.data_kg.n_relations, self.input_dim)).to(device))\n",
    "        })\n",
    "        return embedding_dict\n",
    "    \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            init.normal_(m.weight, std=0.01)\n",
    "            if m.bias is not None:\n",
    "                init.zeros_(m.bias)\n",
    "\n",
    "    def graph_reconstruction(self):\n",
    "        if self.aug_type==0 or 1:\n",
    "            dropped_adj = self.random_graph_augment()\n",
    "        else:\n",
    "            dropped_adj = [], []\n",
    "            for k in range(self.n_layers):\n",
    "                dropped_adj = self.random_graph_augment()\n",
    "                dropped_adj.append(dropped_adj_)\n",
    "        return dropped_adj\n",
    "\n",
    "    def random_graph_augment(self):\n",
    "        dropped_mat = None\n",
    "        if self.aug_type == 0:\n",
    "            dropped_mat = GraphAugmentor.node_dropout(self.data.interaction_mat, self.drop_rate)\n",
    "        elif self.aug_type == 1 or self.aug_type == 2:\n",
    "            dropped_mat = GraphAugmentor.edge_dropout(self.data.interaction_mat, self.drop_rate)\n",
    "        return TorchGraphInterface.convert_sparse_mat_to_tensor(dropped_mat).to(device)\n",
    "\n",
    "    def calculate_cf_embeddings(self, perturbed_adj=None):\n",
    "        uEmbed = self.embedding_dict['user_entity_emb'][self.user_indices]\n",
    "        iEmbed = self.embedding_dict['user_entity_emb'][self.item_indices]\n",
    "        \n",
    "        uEmbed = self.dropout(self.act(self.fc_u(uEmbed)))\n",
    "        iEmbed = self.dropout(self.act(self.fc_i(iEmbed)))\n",
    "        \n",
    "        embeds = torch.cat([uEmbed, iEmbed], 0)\n",
    "        all_embeddings = [embeds]\n",
    "        \n",
    "        for k in range(self.layers):     \n",
    "            if perturbed_adj is not None:\n",
    "                if isinstance(perturbed_adj, list):\n",
    "                    hyperULat = self.hgnn_u[k](perturbed_adj[k], uEmbed)\n",
    "                    hyperILat = self.hgnn_i[k](perturbed_adj[k].t(), iEmbed)\n",
    "                else:\n",
    "                    hyperULat = self.hgnn_u[k](perturbed_adj, uEmbed)\n",
    "                    hyperILat = self.hgnn_i[k](perturbed_adj.t(), iEmbed)\n",
    "            else:\n",
    "                hyperULat = self.hgnn_u[k](self.adj, uEmbed)\n",
    "                hyperILat = self.hgnn_i[k](self.adj.t(), iEmbed)\n",
    "            \n",
    "            uEmbed += hyperULat\n",
    "            iEmbed += hyperILat\n",
    "            ego_embeddings = torch.cat([hyperULat, hyperILat], dim=0)\n",
    "            all_embeddings += [ego_embeddings]\n",
    "            \n",
    "        all_embeddings = torch.stack(all_embeddings, dim=1)\n",
    "        all_embeddings = torch.mean(all_embeddings, dim=1)\n",
    "        user_all_embeddings = all_embeddings[:self.data.n_users]\n",
    "        item_all_embeddings = all_embeddings[self.data.n_users:]\n",
    "        return user_all_embeddings, item_all_embeddings \n",
    "\n",
    "    def calculate_kg_embeddings(self, perturbed_adj=None):\n",
    "        eEmbed = self.embedding_dict['user_entity_emb']\n",
    "        eEmbed = self.dropout(self.act(self.fc_e(eEmbed)))\n",
    "        all_embeddings = [eEmbed]\n",
    "        for k in range(self.layers):     \n",
    "            if perturbed_adj is not None:\n",
    "                if isinstance(perturbed_adj, list):\n",
    "                    hyperELat = self.hgnn_e[k](perturbed_adj[k], eEmbed)\n",
    "                else:\n",
    "                    hyperELat = self.hgnn_e[k](perturbed_adj, eEmbed)\n",
    "            else:\n",
    "                hyperELat = self.hgnn_e[k](self.kg_adj, eEmbed)\n",
    "            eEmbed += hyperELat\n",
    "            all_embeddings += [eEmbed]\n",
    "        all_embeddings = torch.stack(all_embeddings, dim=1)\n",
    "        all_embeddings = torch.mean(all_embeddings, dim=1)\n",
    "        return all_embeddings \n",
    "\n",
    "    def update_attention_batch(self, ego_embed, h_list, t_list, r_idx):\n",
    "        r_embed = self.relation_emb[r_idx]\n",
    "        W_r = self.trans_M[r_idx]\n",
    "        h_embed = ego_embed[h_list]\n",
    "        t_embed = ego_embed[t_list]\n",
    "        # Equation (4)\n",
    "        r_mul_h = torch.matmul(h_embed, W_r)\n",
    "        r_mul_t = torch.matmul(t_embed, W_r)\n",
    "        v_list = torch.sum(r_mul_t * torch.tanh(r_mul_h + r_embed), dim=1)\n",
    "        return v_list\n",
    "    \n",
    "    def update_attention(self, ego_embed, h_list, t_list, r_list, relations):\n",
    "        rows, cols, values = [], [], []\n",
    "\n",
    "        for r_idx in relations:\n",
    "            index_list = torch.where(r_list == r_idx)\n",
    "            batch_h_list = h_list[index_list]\n",
    "            batch_t_list = t_list[index_list]\n",
    "\n",
    "            batch_v_list = self.update_attention_batch(ego_embed, batch_h_list, batch_t_list, r_idx)\n",
    "            rows.append(batch_h_list)\n",
    "            cols.append(batch_t_list)\n",
    "            values.append(batch_v_list)\n",
    "\n",
    "        rows = torch.cat(rows)\n",
    "        cols = torch.cat(cols)\n",
    "        values = torch.cat(values)\n",
    "\n",
    "        indices = torch.stack([rows, cols])\n",
    "        shape = self.kg_adj.shape\n",
    "        A_in = torch.sparse.FloatTensor(indices, values, torch.Size(shape))\n",
    "        # Equation (5)\n",
    "        A_in = torch.sparse.softmax(A_in.cpu(), dim=1)\n",
    "        self.kg_adj.data = A_in.to(device)\n",
    "\n",
    "    def forward(self, perturbed_adj=None, mode='cf'):\n",
    "        if mode == 'cf':\n",
    "            user_embed, item_embed = self.calculate_cf_embeddings(perturbed_adj)\n",
    "            return user_embed, item_embed\n",
    "        elif mode == 'kg':\n",
    "            entity_embed = self.calculate_kg_embeddings(perturbed_adj)\n",
    "            return entity_embed \n",
    "\n",
    "    def calculate_cf_loss(self, anchor_emb, pos_emb, neg_emb, reg):\n",
    "        calc_reg_loss = EmbLoss()\n",
    "        rec_loss = bpr_loss(anchor_emb, pos_emb, neg_emb)\n",
    "        reg_loss = reg * calc_reg_loss(anchor_emb, pos_emb, neg_emb)\n",
    "\n",
    "        cf_loss  = rec_loss + reg_loss\n",
    "        return cf_loss\n",
    "    \n",
    "    def calculate_kg_loss(self, h_embed, r, pos_t_embed, neg_t_embed, reg_kg):\n",
    "        calc_reg_loss = EmbLoss()\n",
    "        \n",
    "        r_embed = self.relation_emb[r]                                                # (kg_batch_size, relation_dim)\n",
    "        W_r = self.trans_M[r]                                                           # (kg_batch_size, embed_dim, relation_dim)\n",
    "        r_mul_h = torch.bmm(h_embed.unsqueeze(1), W_r).squeeze(1)                       # (kg_batch_size, relation_dim)\n",
    "        r_mul_pos_t = torch.bmm(pos_t_embed.unsqueeze(1), W_r).squeeze(1)               # (kg_batch_size, relation_dim)\n",
    "        r_mul_neg_t = torch.bmm(neg_t_embed.unsqueeze(1), W_r).squeeze(1)               # (kg_batch_size, relation_dim)\n",
    "\n",
    "        # Equation (1)\n",
    "        pos_score = torch.sum(torch.pow(r_mul_h + r_embed - r_mul_pos_t, 2), dim=1)     # (kg_batch_size)\n",
    "        neg_score = torch.sum(torch.pow(r_mul_h + r_embed - r_mul_neg_t, 2), dim=1)     # (kg_batch_size)\n",
    "\n",
    "        # Equation (2)\n",
    "        # kg_loss = F.softplus(pos_score - neg_score)\n",
    "        kg_loss = (-1.0) * F.logsigmoid(neg_score - pos_score)\n",
    "        kg_loss = torch.mean(kg_loss)\n",
    "\n",
    "        reg_loss =  reg_kg * calc_reg_loss(r_mul_h, r_embed, r_mul_pos_t, r_mul_neg_t)\n",
    "        loss = kg_loss + reg_loss\n",
    "        return loss\n",
    "        \n",
    "    def cal_cl_loss(self, idxs, perturbed_mat1, perturbed_mat2):\n",
    "        if type(idxs[0]) is not list:\n",
    "            u_idx = torch.unique(idxs[0])\n",
    "        else:\n",
    "            u_idx = torch.unique(torch.Tensor(idxs[0]).to(device).type(torch.long))\n",
    "        if type(idxs[1]) is not list:\n",
    "            i_idx = torch.unique(idxs[1])\n",
    "        else:\n",
    "            i_idx = torch.unique(torch.Tensor(idxs[1]).to(device).type(torch.long))\n",
    "        user_view_1, item_view_1 = self.forward(perturbed_mat1)\n",
    "        user_view_2, item_view_2 = self.forward(perturbed_mat2)\n",
    "        view1 = torch.cat((user_view_1[u_idx],item_view_1[i_idx]),0)\n",
    "        view2 = torch.cat((user_view_2[u_idx],item_view_2[i_idx]),0)\n",
    "        return InfoNCE(view1,view2,self.temp)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1f87c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95e39938-fedf-4eac-8146-225623441e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ssl_loss(data, ancs, poss, emb_cf, emb_kg, temp):\n",
    "    embeds1 = emb_cf\n",
    "    embeds2 = emb_kg\n",
    "    sslLoss = contrastLoss(embeds1[:data.n_users], embeds2[:data.n_users], torch.unique(ancs), temp) + \\\n",
    "                contrastLoss(embeds2[data.n_users:], embeds2[data.n_users:], torch.unique(poss), temp)\n",
    "    return sslLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45a91cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(u, rec, user_emb, item_emb):\n",
    "    user_id  = rec.data.get_user_id(u)\n",
    "    score = torch.matmul(user_emb[user_id], item_emb.transpose(0, 1))\n",
    "    return score.cpu().numpy()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2080f56a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ccef7c2-d692-4afb-9bdc-62131ee18c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_model_cf, train_model_kg, attention_user, attention_item, rec, args):\n",
    "    lst_train_losses = []\n",
    "    lst_cf_losses = []\n",
    "    lst_kg_losses = []\n",
    "    lst_cl_losses = [] \n",
    "    \n",
    "    lst_performances = []\n",
    "    recall_list = []\n",
    "    \n",
    "    for ep in range(maxEpoch):        \n",
    "        cf_losses = []\n",
    "        kg_losses = []\n",
    "        cl_losses = [] \n",
    "        \n",
    "        cf_total_loss = 0\n",
    "        kg_total_loss = 0\n",
    "        cl_total_loss = 0 \n",
    "\n",
    "        n_cf_batch = int(rec.data.n_cf_train // batchSize + 1)\n",
    "        n_kg_batch = int(rec.data_kg.n_kg_train // batchSizeKG + 1)\n",
    "\n",
    "        train_model_cf.train()\n",
    "        train_model_kg.train()\n",
    "        \n",
    "        for n, batch in enumerate(next_batch_unified(rec.data, rec.data_kg, batchSize, batchSizeKG)):\n",
    "            user_idx, pos_idx, neg_idx, kg_batch_head, kg_batch_relation, kg_batch_pos_tail, kg_batch_neg_tail, userent_id, itement_id = batch\n",
    "            user_emb_cf, item_emb_cf = train_model_cf(mode='cf')\n",
    "\n",
    "            ego_embed = train_model_kg(mode='kg')\n",
    "            user_emb_kg, item_emb_kg = ego_embed[train_model_kg.user_indices], ego_embed[train_model_kg.item_indices]\n",
    "            \n",
    "            # anchor_emb_kg = ego_embed[userent_id]\n",
    "            # pos_emb_kg = ego_embed[itement_id]\n",
    "            \n",
    "            kg_batch_head_emb = ego_embed[kg_batch_head]\n",
    "            kg_batch_pos_tail_emb = ego_embed[kg_batch_pos_tail]\n",
    "            kg_batch_neg_tail_emb = ego_embed[kg_batch_neg_tail]\n",
    "\n",
    "            user_emb_fused, _ = attention_user(torch.stack([user_emb_cf, user_emb_kg], dim=1))\n",
    "            item_emb_fused, _ = attention_item(torch.stack([item_emb_cf, item_emb_kg], dim=1))\n",
    "\n",
    "            h_cf = torch.cat([user_emb_cf, item_emb_cf], dim=0)\n",
    "            h_kg = torch.cat([user_emb_kg, item_emb_kg], dim=0)\n",
    "            \n",
    "            anchor_emb = user_emb_fused[user_idx]\n",
    "            pos_emb = item_emb_fused[pos_idx]\n",
    "            neg_emb = item_emb_fused[neg_idx]\n",
    "\n",
    "            cf_batch_loss = train_model_cf.calculate_cf_loss(anchor_emb, pos_emb, neg_emb, reg)\n",
    "            kg_batch_loss = train_model_kg.calculate_kg_loss(kg_batch_head_emb, kg_batch_relation, kg_batch_pos_tail_emb, kg_batch_neg_tail_emb, reg_kg)\n",
    "            cf_total_loss += cf_batch_loss.item()\n",
    "            kg_total_loss +=  kg_batch_loss.item()\n",
    "            \n",
    "            if args['use_contrastive']:\n",
    "                cl_batch_loss = cl_rate * calculate_ssl_loss(rec.data, user_idx, pos_idx, h_cf, h_kg, args['temp'])\n",
    "                cl_losses.append(cl_batch_loss.item())\n",
    "                cl_total_loss += cl_batch_loss.item()\n",
    "                batch_loss = cf_batch_loss + kg_batch_loss + cl_batch_loss\n",
    "            else:\n",
    "                batch_loss = cf_batch_loss + kg_batch_loss \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            cf_losses.append(cf_batch_loss.item())\n",
    "            kg_losses.append(kg_batch_loss.item())\n",
    "\n",
    "            if (n % 20) == 0:\n",
    "                print('CF Training: Epoch {:04d} Iter {:04d} / {:04d} | Iter Loss {:.4f} | Iter Mean Loss {:.4f}'.format(ep, n, n_kg_batch,  cf_batch_loss.item(), cf_total_loss / (n+1)))\n",
    "                print('KG Training: Epoch {:04d} Iter {:04d} / {:04d} | Iter Loss {:.4f} | Iter Mean Loss {:.4f}'.format(ep, n, n_kg_batch, kg_batch_loss.item(), kg_total_loss / (n+1)))\n",
    "                print('CL Training: Epoch {:04d} Iter {:04d} / {:04d} | Iter Loss {:.4f} | Iter Mean Loss {:.4f}'.format(ep, n, n_kg_batch, cl_batch_loss.item(), cl_total_loss / (n+1)))\n",
    "                    \n",
    "            if args['use_attention_propagation']:\n",
    "                h_list  = rec.data_kg.h_list\n",
    "                t_list  = rec.data_kg.t_list\n",
    "                r_list = rec.data_kg.r_list\n",
    "                relations = list(rec.data_kg.laplacian_dict.keys())\n",
    "                train_model_kg.update_attention(ego_embed, h_list, t_list, r_list, relations)\n",
    "        \n",
    "        cf_loss = np.mean(cf_losses)\n",
    "\n",
    "        kg_loss = np.mean(kg_losses)\n",
    "\n",
    "        if args['use_contrastive']:\n",
    "            cl_loss = np.mean(cl_losses)\n",
    "            train_loss = cf_loss + kg_loss + cl_loss \n",
    "        else:\n",
    "            cl_loss  = 0\n",
    "            train_loss = cf_loss + kg_loss\n",
    "\n",
    "        lst_cf_losses.append([ep,cf_loss])\n",
    "        lst_kg_losses.append([ep, kg_loss])\n",
    "        lst_train_losses.append([ep, train_loss])\n",
    "        scheduler.step(train_loss)\n",
    "        \n",
    "        # Evaluation\n",
    "        train_model_cf.eval()\n",
    "        train_model_kg.eval()\n",
    "        attention_user.eval()\n",
    "        attention_item.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            user_emb_cf, item_emb_cf = train_model_cf(mode='cf')\n",
    "            ego_emb = train_model_kg(mode='kg')\n",
    "            user_emb_kg, item_emb_kg = ego_emb[train_model_kg.user_indices], ego_emb[train_model_kg.item_indices]\n",
    "\n",
    "            user_emb, _ = attention_user(torch.stack([user_emb_cf, user_emb_kg], dim=1))\n",
    "            item_emb, _ = attention_item(torch.stack([item_emb_cf, item_emb_kg], dim=1))\n",
    "            data_ep = rec.fast_evaluation(ep, train_model_cf, train_model_kg, user_emb, item_emb)\n",
    "        \n",
    "            cur_recall =  float(data_ep[2].split(':')[1])\n",
    "            recall_list.append(cur_recall)\n",
    "            best_recall, should_stop = early_stopping(recall_list, 100)\n",
    "\n",
    "        rec.save_performance_row(ep, data_ep)\n",
    "        rec.save_loss_row([ep, train_loss, cf_loss, kg_loss, cl_loss])\n",
    "        lst_performances.append(data_ep)\n",
    "\n",
    "    rec.save_loss(lst_train_losses, lst_kg_losses, lst_cf_losses, lst_kg_losses)\n",
    "    rec.save_perfomance_training(lst_performances)\n",
    "    user_emb, item_emb = rec.best_user_emb, rec.best_item_emb\n",
    "    return user_emb, item_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081217e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "184d99a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(rec, user_emb, item_emb):\n",
    "    def process_bar(num, total):\n",
    "        rate = float(num) / total\n",
    "        ratenum = int(50 * rate)\n",
    "        r = '\\rProgress: [{}{}]{}%'.format('+' * ratenum, ' ' * (50 - ratenum), ratenum*2)\n",
    "        sys.stdout.write(r)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    # predict\n",
    "    rec_list = {}\n",
    "    user_count = len(rec.data.test_set)\n",
    "    for i, user in enumerate(rec.data.test_set):\n",
    "        # s_find_candidates = time.time()\n",
    "        candidates = predict(user, rec, user_emb, item_emb)\n",
    "        rated_list, li = rec.data.user_rated(user)\n",
    "        for item in rated_list:\n",
    "            candidates[rec.data.item[item]] = -10e8\n",
    "\n",
    "        # s_find_k_largest = time.time()\n",
    "        ids, scores = find_k_largest(rec.max_N, candidates)\n",
    "        # e_find_k_largest = time.time()\n",
    "        # print(\"Find k largest candidates: %f s\" % (e_find_k_largest - s_find_k_largest))\n",
    "        item_names = [rec.data.id2item[iid] for iid in ids]\n",
    "        rec_list[user] = list(zip(item_names, scores))\n",
    "        if i % 1000 == 0:\n",
    "            process_bar(i, user_count)\n",
    "    process_bar(user_count, user_count)\n",
    "    print('')\n",
    "    rec.evaluate(rec_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d97fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a92d19f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'HGNN'\n",
    "if model not in ['HGNN', 'LightGCN']:\n",
    "    print(\"No model found.\")\n",
    "config = ModelConf('./conf/' + model + '.conf')\n",
    "\n",
    "dataset = ['lastfm']\n",
    "batchSize = 2048\n",
    "batchSizeKG = 8192\n",
    "maxEpoch = 1000\n",
    "lRates = [0.01]\n",
    "lRateKgs = [0.01]\n",
    "lrDecays = [0.7]\n",
    "regs = [0.01]\n",
    "reg_kgs = [0.1]\n",
    "hyperDims = [128]\n",
    "inputDims = [32]\n",
    "ps = [0.3]\n",
    "dropRates = [0.3]\n",
    "nLayers = [2]\n",
    "nHeads = [1]\n",
    "nSelfAtt = [1]\n",
    "clRate = [0.01]\n",
    "augType = [1]\n",
    "temp = [0.3]\n",
    "use_contrasts = [True]\n",
    "use_attention_propagations = [True]\n",
    "hyperparameters = [dataset, lRates, lRateKgs, lrDecays, regs, reg_kgs, hyperDims, inputDims, ps, dropRates, nLayers, nHeads, nSelfAtt, clRate, augType, temp, use_contrasts, use_attention_propagations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "638e44e4-ced6-4604-b477-8d87e64b9bab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n",
      "/tmp/ipykernel_18569/1351531476.py:181: RuntimeWarning: divide by zero encountered in power\n",
      "  d_inv = np.power(rowsum, -1.0).flatten()\n"
     ]
    }
   ],
   "source": [
    "dataset = 'lastfm'\n",
    "training_data = FileIO.load_data_set('./dataset/' + dataset + '/' +config['training.set'], config['model.type'])\n",
    "test_data = FileIO.load_data_set('./dataset/' + dataset + '/'  +config['test.set'], config['model.type'])\n",
    "knowledge_set = FileIO.load_kg_data('./dataset/' + dataset +'/'+ dataset +'.kg')\n",
    "data = Interaction(config, training_data, test_data)\n",
    "data_kg = Knowledge(config, training_data, test_data, knowledge_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005f0ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lastfm', 0.01, 0.01, 0.7, 0.01, 0.1, 128, 32, 0.3, 0.3, 2, 1, 1, 0.01, 1, 0.3, True, True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk1/hungvv/recommender/SELFRec/base/torch_interface.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  i = torch.LongTensor([coo.row, coo.col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF Training: Epoch 0000 Iter 0000 / 0263 | Iter Loss 0.6250 | Iter Mean Loss 0.6250\n",
      "KG Training: Epoch 0000 Iter 0000 / 0263 | Iter Loss 0.7184 | Iter Mean Loss 0.7184\n",
      "CL Training: Epoch 0000 Iter 0000 / 0263 | Iter Loss 0.1418 | Iter Mean Loss 0.1418\n",
      "CF Training: Epoch 0000 Iter 0020 / 0263 | Iter Loss 0.3082 | Iter Mean Loss 0.4691\n",
      "KG Training: Epoch 0000 Iter 0020 / 0263 | Iter Loss 0.5231 | Iter Mean Loss 0.5756\n",
      "CL Training: Epoch 0000 Iter 0020 / 0263 | Iter Loss 0.1423 | Iter Mean Loss 0.1424\n",
      "CF Training: Epoch 0000 Iter 0040 / 0263 | Iter Loss 0.2064 | Iter Mean Loss 0.3580\n",
      "KG Training: Epoch 0000 Iter 0040 / 0263 | Iter Loss 0.4601 | Iter Mean Loss 0.5323\n",
      "CL Training: Epoch 0000 Iter 0040 / 0263 | Iter Loss 0.1407 | Iter Mean Loss 0.1419\n",
      "CF Training: Epoch 0000 Iter 0060 / 0263 | Iter Loss 0.1390 | Iter Mean Loss 0.2960\n",
      "KG Training: Epoch 0000 Iter 0060 / 0263 | Iter Loss 0.4193 | Iter Mean Loss 0.5031\n",
      "CL Training: Epoch 0000 Iter 0060 / 0263 | Iter Loss 0.1402 | Iter Mean Loss 0.1414\n",
      "CF Training: Epoch 0000 Iter 0080 / 0263 | Iter Loss 0.1343 | Iter Mean Loss 0.2588\n",
      "KG Training: Epoch 0000 Iter 0080 / 0263 | Iter Loss 0.4379 | Iter Mean Loss 0.4856\n",
      "CL Training: Epoch 0000 Iter 0080 / 0263 | Iter Loss 0.1393 | Iter Mean Loss 0.1410\n",
      "CF Training: Epoch 0000 Iter 0100 / 0263 | Iter Loss 0.0998 | Iter Mean Loss 0.2319\n",
      "KG Training: Epoch 0000 Iter 0100 / 0263 | Iter Loss 0.4428 | Iter Mean Loss 0.4778\n",
      "CL Training: Epoch 0000 Iter 0100 / 0263 | Iter Loss 0.1388 | Iter Mean Loss 0.1406\n",
      "CF Training: Epoch 0000 Iter 0120 / 0263 | Iter Loss 0.1063 | Iter Mean Loss 0.2116\n",
      "KG Training: Epoch 0000 Iter 0120 / 0263 | Iter Loss 0.4224 | Iter Mean Loss 0.4702\n",
      "CL Training: Epoch 0000 Iter 0120 / 0263 | Iter Loss 0.1382 | Iter Mean Loss 0.1403\n",
      "CF Training: Epoch 0000 Iter 0140 / 0263 | Iter Loss 0.1029 | Iter Mean Loss 0.1960\n",
      "KG Training: Epoch 0000 Iter 0140 / 0263 | Iter Loss 0.3704 | Iter Mean Loss 0.4595\n",
      "CL Training: Epoch 0000 Iter 0140 / 0263 | Iter Loss 0.1376 | Iter Mean Loss 0.1400\n",
      "CF Training: Epoch 0000 Iter 0160 / 0263 | Iter Loss 0.0921 | Iter Mean Loss 0.1830\n",
      "KG Training: Epoch 0000 Iter 0160 / 0263 | Iter Loss 0.3512 | Iter Mean Loss 0.4475\n",
      "CL Training: Epoch 0000 Iter 0160 / 0263 | Iter Loss 0.1370 | Iter Mean Loss 0.1396\n",
      "CF Training: Epoch 0000 Iter 0180 / 0263 | Iter Loss 0.0761 | Iter Mean Loss 0.1723\n",
      "KG Training: Epoch 0000 Iter 0180 / 0263 | Iter Loss 0.3333 | Iter Mean Loss 0.4363\n",
      "CL Training: Epoch 0000 Iter 0180 / 0263 | Iter Loss 0.1365 | Iter Mean Loss 0.1393\n",
      "CF Training: Epoch 0000 Iter 0200 / 0263 | Iter Loss 0.0734 | Iter Mean Loss 0.1629\n",
      "KG Training: Epoch 0000 Iter 0200 / 0263 | Iter Loss 0.3117 | Iter Mean Loss 0.4254\n",
      "CL Training: Epoch 0000 Iter 0200 / 0263 | Iter Loss 0.1358 | Iter Mean Loss 0.1390\n",
      "CF Training: Epoch 0000 Iter 0220 / 0263 | Iter Loss 0.0640 | Iter Mean Loss 0.1548\n",
      "KG Training: Epoch 0000 Iter 0220 / 0263 | Iter Loss 0.3044 | Iter Mean Loss 0.4147\n",
      "CL Training: Epoch 0000 Iter 0220 / 0263 | Iter Loss 0.1353 | Iter Mean Loss 0.1387\n",
      "CF Training: Epoch 0000 Iter 0240 / 0263 | Iter Loss 0.0782 | Iter Mean Loss 0.1475\n",
      "KG Training: Epoch 0000 Iter 0240 / 0263 | Iter Loss 0.2873 | Iter Mean Loss 0.4041\n",
      "CL Training: Epoch 0000 Iter 0240 / 0263 | Iter Loss 0.1348 | Iter Mean Loss 0.1384\n",
      "CF Training: Epoch 0000 Iter 0260 / 0263 | Iter Loss 0.0596 | Iter Mean Loss 0.1412\n",
      "KG Training: Epoch 0000 Iter 0260 / 0263 | Iter Loss 0.2864 | Iter Mean Loss 0.3949\n",
      "CL Training: Epoch 0000 Iter 0260 / 0263 | Iter Loss 0.1342 | Iter Mean Loss 0.1381\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 5.549513 s\n",
      "Measure time: 0.017364 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 1, Hit Ratio:0.17345  |  Precision:0.10682  |  Recall:0.17472  |  NDCG:0.17767\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 1, Hit Ratio:0.17345  |  Precision:0.10682  |  Recall:0.17472  |  NDCG:0.17767\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0001 Iter 0000 / 0263 | Iter Loss 0.0670 | Iter Mean Loss 0.0670\n",
      "KG Training: Epoch 0001 Iter 0000 / 0263 | Iter Loss 0.2646 | Iter Mean Loss 0.2646\n",
      "CL Training: Epoch 0001 Iter 0000 / 0263 | Iter Loss 0.1342 | Iter Mean Loss 0.1342\n",
      "CF Training: Epoch 0001 Iter 0020 / 0263 | Iter Loss 0.0588 | Iter Mean Loss 0.0630\n",
      "KG Training: Epoch 0001 Iter 0020 / 0263 | Iter Loss 0.3386 | Iter Mean Loss 0.2932\n",
      "CL Training: Epoch 0001 Iter 0020 / 0263 | Iter Loss 0.1346 | Iter Mean Loss 0.1343\n",
      "CF Training: Epoch 0001 Iter 0040 / 0263 | Iter Loss 0.0564 | Iter Mean Loss 0.0622\n",
      "KG Training: Epoch 0001 Iter 0040 / 0263 | Iter Loss 0.2924 | Iter Mean Loss 0.2980\n",
      "CL Training: Epoch 0001 Iter 0040 / 0263 | Iter Loss 0.1341 | Iter Mean Loss 0.1344\n",
      "CF Training: Epoch 0001 Iter 0060 / 0263 | Iter Loss 0.0448 | Iter Mean Loss 0.0600\n",
      "KG Training: Epoch 0001 Iter 0060 / 0263 | Iter Loss 0.2799 | Iter Mean Loss 0.2944\n",
      "CL Training: Epoch 0001 Iter 0060 / 0263 | Iter Loss 0.1335 | Iter Mean Loss 0.1342\n",
      "CF Training: Epoch 0001 Iter 0080 / 0263 | Iter Loss 0.0496 | Iter Mean Loss 0.0584\n",
      "KG Training: Epoch 0001 Iter 0080 / 0263 | Iter Loss 0.2780 | Iter Mean Loss 0.2911\n",
      "CL Training: Epoch 0001 Iter 0080 / 0263 | Iter Loss 0.1328 | Iter Mean Loss 0.1340\n",
      "CF Training: Epoch 0001 Iter 0100 / 0263 | Iter Loss 0.0472 | Iter Mean Loss 0.0573\n",
      "KG Training: Epoch 0001 Iter 0100 / 0263 | Iter Loss 0.2549 | Iter Mean Loss 0.2872\n",
      "CL Training: Epoch 0001 Iter 0100 / 0263 | Iter Loss 0.1324 | Iter Mean Loss 0.1337\n",
      "CF Training: Epoch 0001 Iter 0120 / 0263 | Iter Loss 0.0493 | Iter Mean Loss 0.0560\n",
      "KG Training: Epoch 0001 Iter 0120 / 0263 | Iter Loss 0.2437 | Iter Mean Loss 0.2804\n",
      "CL Training: Epoch 0001 Iter 0120 / 0263 | Iter Loss 0.1320 | Iter Mean Loss 0.1335\n",
      "CF Training: Epoch 0001 Iter 0140 / 0263 | Iter Loss 0.0446 | Iter Mean Loss 0.0550\n",
      "KG Training: Epoch 0001 Iter 0140 / 0263 | Iter Loss 0.2234 | Iter Mean Loss 0.2732\n",
      "CL Training: Epoch 0001 Iter 0140 / 0263 | Iter Loss 0.1316 | Iter Mean Loss 0.1332\n",
      "CF Training: Epoch 0001 Iter 0160 / 0263 | Iter Loss 0.0358 | Iter Mean Loss 0.0538\n",
      "KG Training: Epoch 0001 Iter 0160 / 0263 | Iter Loss 0.2190 | Iter Mean Loss 0.2668\n",
      "CL Training: Epoch 0001 Iter 0160 / 0263 | Iter Loss 0.1312 | Iter Mean Loss 0.1330\n",
      "CF Training: Epoch 0001 Iter 0180 / 0263 | Iter Loss 0.0369 | Iter Mean Loss 0.0526\n",
      "KG Training: Epoch 0001 Iter 0180 / 0263 | Iter Loss 0.2196 | Iter Mean Loss 0.2621\n",
      "CL Training: Epoch 0001 Iter 0180 / 0263 | Iter Loss 0.1307 | Iter Mean Loss 0.1328\n",
      "CF Training: Epoch 0001 Iter 0200 / 0263 | Iter Loss 0.0409 | Iter Mean Loss 0.0516\n",
      "KG Training: Epoch 0001 Iter 0200 / 0263 | Iter Loss 0.2078 | Iter Mean Loss 0.2574\n",
      "CL Training: Epoch 0001 Iter 0200 / 0263 | Iter Loss 0.1301 | Iter Mean Loss 0.1325\n",
      "CF Training: Epoch 0001 Iter 0220 / 0263 | Iter Loss 0.0362 | Iter Mean Loss 0.0510\n",
      "KG Training: Epoch 0001 Iter 0220 / 0263 | Iter Loss 0.2060 | Iter Mean Loss 0.2528\n",
      "CL Training: Epoch 0001 Iter 0220 / 0263 | Iter Loss 0.1299 | Iter Mean Loss 0.1323\n",
      "CF Training: Epoch 0001 Iter 0240 / 0263 | Iter Loss 0.0441 | Iter Mean Loss 0.0504\n",
      "KG Training: Epoch 0001 Iter 0240 / 0263 | Iter Loss 0.1970 | Iter Mean Loss 0.2485\n",
      "CL Training: Epoch 0001 Iter 0240 / 0263 | Iter Loss 0.1298 | Iter Mean Loss 0.1321\n",
      "CF Training: Epoch 0001 Iter 0260 / 0263 | Iter Loss 0.0409 | Iter Mean Loss 0.0496\n",
      "KG Training: Epoch 0001 Iter 0260 / 0263 | Iter Loss 0.2144 | Iter Mean Loss 0.2452\n",
      "CL Training: Epoch 0001 Iter 0260 / 0263 | Iter Loss 0.1289 | Iter Mean Loss 0.1319\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.910707 s\n",
      "Measure time: 0.017435 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 2, Hit Ratio:0.18845  |  Precision:0.11606  |  Recall:0.18986  |  NDCG:0.19947\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 2, Hit Ratio:0.18845  |  Precision:0.11606  |  Recall:0.18986  |  NDCG:0.19947\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0002 Iter 0000 / 0263 | Iter Loss 0.0314 | Iter Mean Loss 0.0314\n",
      "KG Training: Epoch 0002 Iter 0000 / 0263 | Iter Loss 0.1819 | Iter Mean Loss 0.1819\n",
      "CL Training: Epoch 0002 Iter 0000 / 0263 | Iter Loss 0.1292 | Iter Mean Loss 0.1292\n",
      "CF Training: Epoch 0002 Iter 0020 / 0263 | Iter Loss 0.0380 | Iter Mean Loss 0.0397\n",
      "KG Training: Epoch 0002 Iter 0020 / 0263 | Iter Loss 0.1992 | Iter Mean Loss 0.2038\n",
      "CL Training: Epoch 0002 Iter 0020 / 0263 | Iter Loss 0.1296 | Iter Mean Loss 0.1294\n",
      "CF Training: Epoch 0002 Iter 0040 / 0263 | Iter Loss 0.0378 | Iter Mean Loss 0.0393\n",
      "KG Training: Epoch 0002 Iter 0040 / 0263 | Iter Loss 0.2131 | Iter Mean Loss 0.2073\n",
      "CL Training: Epoch 0002 Iter 0040 / 0263 | Iter Loss 0.1291 | Iter Mean Loss 0.1293\n",
      "CF Training: Epoch 0002 Iter 0060 / 0263 | Iter Loss 0.0468 | Iter Mean Loss 0.0391\n",
      "KG Training: Epoch 0002 Iter 0060 / 0263 | Iter Loss 0.1987 | Iter Mean Loss 0.2075\n",
      "CL Training: Epoch 0002 Iter 0060 / 0263 | Iter Loss 0.1284 | Iter Mean Loss 0.1291\n",
      "CF Training: Epoch 0002 Iter 0080 / 0263 | Iter Loss 0.0310 | Iter Mean Loss 0.0389\n",
      "KG Training: Epoch 0002 Iter 0080 / 0263 | Iter Loss 0.2065 | Iter Mean Loss 0.2065\n",
      "CL Training: Epoch 0002 Iter 0080 / 0263 | Iter Loss 0.1281 | Iter Mean Loss 0.1289\n",
      "CF Training: Epoch 0002 Iter 0100 / 0263 | Iter Loss 0.0431 | Iter Mean Loss 0.0385\n",
      "KG Training: Epoch 0002 Iter 0100 / 0263 | Iter Loss 0.1870 | Iter Mean Loss 0.2039\n",
      "CL Training: Epoch 0002 Iter 0100 / 0263 | Iter Loss 0.1272 | Iter Mean Loss 0.1286\n",
      "CF Training: Epoch 0002 Iter 0120 / 0263 | Iter Loss 0.0397 | Iter Mean Loss 0.0388\n",
      "KG Training: Epoch 0002 Iter 0120 / 0263 | Iter Loss 0.1732 | Iter Mean Loss 0.1996\n",
      "CL Training: Epoch 0002 Iter 0120 / 0263 | Iter Loss 0.1273 | Iter Mean Loss 0.1284\n",
      "CF Training: Epoch 0002 Iter 0140 / 0263 | Iter Loss 0.0370 | Iter Mean Loss 0.0386\n",
      "KG Training: Epoch 0002 Iter 0140 / 0263 | Iter Loss 0.1659 | Iter Mean Loss 0.1948\n",
      "CL Training: Epoch 0002 Iter 0140 / 0263 | Iter Loss 0.1265 | Iter Mean Loss 0.1282\n",
      "CF Training: Epoch 0002 Iter 0160 / 0263 | Iter Loss 0.0424 | Iter Mean Loss 0.0384\n",
      "KG Training: Epoch 0002 Iter 0160 / 0263 | Iter Loss 0.1650 | Iter Mean Loss 0.1908\n",
      "CL Training: Epoch 0002 Iter 0160 / 0263 | Iter Loss 0.1266 | Iter Mean Loss 0.1280\n",
      "CF Training: Epoch 0002 Iter 0180 / 0263 | Iter Loss 0.0276 | Iter Mean Loss 0.0381\n",
      "KG Training: Epoch 0002 Iter 0180 / 0263 | Iter Loss 0.1688 | Iter Mean Loss 0.1883\n",
      "CL Training: Epoch 0002 Iter 0180 / 0263 | Iter Loss 0.1260 | Iter Mean Loss 0.1278\n",
      "CF Training: Epoch 0002 Iter 0200 / 0263 | Iter Loss 0.0431 | Iter Mean Loss 0.0380\n",
      "KG Training: Epoch 0002 Iter 0200 / 0263 | Iter Loss 0.1705 | Iter Mean Loss 0.1856\n",
      "CL Training: Epoch 0002 Iter 0200 / 0263 | Iter Loss 0.1255 | Iter Mean Loss 0.1276\n",
      "CF Training: Epoch 0002 Iter 0220 / 0263 | Iter Loss 0.0391 | Iter Mean Loss 0.0377\n",
      "KG Training: Epoch 0002 Iter 0220 / 0263 | Iter Loss 0.1499 | Iter Mean Loss 0.1829\n",
      "CL Training: Epoch 0002 Iter 0220 / 0263 | Iter Loss 0.1260 | Iter Mean Loss 0.1274\n",
      "CF Training: Epoch 0002 Iter 0240 / 0263 | Iter Loss 0.0360 | Iter Mean Loss 0.0373\n",
      "KG Training: Epoch 0002 Iter 0240 / 0263 | Iter Loss 0.1565 | Iter Mean Loss 0.1804\n",
      "CL Training: Epoch 0002 Iter 0240 / 0263 | Iter Loss 0.1256 | Iter Mean Loss 0.1273\n",
      "CF Training: Epoch 0002 Iter 0260 / 0263 | Iter Loss 0.0338 | Iter Mean Loss 0.0370\n",
      "KG Training: Epoch 0002 Iter 0260 / 0263 | Iter Loss 0.1726 | Iter Mean Loss 0.1790\n",
      "CL Training: Epoch 0002 Iter 0260 / 0263 | Iter Loss 0.1249 | Iter Mean Loss 0.1271\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.960286 s\n",
      "Measure time: 0.017852 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 3, Hit Ratio:0.18362  |  Precision:0.11308  |  Recall:0.18473  |  NDCG:0.19114\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 2, Hit Ratio:0.18845  |  Precision:0.11606  |  Recall:0.18986  |  NDCG:0.19947\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0003 Iter 0000 / 0263 | Iter Loss 0.0311 | Iter Mean Loss 0.0311\n",
      "KG Training: Epoch 0003 Iter 0000 / 0263 | Iter Loss 0.1344 | Iter Mean Loss 0.1344\n",
      "CL Training: Epoch 0003 Iter 0000 / 0263 | Iter Loss 0.1246 | Iter Mean Loss 0.1246\n",
      "CF Training: Epoch 0003 Iter 0020 / 0263 | Iter Loss 0.0326 | Iter Mean Loss 0.0331\n",
      "KG Training: Epoch 0003 Iter 0020 / 0263 | Iter Loss 0.1590 | Iter Mean Loss 0.1507\n",
      "CL Training: Epoch 0003 Iter 0020 / 0263 | Iter Loss 0.1255 | Iter Mean Loss 0.1253\n",
      "CF Training: Epoch 0003 Iter 0040 / 0263 | Iter Loss 0.0416 | Iter Mean Loss 0.0334\n",
      "KG Training: Epoch 0003 Iter 0040 / 0263 | Iter Loss 0.1567 | Iter Mean Loss 0.1543\n",
      "CL Training: Epoch 0003 Iter 0040 / 0263 | Iter Loss 0.1254 | Iter Mean Loss 0.1253\n",
      "CF Training: Epoch 0003 Iter 0060 / 0263 | Iter Loss 0.0330 | Iter Mean Loss 0.0327\n",
      "KG Training: Epoch 0003 Iter 0060 / 0263 | Iter Loss 0.1545 | Iter Mean Loss 0.1550\n",
      "CL Training: Epoch 0003 Iter 0060 / 0263 | Iter Loss 0.1244 | Iter Mean Loss 0.1252\n",
      "CF Training: Epoch 0003 Iter 0080 / 0263 | Iter Loss 0.0390 | Iter Mean Loss 0.0326\n",
      "KG Training: Epoch 0003 Iter 0080 / 0263 | Iter Loss 0.1553 | Iter Mean Loss 0.1547\n",
      "CL Training: Epoch 0003 Iter 0080 / 0263 | Iter Loss 0.1243 | Iter Mean Loss 0.1250\n",
      "CF Training: Epoch 0003 Iter 0100 / 0263 | Iter Loss 0.0330 | Iter Mean Loss 0.0329\n",
      "KG Training: Epoch 0003 Iter 0100 / 0263 | Iter Loss 0.1425 | Iter Mean Loss 0.1538\n",
      "CL Training: Epoch 0003 Iter 0100 / 0263 | Iter Loss 0.1238 | Iter Mean Loss 0.1248\n",
      "CF Training: Epoch 0003 Iter 0120 / 0263 | Iter Loss 0.0332 | Iter Mean Loss 0.0326\n",
      "KG Training: Epoch 0003 Iter 0120 / 0263 | Iter Loss 0.1323 | Iter Mean Loss 0.1513\n",
      "CL Training: Epoch 0003 Iter 0120 / 0263 | Iter Loss 0.1237 | Iter Mean Loss 0.1246\n",
      "CF Training: Epoch 0003 Iter 0140 / 0263 | Iter Loss 0.0339 | Iter Mean Loss 0.0325\n",
      "KG Training: Epoch 0003 Iter 0140 / 0263 | Iter Loss 0.1309 | Iter Mean Loss 0.1485\n",
      "CL Training: Epoch 0003 Iter 0140 / 0263 | Iter Loss 0.1234 | Iter Mean Loss 0.1244\n",
      "CF Training: Epoch 0003 Iter 0160 / 0263 | Iter Loss 0.0329 | Iter Mean Loss 0.0325\n",
      "KG Training: Epoch 0003 Iter 0160 / 0263 | Iter Loss 0.1306 | Iter Mean Loss 0.1459\n",
      "CL Training: Epoch 0003 Iter 0160 / 0263 | Iter Loss 0.1228 | Iter Mean Loss 0.1242\n",
      "CF Training: Epoch 0003 Iter 0180 / 0263 | Iter Loss 0.0314 | Iter Mean Loss 0.0323\n",
      "KG Training: Epoch 0003 Iter 0180 / 0263 | Iter Loss 0.1390 | Iter Mean Loss 0.1445\n",
      "CL Training: Epoch 0003 Iter 0180 / 0263 | Iter Loss 0.1227 | Iter Mean Loss 0.1240\n",
      "CF Training: Epoch 0003 Iter 0200 / 0263 | Iter Loss 0.0398 | Iter Mean Loss 0.0321\n",
      "KG Training: Epoch 0003 Iter 0200 / 0263 | Iter Loss 0.1277 | Iter Mean Loss 0.1431\n",
      "CL Training: Epoch 0003 Iter 0200 / 0263 | Iter Loss 0.1222 | Iter Mean Loss 0.1239\n",
      "CF Training: Epoch 0003 Iter 0220 / 0263 | Iter Loss 0.0310 | Iter Mean Loss 0.0322\n",
      "KG Training: Epoch 0003 Iter 0220 / 0263 | Iter Loss 0.1298 | Iter Mean Loss 0.1419\n",
      "CL Training: Epoch 0003 Iter 0220 / 0263 | Iter Loss 0.1224 | Iter Mean Loss 0.1237\n",
      "CF Training: Epoch 0003 Iter 0240 / 0263 | Iter Loss 0.0270 | Iter Mean Loss 0.0319\n",
      "KG Training: Epoch 0003 Iter 0240 / 0263 | Iter Loss 0.1380 | Iter Mean Loss 0.1407\n",
      "CL Training: Epoch 0003 Iter 0240 / 0263 | Iter Loss 0.1219 | Iter Mean Loss 0.1236\n",
      "CF Training: Epoch 0003 Iter 0260 / 0263 | Iter Loss 0.0260 | Iter Mean Loss 0.0317\n",
      "KG Training: Epoch 0003 Iter 0260 / 0263 | Iter Loss 0.1369 | Iter Mean Loss 0.1403\n",
      "CL Training: Epoch 0003 Iter 0260 / 0263 | Iter Loss 0.1218 | Iter Mean Loss 0.1234\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.700484 s\n",
      "Measure time: 0.017323 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 4, Hit Ratio:0.19647  |  Precision:0.12099  |  Recall:0.19931  |  NDCG:0.20598\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 4, Hit Ratio:0.19647  |  Precision:0.12099  |  Recall:0.19931  |  NDCG:0.20598\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0004 Iter 0000 / 0263 | Iter Loss 0.0468 | Iter Mean Loss 0.0468\n",
      "KG Training: Epoch 0004 Iter 0000 / 0263 | Iter Loss 0.1024 | Iter Mean Loss 0.1024\n",
      "CL Training: Epoch 0004 Iter 0000 / 0263 | Iter Loss 0.1218 | Iter Mean Loss 0.1218\n",
      "CF Training: Epoch 0004 Iter 0020 / 0263 | Iter Loss 0.0249 | Iter Mean Loss 0.0294\n",
      "KG Training: Epoch 0004 Iter 0020 / 0263 | Iter Loss 0.1189 | Iter Mean Loss 0.1155\n",
      "CL Training: Epoch 0004 Iter 0020 / 0263 | Iter Loss 0.1223 | Iter Mean Loss 0.1221\n",
      "CF Training: Epoch 0004 Iter 0040 / 0263 | Iter Loss 0.0259 | Iter Mean Loss 0.0294\n",
      "KG Training: Epoch 0004 Iter 0040 / 0263 | Iter Loss 0.1224 | Iter Mean Loss 0.1194\n",
      "CL Training: Epoch 0004 Iter 0040 / 0263 | Iter Loss 0.1221 | Iter Mean Loss 0.1221\n",
      "CF Training: Epoch 0004 Iter 0060 / 0263 | Iter Loss 0.0327 | Iter Mean Loss 0.0295\n",
      "KG Training: Epoch 0004 Iter 0060 / 0263 | Iter Loss 0.1240 | Iter Mean Loss 0.1204\n",
      "CL Training: Epoch 0004 Iter 0060 / 0263 | Iter Loss 0.1216 | Iter Mean Loss 0.1219\n",
      "CF Training: Epoch 0004 Iter 0080 / 0263 | Iter Loss 0.0377 | Iter Mean Loss 0.0298\n",
      "KG Training: Epoch 0004 Iter 0080 / 0263 | Iter Loss 0.1235 | Iter Mean Loss 0.1208\n",
      "CL Training: Epoch 0004 Iter 0080 / 0263 | Iter Loss 0.1212 | Iter Mean Loss 0.1217\n",
      "CF Training: Epoch 0004 Iter 0100 / 0263 | Iter Loss 0.0292 | Iter Mean Loss 0.0301\n",
      "KG Training: Epoch 0004 Iter 0100 / 0263 | Iter Loss 0.1174 | Iter Mean Loss 0.1206\n",
      "CL Training: Epoch 0004 Iter 0100 / 0263 | Iter Loss 0.1208 | Iter Mean Loss 0.1216\n",
      "CF Training: Epoch 0004 Iter 0120 / 0263 | Iter Loss 0.0309 | Iter Mean Loss 0.0299\n",
      "KG Training: Epoch 0004 Iter 0120 / 0263 | Iter Loss 0.1110 | Iter Mean Loss 0.1193\n",
      "CL Training: Epoch 0004 Iter 0120 / 0263 | Iter Loss 0.1203 | Iter Mean Loss 0.1214\n",
      "CF Training: Epoch 0004 Iter 0140 / 0263 | Iter Loss 0.0304 | Iter Mean Loss 0.0299\n",
      "KG Training: Epoch 0004 Iter 0140 / 0263 | Iter Loss 0.1091 | Iter Mean Loss 0.1178\n",
      "CL Training: Epoch 0004 Iter 0140 / 0263 | Iter Loss 0.1206 | Iter Mean Loss 0.1212\n",
      "CF Training: Epoch 0004 Iter 0160 / 0263 | Iter Loss 0.0231 | Iter Mean Loss 0.0296\n",
      "KG Training: Epoch 0004 Iter 0160 / 0263 | Iter Loss 0.1070 | Iter Mean Loss 0.1166\n",
      "CL Training: Epoch 0004 Iter 0160 / 0263 | Iter Loss 0.1200 | Iter Mean Loss 0.1211\n",
      "CF Training: Epoch 0004 Iter 0180 / 0263 | Iter Loss 0.0300 | Iter Mean Loss 0.0292\n",
      "KG Training: Epoch 0004 Iter 0180 / 0263 | Iter Loss 0.1122 | Iter Mean Loss 0.1162\n",
      "CL Training: Epoch 0004 Iter 0180 / 0263 | Iter Loss 0.1199 | Iter Mean Loss 0.1210\n",
      "CF Training: Epoch 0004 Iter 0200 / 0263 | Iter Loss 0.0335 | Iter Mean Loss 0.0291\n",
      "KG Training: Epoch 0004 Iter 0200 / 0263 | Iter Loss 0.1073 | Iter Mean Loss 0.1156\n",
      "CL Training: Epoch 0004 Iter 0200 / 0263 | Iter Loss 0.1196 | Iter Mean Loss 0.1208\n",
      "CF Training: Epoch 0004 Iter 0220 / 0263 | Iter Loss 0.0225 | Iter Mean Loss 0.0289\n",
      "KG Training: Epoch 0004 Iter 0220 / 0263 | Iter Loss 0.1105 | Iter Mean Loss 0.1152\n",
      "CL Training: Epoch 0004 Iter 0220 / 0263 | Iter Loss 0.1194 | Iter Mean Loss 0.1207\n",
      "CF Training: Epoch 0004 Iter 0240 / 0263 | Iter Loss 0.0285 | Iter Mean Loss 0.0290\n",
      "KG Training: Epoch 0004 Iter 0240 / 0263 | Iter Loss 0.1112 | Iter Mean Loss 0.1147\n",
      "CL Training: Epoch 0004 Iter 0240 / 0263 | Iter Loss 0.1187 | Iter Mean Loss 0.1205\n",
      "CF Training: Epoch 0004 Iter 0260 / 0263 | Iter Loss 0.0273 | Iter Mean Loss 0.0289\n",
      "KG Training: Epoch 0004 Iter 0260 / 0263 | Iter Loss 0.1193 | Iter Mean Loss 0.1151\n",
      "CL Training: Epoch 0004 Iter 0260 / 0263 | Iter Loss 0.1190 | Iter Mean Loss 0.1204\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.947957 s\n",
      "Measure time: 0.017835 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 5, Hit Ratio:0.20134  |  Precision:0.12399  |  Recall:0.20363  |  NDCG:0.21226\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 5, Hit Ratio:0.20134  |  Precision:0.12399  |  Recall:0.20363  |  NDCG:0.21226\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0005 Iter 0000 / 0263 | Iter Loss 0.0282 | Iter Mean Loss 0.0282\n",
      "KG Training: Epoch 0005 Iter 0000 / 0263 | Iter Loss 0.0807 | Iter Mean Loss 0.0807\n",
      "CL Training: Epoch 0005 Iter 0000 / 0263 | Iter Loss 0.1193 | Iter Mean Loss 0.1193\n",
      "CF Training: Epoch 0005 Iter 0020 / 0263 | Iter Loss 0.0307 | Iter Mean Loss 0.0271\n",
      "KG Training: Epoch 0005 Iter 0020 / 0263 | Iter Loss 0.0992 | Iter Mean Loss 0.0929\n",
      "CL Training: Epoch 0005 Iter 0020 / 0263 | Iter Loss 0.1196 | Iter Mean Loss 0.1193\n",
      "CF Training: Epoch 0005 Iter 0040 / 0263 | Iter Loss 0.0255 | Iter Mean Loss 0.0268\n",
      "KG Training: Epoch 0005 Iter 0040 / 0263 | Iter Loss 0.0998 | Iter Mean Loss 0.0960\n",
      "CL Training: Epoch 0005 Iter 0040 / 0263 | Iter Loss 0.1189 | Iter Mean Loss 0.1193\n",
      "CF Training: Epoch 0005 Iter 0060 / 0263 | Iter Loss 0.0244 | Iter Mean Loss 0.0266\n",
      "KG Training: Epoch 0005 Iter 0060 / 0263 | Iter Loss 0.1016 | Iter Mean Loss 0.0975\n",
      "CL Training: Epoch 0005 Iter 0060 / 0263 | Iter Loss 0.1189 | Iter Mean Loss 0.1192\n",
      "CF Training: Epoch 0005 Iter 0080 / 0263 | Iter Loss 0.0248 | Iter Mean Loss 0.0272\n",
      "KG Training: Epoch 0005 Iter 0080 / 0263 | Iter Loss 0.1011 | Iter Mean Loss 0.0985\n",
      "CL Training: Epoch 0005 Iter 0080 / 0263 | Iter Loss 0.1188 | Iter Mean Loss 0.1190\n",
      "CF Training: Epoch 0005 Iter 0100 / 0263 | Iter Loss 0.0218 | Iter Mean Loss 0.0270\n",
      "KG Training: Epoch 0005 Iter 0100 / 0263 | Iter Loss 0.0998 | Iter Mean Loss 0.0989\n",
      "CL Training: Epoch 0005 Iter 0100 / 0263 | Iter Loss 0.1184 | Iter Mean Loss 0.1189\n",
      "CF Training: Epoch 0005 Iter 0120 / 0263 | Iter Loss 0.0323 | Iter Mean Loss 0.0271\n",
      "KG Training: Epoch 0005 Iter 0120 / 0263 | Iter Loss 0.0920 | Iter Mean Loss 0.0986\n",
      "CL Training: Epoch 0005 Iter 0120 / 0263 | Iter Loss 0.1183 | Iter Mean Loss 0.1188\n",
      "CF Training: Epoch 0005 Iter 0140 / 0263 | Iter Loss 0.0226 | Iter Mean Loss 0.0270\n",
      "KG Training: Epoch 0005 Iter 0140 / 0263 | Iter Loss 0.0931 | Iter Mean Loss 0.0980\n",
      "CL Training: Epoch 0005 Iter 0140 / 0263 | Iter Loss 0.1176 | Iter Mean Loss 0.1187\n",
      "CF Training: Epoch 0005 Iter 0160 / 0263 | Iter Loss 0.0287 | Iter Mean Loss 0.0268\n",
      "KG Training: Epoch 0005 Iter 0160 / 0263 | Iter Loss 0.0976 | Iter Mean Loss 0.0977\n",
      "CL Training: Epoch 0005 Iter 0160 / 0263 | Iter Loss 0.1176 | Iter Mean Loss 0.1185\n",
      "CF Training: Epoch 0005 Iter 0180 / 0263 | Iter Loss 0.0327 | Iter Mean Loss 0.0267\n",
      "KG Training: Epoch 0005 Iter 0180 / 0263 | Iter Loss 0.0991 | Iter Mean Loss 0.0977\n",
      "CL Training: Epoch 0005 Iter 0180 / 0263 | Iter Loss 0.1171 | Iter Mean Loss 0.1185\n",
      "CF Training: Epoch 0005 Iter 0200 / 0263 | Iter Loss 0.0277 | Iter Mean Loss 0.0265\n",
      "KG Training: Epoch 0005 Iter 0200 / 0263 | Iter Loss 0.0938 | Iter Mean Loss 0.0977\n",
      "CL Training: Epoch 0005 Iter 0200 / 0263 | Iter Loss 0.1172 | Iter Mean Loss 0.1183\n",
      "CF Training: Epoch 0005 Iter 0220 / 0263 | Iter Loss 0.0275 | Iter Mean Loss 0.0265\n",
      "KG Training: Epoch 0005 Iter 0220 / 0263 | Iter Loss 0.0976 | Iter Mean Loss 0.0979\n",
      "CL Training: Epoch 0005 Iter 0220 / 0263 | Iter Loss 0.1172 | Iter Mean Loss 0.1183\n",
      "CF Training: Epoch 0005 Iter 0240 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0263\n",
      "KG Training: Epoch 0005 Iter 0240 / 0263 | Iter Loss 0.1013 | Iter Mean Loss 0.0978\n",
      "CL Training: Epoch 0005 Iter 0240 / 0263 | Iter Loss 0.1174 | Iter Mean Loss 0.1182\n",
      "CF Training: Epoch 0005 Iter 0260 / 0263 | Iter Loss 0.0272 | Iter Mean Loss 0.0263\n",
      "KG Training: Epoch 0005 Iter 0260 / 0263 | Iter Loss 0.1142 | Iter Mean Loss 0.0984\n",
      "CL Training: Epoch 0005 Iter 0260 / 0263 | Iter Loss 0.1167 | Iter Mean Loss 0.1181\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.919520 s\n",
      "Measure time: 0.017554 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 6, Hit Ratio:0.20711  |  Precision:0.12755  |  Recall:0.21018  |  NDCG:0.22247\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 6, Hit Ratio:0.20711  |  Precision:0.12755  |  Recall:0.21018  |  NDCG:0.22247\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0006 Iter 0000 / 0263 | Iter Loss 0.0247 | Iter Mean Loss 0.0247\n",
      "KG Training: Epoch 0006 Iter 0000 / 0263 | Iter Loss 0.0639 | Iter Mean Loss 0.0639\n",
      "CL Training: Epoch 0006 Iter 0000 / 0263 | Iter Loss 0.1168 | Iter Mean Loss 0.1168\n",
      "CF Training: Epoch 0006 Iter 0020 / 0263 | Iter Loss 0.0254 | Iter Mean Loss 0.0242\n",
      "KG Training: Epoch 0006 Iter 0020 / 0263 | Iter Loss 0.0806 | Iter Mean Loss 0.0761\n",
      "CL Training: Epoch 0006 Iter 0020 / 0263 | Iter Loss 0.1172 | Iter Mean Loss 0.1172\n",
      "CF Training: Epoch 0006 Iter 0040 / 0263 | Iter Loss 0.0247 | Iter Mean Loss 0.0246\n",
      "KG Training: Epoch 0006 Iter 0040 / 0263 | Iter Loss 0.0870 | Iter Mean Loss 0.0799\n",
      "CL Training: Epoch 0006 Iter 0040 / 0263 | Iter Loss 0.1169 | Iter Mean Loss 0.1172\n",
      "CF Training: Epoch 0006 Iter 0060 / 0263 | Iter Loss 0.0242 | Iter Mean Loss 0.0249\n",
      "KG Training: Epoch 0006 Iter 0060 / 0263 | Iter Loss 0.0895 | Iter Mean Loss 0.0820\n",
      "CL Training: Epoch 0006 Iter 0060 / 0263 | Iter Loss 0.1167 | Iter Mean Loss 0.1171\n",
      "CF Training: Epoch 0006 Iter 0080 / 0263 | Iter Loss 0.0278 | Iter Mean Loss 0.0254\n",
      "KG Training: Epoch 0006 Iter 0080 / 0263 | Iter Loss 0.0915 | Iter Mean Loss 0.0833\n",
      "CL Training: Epoch 0006 Iter 0080 / 0263 | Iter Loss 0.1163 | Iter Mean Loss 0.1170\n",
      "CF Training: Epoch 0006 Iter 0100 / 0263 | Iter Loss 0.0257 | Iter Mean Loss 0.0257\n",
      "KG Training: Epoch 0006 Iter 0100 / 0263 | Iter Loss 0.0805 | Iter Mean Loss 0.0838\n",
      "CL Training: Epoch 0006 Iter 0100 / 0263 | Iter Loss 0.1163 | Iter Mean Loss 0.1168\n",
      "CF Training: Epoch 0006 Iter 0120 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0255\n",
      "KG Training: Epoch 0006 Iter 0120 / 0263 | Iter Loss 0.0847 | Iter Mean Loss 0.0840\n",
      "CL Training: Epoch 0006 Iter 0120 / 0263 | Iter Loss 0.1159 | Iter Mean Loss 0.1167\n",
      "CF Training: Epoch 0006 Iter 0140 / 0263 | Iter Loss 0.0249 | Iter Mean Loss 0.0255\n",
      "KG Training: Epoch 0006 Iter 0140 / 0263 | Iter Loss 0.0814 | Iter Mean Loss 0.0840\n",
      "CL Training: Epoch 0006 Iter 0140 / 0263 | Iter Loss 0.1159 | Iter Mean Loss 0.1166\n",
      "CF Training: Epoch 0006 Iter 0160 / 0263 | Iter Loss 0.0251 | Iter Mean Loss 0.0255\n",
      "KG Training: Epoch 0006 Iter 0160 / 0263 | Iter Loss 0.0796 | Iter Mean Loss 0.0842\n",
      "CL Training: Epoch 0006 Iter 0160 / 0263 | Iter Loss 0.1161 | Iter Mean Loss 0.1165\n",
      "CF Training: Epoch 0006 Iter 0180 / 0263 | Iter Loss 0.0293 | Iter Mean Loss 0.0254\n",
      "KG Training: Epoch 0006 Iter 0180 / 0263 | Iter Loss 0.0887 | Iter Mean Loss 0.0846\n",
      "CL Training: Epoch 0006 Iter 0180 / 0263 | Iter Loss 0.1155 | Iter Mean Loss 0.1165\n",
      "CF Training: Epoch 0006 Iter 0200 / 0263 | Iter Loss 0.0163 | Iter Mean Loss 0.0252\n",
      "KG Training: Epoch 0006 Iter 0200 / 0263 | Iter Loss 0.0940 | Iter Mean Loss 0.0851\n",
      "CL Training: Epoch 0006 Iter 0200 / 0263 | Iter Loss 0.1155 | Iter Mean Loss 0.1164\n",
      "CF Training: Epoch 0006 Iter 0220 / 0263 | Iter Loss 0.0204 | Iter Mean Loss 0.0251\n",
      "KG Training: Epoch 0006 Iter 0220 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0856\n",
      "CL Training: Epoch 0006 Iter 0220 / 0263 | Iter Loss 0.1155 | Iter Mean Loss 0.1163\n",
      "CF Training: Epoch 0006 Iter 0240 / 0263 | Iter Loss 0.0234 | Iter Mean Loss 0.0251\n",
      "KG Training: Epoch 0006 Iter 0240 / 0263 | Iter Loss 0.0885 | Iter Mean Loss 0.0860\n",
      "CL Training: Epoch 0006 Iter 0240 / 0263 | Iter Loss 0.1150 | Iter Mean Loss 0.1162\n",
      "CF Training: Epoch 0006 Iter 0260 / 0263 | Iter Loss 0.0243 | Iter Mean Loss 0.0251\n",
      "KG Training: Epoch 0006 Iter 0260 / 0263 | Iter Loss 0.1025 | Iter Mean Loss 0.0869\n",
      "CL Training: Epoch 0006 Iter 0260 / 0263 | Iter Loss 0.1150 | Iter Mean Loss 0.1161\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.953794 s\n",
      "Measure time: 0.017915 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 7, Hit Ratio:0.20715  |  Precision:0.12757  |  Recall:0.20984  |  NDCG:0.22467\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 7, Hit Ratio:0.20715  |  Precision:0.12757  |  Recall:0.20984  |  NDCG:0.22467\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0007 Iter 0000 / 0263 | Iter Loss 0.0274 | Iter Mean Loss 0.0274\n",
      "KG Training: Epoch 0007 Iter 0000 / 0263 | Iter Loss 0.0602 | Iter Mean Loss 0.0602\n",
      "CL Training: Epoch 0007 Iter 0000 / 0263 | Iter Loss 0.1150 | Iter Mean Loss 0.1150\n",
      "CF Training: Epoch 0007 Iter 0020 / 0263 | Iter Loss 0.0235 | Iter Mean Loss 0.0256\n",
      "KG Training: Epoch 0007 Iter 0020 / 0263 | Iter Loss 0.0772 | Iter Mean Loss 0.0679\n",
      "CL Training: Epoch 0007 Iter 0020 / 0263 | Iter Loss 0.1154 | Iter Mean Loss 0.1155\n",
      "CF Training: Epoch 0007 Iter 0040 / 0263 | Iter Loss 0.0245 | Iter Mean Loss 0.0256\n",
      "KG Training: Epoch 0007 Iter 0040 / 0263 | Iter Loss 0.0711 | Iter Mean Loss 0.0706\n",
      "CL Training: Epoch 0007 Iter 0040 / 0263 | Iter Loss 0.1155 | Iter Mean Loss 0.1154\n",
      "CF Training: Epoch 0007 Iter 0060 / 0263 | Iter Loss 0.0243 | Iter Mean Loss 0.0250\n",
      "KG Training: Epoch 0007 Iter 0060 / 0263 | Iter Loss 0.0787 | Iter Mean Loss 0.0723\n",
      "CL Training: Epoch 0007 Iter 0060 / 0263 | Iter Loss 0.1152 | Iter Mean Loss 0.1154\n",
      "CF Training: Epoch 0007 Iter 0080 / 0263 | Iter Loss 0.0237 | Iter Mean Loss 0.0249\n",
      "KG Training: Epoch 0007 Iter 0080 / 0263 | Iter Loss 0.0841 | Iter Mean Loss 0.0736\n",
      "CL Training: Epoch 0007 Iter 0080 / 0263 | Iter Loss 0.1151 | Iter Mean Loss 0.1153\n",
      "CF Training: Epoch 0007 Iter 0100 / 0263 | Iter Loss 0.0279 | Iter Mean Loss 0.0246\n",
      "KG Training: Epoch 0007 Iter 0100 / 0263 | Iter Loss 0.0775 | Iter Mean Loss 0.0742\n",
      "CL Training: Epoch 0007 Iter 0100 / 0263 | Iter Loss 0.1144 | Iter Mean Loss 0.1152\n",
      "CF Training: Epoch 0007 Iter 0120 / 0263 | Iter Loss 0.0260 | Iter Mean Loss 0.0245\n",
      "KG Training: Epoch 0007 Iter 0120 / 0263 | Iter Loss 0.0797 | Iter Mean Loss 0.0746\n",
      "CL Training: Epoch 0007 Iter 0120 / 0263 | Iter Loss 0.1142 | Iter Mean Loss 0.1151\n",
      "CF Training: Epoch 0007 Iter 0140 / 0263 | Iter Loss 0.0185 | Iter Mean Loss 0.0244\n",
      "KG Training: Epoch 0007 Iter 0140 / 0263 | Iter Loss 0.0763 | Iter Mean Loss 0.0748\n",
      "CL Training: Epoch 0007 Iter 0140 / 0263 | Iter Loss 0.1144 | Iter Mean Loss 0.1150\n",
      "CF Training: Epoch 0007 Iter 0160 / 0263 | Iter Loss 0.0276 | Iter Mean Loss 0.0245\n",
      "KG Training: Epoch 0007 Iter 0160 / 0263 | Iter Loss 0.0864 | Iter Mean Loss 0.0754\n",
      "CL Training: Epoch 0007 Iter 0160 / 0263 | Iter Loss 0.1141 | Iter Mean Loss 0.1149\n",
      "CF Training: Epoch 0007 Iter 0180 / 0263 | Iter Loss 0.0290 | Iter Mean Loss 0.0246\n",
      "KG Training: Epoch 0007 Iter 0180 / 0263 | Iter Loss 0.0878 | Iter Mean Loss 0.0760\n",
      "CL Training: Epoch 0007 Iter 0180 / 0263 | Iter Loss 0.1141 | Iter Mean Loss 0.1148\n",
      "CF Training: Epoch 0007 Iter 0200 / 0263 | Iter Loss 0.0199 | Iter Mean Loss 0.0245\n",
      "KG Training: Epoch 0007 Iter 0200 / 0263 | Iter Loss 0.0819 | Iter Mean Loss 0.0768\n",
      "CL Training: Epoch 0007 Iter 0200 / 0263 | Iter Loss 0.1140 | Iter Mean Loss 0.1148\n",
      "CF Training: Epoch 0007 Iter 0220 / 0263 | Iter Loss 0.0349 | Iter Mean Loss 0.0245\n",
      "KG Training: Epoch 0007 Iter 0220 / 0263 | Iter Loss 0.0818 | Iter Mean Loss 0.0774\n",
      "CL Training: Epoch 0007 Iter 0220 / 0263 | Iter Loss 0.1141 | Iter Mean Loss 0.1147\n",
      "CF Training: Epoch 0007 Iter 0240 / 0263 | Iter Loss 0.0282 | Iter Mean Loss 0.0244\n",
      "KG Training: Epoch 0007 Iter 0240 / 0263 | Iter Loss 0.0888 | Iter Mean Loss 0.0780\n",
      "CL Training: Epoch 0007 Iter 0240 / 0263 | Iter Loss 0.1137 | Iter Mean Loss 0.1146\n",
      "CF Training: Epoch 0007 Iter 0260 / 0263 | Iter Loss 0.0212 | Iter Mean Loss 0.0242\n",
      "KG Training: Epoch 0007 Iter 0260 / 0263 | Iter Loss 0.1048 | Iter Mean Loss 0.0791\n",
      "CL Training: Epoch 0007 Iter 0260 / 0263 | Iter Loss 0.1134 | Iter Mean Loss 0.1145\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.820826 s\n",
      "Measure time: 0.017501 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 8, Hit Ratio:0.20858  |  Precision:0.12845  |  Recall:0.21109  |  NDCG:0.22096\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 8, Hit Ratio:0.20858  |  Precision:0.12845  |  Recall:0.21109  |  NDCG:0.22096\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0008 Iter 0000 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0008 Iter 0000 / 0263 | Iter Loss 0.0491 | Iter Mean Loss 0.0491\n",
      "CL Training: Epoch 0008 Iter 0000 / 0263 | Iter Loss 0.1138 | Iter Mean Loss 0.1138\n",
      "CF Training: Epoch 0008 Iter 0020 / 0263 | Iter Loss 0.0216 | Iter Mean Loss 0.0227\n",
      "KG Training: Epoch 0008 Iter 0020 / 0263 | Iter Loss 0.0675 | Iter Mean Loss 0.0603\n",
      "CL Training: Epoch 0008 Iter 0020 / 0263 | Iter Loss 0.1140 | Iter Mean Loss 0.1139\n",
      "CF Training: Epoch 0008 Iter 0040 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0223\n",
      "KG Training: Epoch 0008 Iter 0040 / 0263 | Iter Loss 0.0619 | Iter Mean Loss 0.0627\n",
      "CL Training: Epoch 0008 Iter 0040 / 0263 | Iter Loss 0.1140 | Iter Mean Loss 0.1139\n",
      "CF Training: Epoch 0008 Iter 0060 / 0263 | Iter Loss 0.0243 | Iter Mean Loss 0.0223\n",
      "KG Training: Epoch 0008 Iter 0060 / 0263 | Iter Loss 0.0662 | Iter Mean Loss 0.0645\n",
      "CL Training: Epoch 0008 Iter 0060 / 0263 | Iter Loss 0.1135 | Iter Mean Loss 0.1138\n",
      "CF Training: Epoch 0008 Iter 0080 / 0263 | Iter Loss 0.0295 | Iter Mean Loss 0.0228\n",
      "KG Training: Epoch 0008 Iter 0080 / 0263 | Iter Loss 0.0666 | Iter Mean Loss 0.0659\n",
      "CL Training: Epoch 0008 Iter 0080 / 0263 | Iter Loss 0.1134 | Iter Mean Loss 0.1137\n",
      "CF Training: Epoch 0008 Iter 0100 / 0263 | Iter Loss 0.0220 | Iter Mean Loss 0.0227\n",
      "KG Training: Epoch 0008 Iter 0100 / 0263 | Iter Loss 0.0680 | Iter Mean Loss 0.0669\n",
      "CL Training: Epoch 0008 Iter 0100 / 0263 | Iter Loss 0.1132 | Iter Mean Loss 0.1136\n",
      "CF Training: Epoch 0008 Iter 0120 / 0263 | Iter Loss 0.0257 | Iter Mean Loss 0.0229\n",
      "KG Training: Epoch 0008 Iter 0120 / 0263 | Iter Loss 0.0698 | Iter Mean Loss 0.0676\n",
      "CL Training: Epoch 0008 Iter 0120 / 0263 | Iter Loss 0.1127 | Iter Mean Loss 0.1136\n",
      "CF Training: Epoch 0008 Iter 0140 / 0263 | Iter Loss 0.0241 | Iter Mean Loss 0.0230\n",
      "KG Training: Epoch 0008 Iter 0140 / 0263 | Iter Loss 0.0725 | Iter Mean Loss 0.0682\n",
      "CL Training: Epoch 0008 Iter 0140 / 0263 | Iter Loss 0.1129 | Iter Mean Loss 0.1135\n",
      "CF Training: Epoch 0008 Iter 0160 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0228\n",
      "KG Training: Epoch 0008 Iter 0160 / 0263 | Iter Loss 0.0762 | Iter Mean Loss 0.0689\n",
      "CL Training: Epoch 0008 Iter 0160 / 0263 | Iter Loss 0.1130 | Iter Mean Loss 0.1134\n",
      "CF Training: Epoch 0008 Iter 0180 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0229\n",
      "KG Training: Epoch 0008 Iter 0180 / 0263 | Iter Loss 0.0722 | Iter Mean Loss 0.0696\n",
      "CL Training: Epoch 0008 Iter 0180 / 0263 | Iter Loss 0.1124 | Iter Mean Loss 0.1133\n",
      "CF Training: Epoch 0008 Iter 0200 / 0263 | Iter Loss 0.0234 | Iter Mean Loss 0.0229\n",
      "KG Training: Epoch 0008 Iter 0200 / 0263 | Iter Loss 0.0821 | Iter Mean Loss 0.0703\n",
      "CL Training: Epoch 0008 Iter 0200 / 0263 | Iter Loss 0.1123 | Iter Mean Loss 0.1133\n",
      "CF Training: Epoch 0008 Iter 0220 / 0263 | Iter Loss 0.0250 | Iter Mean Loss 0.0229\n",
      "KG Training: Epoch 0008 Iter 0220 / 0263 | Iter Loss 0.0821 | Iter Mean Loss 0.0710\n",
      "CL Training: Epoch 0008 Iter 0220 / 0263 | Iter Loss 0.1124 | Iter Mean Loss 0.1132\n",
      "CF Training: Epoch 0008 Iter 0240 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0230\n",
      "KG Training: Epoch 0008 Iter 0240 / 0263 | Iter Loss 0.0797 | Iter Mean Loss 0.0717\n",
      "CL Training: Epoch 0008 Iter 0240 / 0263 | Iter Loss 0.1125 | Iter Mean Loss 0.1131\n",
      "CF Training: Epoch 0008 Iter 0260 / 0263 | Iter Loss 0.0196 | Iter Mean Loss 0.0230\n",
      "KG Training: Epoch 0008 Iter 0260 / 0263 | Iter Loss 0.0881 | Iter Mean Loss 0.0727\n",
      "CL Training: Epoch 0008 Iter 0260 / 0263 | Iter Loss 0.1122 | Iter Mean Loss 0.1131\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.886048 s\n",
      "Measure time: 0.017516 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 9, Hit Ratio:0.20142  |  Precision:0.12404  |  Recall:0.20374  |  NDCG:0.21319\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 8, Hit Ratio:0.20858  |  Precision:0.12845  |  Recall:0.21109  |  NDCG:0.22096\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0009 Iter 0000 / 0263 | Iter Loss 0.0224 | Iter Mean Loss 0.0224\n",
      "KG Training: Epoch 0009 Iter 0000 / 0263 | Iter Loss 0.0500 | Iter Mean Loss 0.0500\n",
      "CL Training: Epoch 0009 Iter 0000 / 0263 | Iter Loss 0.1126 | Iter Mean Loss 0.1126\n",
      "CF Training: Epoch 0009 Iter 0020 / 0263 | Iter Loss 0.0213 | Iter Mean Loss 0.0215\n",
      "KG Training: Epoch 0009 Iter 0020 / 0263 | Iter Loss 0.0551 | Iter Mean Loss 0.0545\n",
      "CL Training: Epoch 0009 Iter 0020 / 0263 | Iter Loss 0.1127 | Iter Mean Loss 0.1127\n",
      "CF Training: Epoch 0009 Iter 0040 / 0263 | Iter Loss 0.0214 | Iter Mean Loss 0.0225\n",
      "KG Training: Epoch 0009 Iter 0040 / 0263 | Iter Loss 0.0580 | Iter Mean Loss 0.0572\n",
      "CL Training: Epoch 0009 Iter 0040 / 0263 | Iter Loss 0.1124 | Iter Mean Loss 0.1127\n",
      "CF Training: Epoch 0009 Iter 0060 / 0263 | Iter Loss 0.0231 | Iter Mean Loss 0.0224\n",
      "KG Training: Epoch 0009 Iter 0060 / 0263 | Iter Loss 0.0603 | Iter Mean Loss 0.0587\n",
      "CL Training: Epoch 0009 Iter 0060 / 0263 | Iter Loss 0.1119 | Iter Mean Loss 0.1126\n",
      "CF Training: Epoch 0009 Iter 0080 / 0263 | Iter Loss 0.0218 | Iter Mean Loss 0.0227\n",
      "KG Training: Epoch 0009 Iter 0080 / 0263 | Iter Loss 0.0647 | Iter Mean Loss 0.0598\n",
      "CL Training: Epoch 0009 Iter 0080 / 0263 | Iter Loss 0.1118 | Iter Mean Loss 0.1125\n",
      "CF Training: Epoch 0009 Iter 0100 / 0263 | Iter Loss 0.0298 | Iter Mean Loss 0.0228\n",
      "KG Training: Epoch 0009 Iter 0100 / 0263 | Iter Loss 0.0668 | Iter Mean Loss 0.0607\n",
      "CL Training: Epoch 0009 Iter 0100 / 0263 | Iter Loss 0.1120 | Iter Mean Loss 0.1124\n",
      "CF Training: Epoch 0009 Iter 0120 / 0263 | Iter Loss 0.0212 | Iter Mean Loss 0.0228\n",
      "KG Training: Epoch 0009 Iter 0120 / 0263 | Iter Loss 0.0664 | Iter Mean Loss 0.0615\n",
      "CL Training: Epoch 0009 Iter 0120 / 0263 | Iter Loss 0.1118 | Iter Mean Loss 0.1124\n",
      "CF Training: Epoch 0009 Iter 0140 / 0263 | Iter Loss 0.0173 | Iter Mean Loss 0.0226\n",
      "KG Training: Epoch 0009 Iter 0140 / 0263 | Iter Loss 0.0693 | Iter Mean Loss 0.0623\n",
      "CL Training: Epoch 0009 Iter 0140 / 0263 | Iter Loss 0.1116 | Iter Mean Loss 0.1123\n",
      "CF Training: Epoch 0009 Iter 0160 / 0263 | Iter Loss 0.0295 | Iter Mean Loss 0.0226\n",
      "KG Training: Epoch 0009 Iter 0160 / 0263 | Iter Loss 0.0697 | Iter Mean Loss 0.0631\n",
      "CL Training: Epoch 0009 Iter 0160 / 0263 | Iter Loss 0.1116 | Iter Mean Loss 0.1122\n",
      "CF Training: Epoch 0009 Iter 0180 / 0263 | Iter Loss 0.0204 | Iter Mean Loss 0.0225\n",
      "KG Training: Epoch 0009 Iter 0180 / 0263 | Iter Loss 0.0725 | Iter Mean Loss 0.0640\n",
      "CL Training: Epoch 0009 Iter 0180 / 0263 | Iter Loss 0.1119 | Iter Mean Loss 0.1121\n",
      "CF Training: Epoch 0009 Iter 0200 / 0263 | Iter Loss 0.0268 | Iter Mean Loss 0.0226\n",
      "KG Training: Epoch 0009 Iter 0200 / 0263 | Iter Loss 0.0656 | Iter Mean Loss 0.0647\n",
      "CL Training: Epoch 0009 Iter 0200 / 0263 | Iter Loss 0.1115 | Iter Mean Loss 0.1121\n",
      "CF Training: Epoch 0009 Iter 0220 / 0263 | Iter Loss 0.0271 | Iter Mean Loss 0.0225\n",
      "KG Training: Epoch 0009 Iter 0220 / 0263 | Iter Loss 0.0722 | Iter Mean Loss 0.0656\n",
      "CL Training: Epoch 0009 Iter 0220 / 0263 | Iter Loss 0.1117 | Iter Mean Loss 0.1120\n",
      "CF Training: Epoch 0009 Iter 0240 / 0263 | Iter Loss 0.0163 | Iter Mean Loss 0.0225\n",
      "KG Training: Epoch 0009 Iter 0240 / 0263 | Iter Loss 0.0796 | Iter Mean Loss 0.0665\n",
      "CL Training: Epoch 0009 Iter 0240 / 0263 | Iter Loss 0.1113 | Iter Mean Loss 0.1120\n",
      "CF Training: Epoch 0009 Iter 0260 / 0263 | Iter Loss 0.0201 | Iter Mean Loss 0.0225\n",
      "KG Training: Epoch 0009 Iter 0260 / 0263 | Iter Loss 0.0868 | Iter Mean Loss 0.0677\n",
      "CL Training: Epoch 0009 Iter 0260 / 0263 | Iter Loss 0.1112 | Iter Mean Loss 0.1119\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.945708 s\n",
      "Measure time: 0.017661 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 10, Hit Ratio:0.20457  |  Precision:0.12598  |  Recall:0.20685  |  NDCG:0.21485\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 8, Hit Ratio:0.20858  |  Precision:0.12845  |  Recall:0.21109  |  NDCG:0.22096\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0010 Iter 0000 / 0263 | Iter Loss 0.0225 | Iter Mean Loss 0.0225\n",
      "KG Training: Epoch 0010 Iter 0000 / 0263 | Iter Loss 0.0441 | Iter Mean Loss 0.0441\n",
      "CL Training: Epoch 0010 Iter 0000 / 0263 | Iter Loss 0.1113 | Iter Mean Loss 0.1113\n",
      "CF Training: Epoch 0010 Iter 0020 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0227\n",
      "KG Training: Epoch 0010 Iter 0020 / 0263 | Iter Loss 0.0554 | Iter Mean Loss 0.0497\n",
      "CL Training: Epoch 0010 Iter 0020 / 0263 | Iter Loss 0.1120 | Iter Mean Loss 0.1118\n",
      "CF Training: Epoch 0010 Iter 0040 / 0263 | Iter Loss 0.0195 | Iter Mean Loss 0.0220\n",
      "KG Training: Epoch 0010 Iter 0040 / 0263 | Iter Loss 0.0593 | Iter Mean Loss 0.0527\n",
      "CL Training: Epoch 0010 Iter 0040 / 0263 | Iter Loss 0.1114 | Iter Mean Loss 0.1118\n",
      "CF Training: Epoch 0010 Iter 0060 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0217\n",
      "KG Training: Epoch 0010 Iter 0060 / 0263 | Iter Loss 0.0562 | Iter Mean Loss 0.0541\n",
      "CL Training: Epoch 0010 Iter 0060 / 0263 | Iter Loss 0.1109 | Iter Mean Loss 0.1116\n",
      "CF Training: Epoch 0010 Iter 0080 / 0263 | Iter Loss 0.0250 | Iter Mean Loss 0.0222\n",
      "KG Training: Epoch 0010 Iter 0080 / 0263 | Iter Loss 0.0607 | Iter Mean Loss 0.0554\n",
      "CL Training: Epoch 0010 Iter 0080 / 0263 | Iter Loss 0.1114 | Iter Mean Loss 0.1115\n",
      "CF Training: Epoch 0010 Iter 0100 / 0263 | Iter Loss 0.0307 | Iter Mean Loss 0.0222\n",
      "KG Training: Epoch 0010 Iter 0100 / 0263 | Iter Loss 0.0561 | Iter Mean Loss 0.0565\n",
      "CL Training: Epoch 0010 Iter 0100 / 0263 | Iter Loss 0.1114 | Iter Mean Loss 0.1115\n",
      "CF Training: Epoch 0010 Iter 0120 / 0263 | Iter Loss 0.0197 | Iter Mean Loss 0.0220\n",
      "KG Training: Epoch 0010 Iter 0120 / 0263 | Iter Loss 0.0626 | Iter Mean Loss 0.0574\n",
      "CL Training: Epoch 0010 Iter 0120 / 0263 | Iter Loss 0.1112 | Iter Mean Loss 0.1114\n",
      "CF Training: Epoch 0010 Iter 0140 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0220\n",
      "KG Training: Epoch 0010 Iter 0140 / 0263 | Iter Loss 0.0637 | Iter Mean Loss 0.0581\n",
      "CL Training: Epoch 0010 Iter 0140 / 0263 | Iter Loss 0.1106 | Iter Mean Loss 0.1113\n",
      "CF Training: Epoch 0010 Iter 0160 / 0263 | Iter Loss 0.0303 | Iter Mean Loss 0.0220\n",
      "KG Training: Epoch 0010 Iter 0160 / 0263 | Iter Loss 0.0723 | Iter Mean Loss 0.0589\n",
      "CL Training: Epoch 0010 Iter 0160 / 0263 | Iter Loss 0.1108 | Iter Mean Loss 0.1112\n",
      "CF Training: Epoch 0010 Iter 0180 / 0263 | Iter Loss 0.0213 | Iter Mean Loss 0.0221\n",
      "KG Training: Epoch 0010 Iter 0180 / 0263 | Iter Loss 0.0684 | Iter Mean Loss 0.0599\n",
      "CL Training: Epoch 0010 Iter 0180 / 0263 | Iter Loss 0.1109 | Iter Mean Loss 0.1112\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.955056 s\n",
      "Measure time: 0.017807 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 11, Hit Ratio:0.20702  |  Precision:0.12749  |  Recall:0.20919  |  NDCG:0.22002\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 8, Hit Ratio:0.20858  |  Precision:0.12845  |  Recall:0.21109  |  NDCG:0.22096\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0011 Iter 0000 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0011 Iter 0000 / 0263 | Iter Loss 0.0409 | Iter Mean Loss 0.0409\n",
      "CL Training: Epoch 0011 Iter 0000 / 0263 | Iter Loss 0.1106 | Iter Mean Loss 0.1106\n",
      "CF Training: Epoch 0011 Iter 0020 / 0263 | Iter Loss 0.0243 | Iter Mean Loss 0.0197\n",
      "KG Training: Epoch 0011 Iter 0020 / 0263 | Iter Loss 0.0535 | Iter Mean Loss 0.0467\n",
      "CL Training: Epoch 0011 Iter 0020 / 0263 | Iter Loss 0.1109 | Iter Mean Loss 0.1107\n",
      "CF Training: Epoch 0011 Iter 0040 / 0263 | Iter Loss 0.0274 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0011 Iter 0040 / 0263 | Iter Loss 0.0513 | Iter Mean Loss 0.0497\n",
      "CL Training: Epoch 0011 Iter 0040 / 0263 | Iter Loss 0.1108 | Iter Mean Loss 0.1107\n",
      "CF Training: Epoch 0011 Iter 0060 / 0263 | Iter Loss 0.0199 | Iter Mean Loss 0.0213\n",
      "KG Training: Epoch 0011 Iter 0060 / 0263 | Iter Loss 0.0575 | Iter Mean Loss 0.0508\n",
      "CL Training: Epoch 0011 Iter 0060 / 0263 | Iter Loss 0.1107 | Iter Mean Loss 0.1106\n",
      "CF Training: Epoch 0011 Iter 0080 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0215\n",
      "KG Training: Epoch 0011 Iter 0080 / 0263 | Iter Loss 0.0576 | Iter Mean Loss 0.0520\n",
      "CL Training: Epoch 0011 Iter 0080 / 0263 | Iter Loss 0.1103 | Iter Mean Loss 0.1105\n",
      "CF Training: Epoch 0011 Iter 0100 / 0263 | Iter Loss 0.0188 | Iter Mean Loss 0.0214\n",
      "KG Training: Epoch 0011 Iter 0100 / 0263 | Iter Loss 0.0567 | Iter Mean Loss 0.0529\n",
      "CL Training: Epoch 0011 Iter 0100 / 0263 | Iter Loss 0.1100 | Iter Mean Loss 0.1104\n",
      "CF Training: Epoch 0011 Iter 0120 / 0263 | Iter Loss 0.0268 | Iter Mean Loss 0.0215\n",
      "KG Training: Epoch 0011 Iter 0120 / 0263 | Iter Loss 0.0593 | Iter Mean Loss 0.0540\n",
      "CL Training: Epoch 0011 Iter 0120 / 0263 | Iter Loss 0.1099 | Iter Mean Loss 0.1103\n",
      "CF Training: Epoch 0011 Iter 0140 / 0263 | Iter Loss 0.0219 | Iter Mean Loss 0.0215\n",
      "KG Training: Epoch 0011 Iter 0140 / 0263 | Iter Loss 0.0589 | Iter Mean Loss 0.0548\n",
      "CL Training: Epoch 0011 Iter 0140 / 0263 | Iter Loss 0.1100 | Iter Mean Loss 0.1103\n",
      "CF Training: Epoch 0011 Iter 0160 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0215\n",
      "KG Training: Epoch 0011 Iter 0160 / 0263 | Iter Loss 0.0621 | Iter Mean Loss 0.0557\n",
      "CL Training: Epoch 0011 Iter 0160 / 0263 | Iter Loss 0.1099 | Iter Mean Loss 0.1102\n",
      "CF Training: Epoch 0011 Iter 0180 / 0263 | Iter Loss 0.0206 | Iter Mean Loss 0.0216\n",
      "KG Training: Epoch 0011 Iter 0180 / 0263 | Iter Loss 0.0669 | Iter Mean Loss 0.0567\n",
      "CL Training: Epoch 0011 Iter 0180 / 0263 | Iter Loss 0.1101 | Iter Mean Loss 0.1102\n",
      "CF Training: Epoch 0011 Iter 0200 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0216\n",
      "KG Training: Epoch 0011 Iter 0200 / 0263 | Iter Loss 0.0727 | Iter Mean Loss 0.0576\n",
      "CL Training: Epoch 0011 Iter 0200 / 0263 | Iter Loss 0.1097 | Iter Mean Loss 0.1102\n",
      "CF Training: Epoch 0011 Iter 0220 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0215\n",
      "KG Training: Epoch 0011 Iter 0220 / 0263 | Iter Loss 0.0718 | Iter Mean Loss 0.0586\n",
      "CL Training: Epoch 0011 Iter 0220 / 0263 | Iter Loss 0.1096 | Iter Mean Loss 0.1101\n",
      "CF Training: Epoch 0011 Iter 0240 / 0263 | Iter Loss 0.0248 | Iter Mean Loss 0.0215\n",
      "KG Training: Epoch 0011 Iter 0240 / 0263 | Iter Loss 0.0706 | Iter Mean Loss 0.0596\n",
      "CL Training: Epoch 0011 Iter 0240 / 0263 | Iter Loss 0.1095 | Iter Mean Loss 0.1101\n",
      "CF Training: Epoch 0011 Iter 0260 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0215\n",
      "KG Training: Epoch 0011 Iter 0260 / 0263 | Iter Loss 0.0804 | Iter Mean Loss 0.0607\n",
      "CL Training: Epoch 0011 Iter 0260 / 0263 | Iter Loss 0.1098 | Iter Mean Loss 0.1101\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.950594 s\n",
      "Measure time: 0.017882 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 12, Hit Ratio:0.1981  |  Precision:0.122  |  Recall:0.20079  |  NDCG:0.20458\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 8, Hit Ratio:0.20858  |  Precision:0.12845  |  Recall:0.21109  |  NDCG:0.22096\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0012 Iter 0000 / 0263 | Iter Loss 0.0286 | Iter Mean Loss 0.0286\n",
      "KG Training: Epoch 0012 Iter 0000 / 0263 | Iter Loss 0.0378 | Iter Mean Loss 0.0378\n",
      "CL Training: Epoch 0012 Iter 0000 / 0263 | Iter Loss 0.1099 | Iter Mean Loss 0.1099\n",
      "CF Training: Epoch 0012 Iter 0020 / 0263 | Iter Loss 0.0196 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0012 Iter 0020 / 0263 | Iter Loss 0.0451 | Iter Mean Loss 0.0434\n",
      "CL Training: Epoch 0012 Iter 0020 / 0263 | Iter Loss 0.1101 | Iter Mean Loss 0.1100\n",
      "CF Training: Epoch 0012 Iter 0040 / 0263 | Iter Loss 0.0188 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0012 Iter 0040 / 0263 | Iter Loss 0.0514 | Iter Mean Loss 0.0462\n",
      "CL Training: Epoch 0012 Iter 0040 / 0263 | Iter Loss 0.1097 | Iter Mean Loss 0.1099\n",
      "CF Training: Epoch 0012 Iter 0060 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0012 Iter 0060 / 0263 | Iter Loss 0.0497 | Iter Mean Loss 0.0478\n",
      "CL Training: Epoch 0012 Iter 0060 / 0263 | Iter Loss 0.1093 | Iter Mean Loss 0.1098\n",
      "CF Training: Epoch 0012 Iter 0080 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0012 Iter 0080 / 0263 | Iter Loss 0.0538 | Iter Mean Loss 0.0489\n",
      "CL Training: Epoch 0012 Iter 0080 / 0263 | Iter Loss 0.1092 | Iter Mean Loss 0.1097\n",
      "CF Training: Epoch 0012 Iter 0100 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0012 Iter 0100 / 0263 | Iter Loss 0.0550 | Iter Mean Loss 0.0499\n",
      "CL Training: Epoch 0012 Iter 0100 / 0263 | Iter Loss 0.1093 | Iter Mean Loss 0.1096\n",
      "CF Training: Epoch 0012 Iter 0120 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0012 Iter 0120 / 0263 | Iter Loss 0.0615 | Iter Mean Loss 0.0507\n",
      "CL Training: Epoch 0012 Iter 0120 / 0263 | Iter Loss 0.1095 | Iter Mean Loss 0.1096\n",
      "CF Training: Epoch 0012 Iter 0140 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0210\n",
      "KG Training: Epoch 0012 Iter 0140 / 0263 | Iter Loss 0.0612 | Iter Mean Loss 0.0518\n",
      "CL Training: Epoch 0012 Iter 0140 / 0263 | Iter Loss 0.1095 | Iter Mean Loss 0.1096\n",
      "CF Training: Epoch 0012 Iter 0160 / 0263 | Iter Loss 0.0226 | Iter Mean Loss 0.0212\n",
      "KG Training: Epoch 0012 Iter 0160 / 0263 | Iter Loss 0.0595 | Iter Mean Loss 0.0529\n",
      "CL Training: Epoch 0012 Iter 0160 / 0263 | Iter Loss 0.1090 | Iter Mean Loss 0.1095\n",
      "CF Training: Epoch 0012 Iter 0180 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0214\n",
      "KG Training: Epoch 0012 Iter 0180 / 0263 | Iter Loss 0.0638 | Iter Mean Loss 0.0539\n",
      "CL Training: Epoch 0012 Iter 0180 / 0263 | Iter Loss 0.1091 | Iter Mean Loss 0.1095\n",
      "CF Training: Epoch 0012 Iter 0200 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0213\n",
      "KG Training: Epoch 0012 Iter 0200 / 0263 | Iter Loss 0.0662 | Iter Mean Loss 0.0548\n",
      "CL Training: Epoch 0012 Iter 0200 / 0263 | Iter Loss 0.1092 | Iter Mean Loss 0.1094\n",
      "CF Training: Epoch 0012 Iter 0220 / 0263 | Iter Loss 0.0225 | Iter Mean Loss 0.0213\n",
      "KG Training: Epoch 0012 Iter 0220 / 0263 | Iter Loss 0.0667 | Iter Mean Loss 0.0558\n",
      "CL Training: Epoch 0012 Iter 0220 / 0263 | Iter Loss 0.1092 | Iter Mean Loss 0.1094\n",
      "CF Training: Epoch 0012 Iter 0240 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0213\n",
      "KG Training: Epoch 0012 Iter 0240 / 0263 | Iter Loss 0.0668 | Iter Mean Loss 0.0569\n",
      "CL Training: Epoch 0012 Iter 0240 / 0263 | Iter Loss 0.1089 | Iter Mean Loss 0.1093\n",
      "CF Training: Epoch 0012 Iter 0260 / 0263 | Iter Loss 0.0299 | Iter Mean Loss 0.0212\n",
      "KG Training: Epoch 0012 Iter 0260 / 0263 | Iter Loss 0.0762 | Iter Mean Loss 0.0581\n",
      "CL Training: Epoch 0012 Iter 0260 / 0263 | Iter Loss 0.1091 | Iter Mean Loss 0.1093\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.845106 s\n",
      "Measure time: 0.020185 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 13, Hit Ratio:0.20939  |  Precision:0.12895  |  Recall:0.21137  |  NDCG:0.22177\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 13, Hit Ratio:0.20939  |  Precision:0.12895  |  Recall:0.21137  |  NDCG:0.22177\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0013 Iter 0000 / 0263 | Iter Loss 0.0188 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0013 Iter 0000 / 0263 | Iter Loss 0.0353 | Iter Mean Loss 0.0353\n",
      "CL Training: Epoch 0013 Iter 0000 / 0263 | Iter Loss 0.1087 | Iter Mean Loss 0.1087\n",
      "CF Training: Epoch 0013 Iter 0020 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0013 Iter 0020 / 0263 | Iter Loss 0.0441 | Iter Mean Loss 0.0421\n",
      "CL Training: Epoch 0013 Iter 0020 / 0263 | Iter Loss 0.1092 | Iter Mean Loss 0.1091\n",
      "CF Training: Epoch 0013 Iter 0040 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0197\n",
      "KG Training: Epoch 0013 Iter 0040 / 0263 | Iter Loss 0.0491 | Iter Mean Loss 0.0443\n",
      "CL Training: Epoch 0013 Iter 0040 / 0263 | Iter Loss 0.1089 | Iter Mean Loss 0.1091\n",
      "CF Training: Epoch 0013 Iter 0060 / 0263 | Iter Loss 0.0196 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0013 Iter 0060 / 0263 | Iter Loss 0.0508 | Iter Mean Loss 0.0459\n",
      "CL Training: Epoch 0013 Iter 0060 / 0263 | Iter Loss 0.1087 | Iter Mean Loss 0.1090\n",
      "CF Training: Epoch 0013 Iter 0080 / 0263 | Iter Loss 0.0134 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0013 Iter 0080 / 0263 | Iter Loss 0.0481 | Iter Mean Loss 0.0469\n",
      "CL Training: Epoch 0013 Iter 0080 / 0263 | Iter Loss 0.1085 | Iter Mean Loss 0.1089\n",
      "CF Training: Epoch 0013 Iter 0100 / 0263 | Iter Loss 0.0168 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0013 Iter 0100 / 0263 | Iter Loss 0.0499 | Iter Mean Loss 0.0476\n",
      "CL Training: Epoch 0013 Iter 0100 / 0263 | Iter Loss 0.1084 | Iter Mean Loss 0.1088\n",
      "CF Training: Epoch 0013 Iter 0120 / 0263 | Iter Loss 0.0150 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0013 Iter 0120 / 0263 | Iter Loss 0.0531 | Iter Mean Loss 0.0487\n",
      "CL Training: Epoch 0013 Iter 0120 / 0263 | Iter Loss 0.1083 | Iter Mean Loss 0.1088\n",
      "CF Training: Epoch 0013 Iter 0140 / 0263 | Iter Loss 0.0154 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0013 Iter 0140 / 0263 | Iter Loss 0.0528 | Iter Mean Loss 0.0496\n",
      "CL Training: Epoch 0013 Iter 0140 / 0263 | Iter Loss 0.1080 | Iter Mean Loss 0.1087\n",
      "CF Training: Epoch 0013 Iter 0160 / 0263 | Iter Loss 0.0167 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0013 Iter 0160 / 0263 | Iter Loss 0.0595 | Iter Mean Loss 0.0505\n",
      "CL Training: Epoch 0013 Iter 0160 / 0263 | Iter Loss 0.1081 | Iter Mean Loss 0.1086\n",
      "CF Training: Epoch 0013 Iter 0180 / 0263 | Iter Loss 0.0244 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0013 Iter 0180 / 0263 | Iter Loss 0.0634 | Iter Mean Loss 0.0516\n",
      "CL Training: Epoch 0013 Iter 0180 / 0263 | Iter Loss 0.1081 | Iter Mean Loss 0.1086\n",
      "CF Training: Epoch 0013 Iter 0200 / 0263 | Iter Loss 0.0197 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0013 Iter 0200 / 0263 | Iter Loss 0.0596 | Iter Mean Loss 0.0526\n",
      "CL Training: Epoch 0013 Iter 0200 / 0263 | Iter Loss 0.1082 | Iter Mean Loss 0.1085\n",
      "CF Training: Epoch 0013 Iter 0220 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0013 Iter 0220 / 0263 | Iter Loss 0.0618 | Iter Mean Loss 0.0536\n",
      "CL Training: Epoch 0013 Iter 0220 / 0263 | Iter Loss 0.1082 | Iter Mean Loss 0.1085\n",
      "CF Training: Epoch 0013 Iter 0240 / 0263 | Iter Loss 0.0231 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0013 Iter 0240 / 0263 | Iter Loss 0.0633 | Iter Mean Loss 0.0546\n",
      "CL Training: Epoch 0013 Iter 0240 / 0263 | Iter Loss 0.1082 | Iter Mean Loss 0.1085\n",
      "CF Training: Epoch 0013 Iter 0260 / 0263 | Iter Loss 0.0193 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0013 Iter 0260 / 0263 | Iter Loss 0.0810 | Iter Mean Loss 0.0558\n",
      "CL Training: Epoch 0013 Iter 0260 / 0263 | Iter Loss 0.1079 | Iter Mean Loss 0.1084\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.889441 s\n",
      "Measure time: 0.018013 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0014 Iter 0000 / 0263 | Iter Loss 0.0261 | Iter Mean Loss 0.0261\n",
      "KG Training: Epoch 0014 Iter 0000 / 0263 | Iter Loss 0.0356 | Iter Mean Loss 0.0356\n",
      "CL Training: Epoch 0014 Iter 0000 / 0263 | Iter Loss 0.1081 | Iter Mean Loss 0.1081\n",
      "CF Training: Epoch 0014 Iter 0020 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0217\n",
      "KG Training: Epoch 0014 Iter 0020 / 0263 | Iter Loss 0.0446 | Iter Mean Loss 0.0400\n",
      "CL Training: Epoch 0014 Iter 0020 / 0263 | Iter Loss 0.1083 | Iter Mean Loss 0.1085\n",
      "CF Training: Epoch 0014 Iter 0040 / 0263 | Iter Loss 0.0181 | Iter Mean Loss 0.0212\n",
      "KG Training: Epoch 0014 Iter 0040 / 0263 | Iter Loss 0.0438 | Iter Mean Loss 0.0424\n",
      "CL Training: Epoch 0014 Iter 0040 / 0263 | Iter Loss 0.1082 | Iter Mean Loss 0.1083\n",
      "CF Training: Epoch 0014 Iter 0060 / 0263 | Iter Loss 0.0204 | Iter Mean Loss 0.0216\n",
      "KG Training: Epoch 0014 Iter 0060 / 0263 | Iter Loss 0.0459 | Iter Mean Loss 0.0438\n",
      "CL Training: Epoch 0014 Iter 0060 / 0263 | Iter Loss 0.1079 | Iter Mean Loss 0.1082\n",
      "CF Training: Epoch 0014 Iter 0080 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0214\n",
      "KG Training: Epoch 0014 Iter 0080 / 0263 | Iter Loss 0.0483 | Iter Mean Loss 0.0447\n",
      "CL Training: Epoch 0014 Iter 0080 / 0263 | Iter Loss 0.1082 | Iter Mean Loss 0.1081\n",
      "CF Training: Epoch 0014 Iter 0100 / 0263 | Iter Loss 0.0123 | Iter Mean Loss 0.0210\n",
      "KG Training: Epoch 0014 Iter 0100 / 0263 | Iter Loss 0.0550 | Iter Mean Loss 0.0457\n",
      "CL Training: Epoch 0014 Iter 0100 / 0263 | Iter Loss 0.1081 | Iter Mean Loss 0.1080\n",
      "CF Training: Epoch 0014 Iter 0120 / 0263 | Iter Loss 0.0137 | Iter Mean Loss 0.0211\n",
      "KG Training: Epoch 0014 Iter 0120 / 0263 | Iter Loss 0.0514 | Iter Mean Loss 0.0467\n",
      "CL Training: Epoch 0014 Iter 0120 / 0263 | Iter Loss 0.1080 | Iter Mean Loss 0.1080\n",
      "CF Training: Epoch 0014 Iter 0140 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0210\n",
      "KG Training: Epoch 0014 Iter 0140 / 0263 | Iter Loss 0.0555 | Iter Mean Loss 0.0476\n",
      "CL Training: Epoch 0014 Iter 0140 / 0263 | Iter Loss 0.1078 | Iter Mean Loss 0.1079\n",
      "CF Training: Epoch 0014 Iter 0160 / 0263 | Iter Loss 0.0172 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0014 Iter 0160 / 0263 | Iter Loss 0.0544 | Iter Mean Loss 0.0487\n",
      "CL Training: Epoch 0014 Iter 0160 / 0263 | Iter Loss 0.1074 | Iter Mean Loss 0.1079\n",
      "CF Training: Epoch 0014 Iter 0180 / 0263 | Iter Loss 0.0239 | Iter Mean Loss 0.0210\n",
      "KG Training: Epoch 0014 Iter 0180 / 0263 | Iter Loss 0.0561 | Iter Mean Loss 0.0496\n",
      "CL Training: Epoch 0014 Iter 0180 / 0263 | Iter Loss 0.1073 | Iter Mean Loss 0.1078\n",
      "CF Training: Epoch 0014 Iter 0200 / 0263 | Iter Loss 0.0151 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0014 Iter 0200 / 0263 | Iter Loss 0.0601 | Iter Mean Loss 0.0506\n",
      "CL Training: Epoch 0014 Iter 0200 / 0263 | Iter Loss 0.1071 | Iter Mean Loss 0.1078\n",
      "CF Training: Epoch 0014 Iter 0220 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0014 Iter 0220 / 0263 | Iter Loss 0.0611 | Iter Mean Loss 0.0517\n",
      "CL Training: Epoch 0014 Iter 0220 / 0263 | Iter Loss 0.1073 | Iter Mean Loss 0.1077\n",
      "CF Training: Epoch 0014 Iter 0240 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0210\n",
      "KG Training: Epoch 0014 Iter 0240 / 0263 | Iter Loss 0.0653 | Iter Mean Loss 0.0527\n",
      "CL Training: Epoch 0014 Iter 0240 / 0263 | Iter Loss 0.1076 | Iter Mean Loss 0.1077\n",
      "CF Training: Epoch 0014 Iter 0260 / 0263 | Iter Loss 0.0223 | Iter Mean Loss 0.0210\n",
      "KG Training: Epoch 0014 Iter 0260 / 0263 | Iter Loss 0.0766 | Iter Mean Loss 0.0540\n",
      "CL Training: Epoch 0014 Iter 0260 / 0263 | Iter Loss 0.1075 | Iter Mean Loss 0.1077\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.839599 s\n",
      "Measure time: 0.019330 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 15, Hit Ratio:0.21043  |  Precision:0.12959  |  Recall:0.2126  |  NDCG:0.22168\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0015 Iter 0000 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0015 Iter 0000 / 0263 | Iter Loss 0.0345 | Iter Mean Loss 0.0345\n",
      "CL Training: Epoch 0015 Iter 0000 / 0263 | Iter Loss 0.1075 | Iter Mean Loss 0.1075\n",
      "CF Training: Epoch 0015 Iter 0020 / 0263 | Iter Loss 0.0250 | Iter Mean Loss 0.0210\n",
      "KG Training: Epoch 0015 Iter 0020 / 0263 | Iter Loss 0.0425 | Iter Mean Loss 0.0387\n",
      "CL Training: Epoch 0015 Iter 0020 / 0263 | Iter Loss 0.1078 | Iter Mean Loss 0.1077\n",
      "CF Training: Epoch 0015 Iter 0040 / 0263 | Iter Loss 0.0263 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0015 Iter 0040 / 0263 | Iter Loss 0.0423 | Iter Mean Loss 0.0407\n",
      "CL Training: Epoch 0015 Iter 0040 / 0263 | Iter Loss 0.1070 | Iter Mean Loss 0.1076\n",
      "CF Training: Epoch 0015 Iter 0060 / 0263 | Iter Loss 0.0220 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0015 Iter 0060 / 0263 | Iter Loss 0.0439 | Iter Mean Loss 0.0424\n",
      "CL Training: Epoch 0015 Iter 0060 / 0263 | Iter Loss 0.1071 | Iter Mean Loss 0.1075\n",
      "CF Training: Epoch 0015 Iter 0080 / 0263 | Iter Loss 0.0239 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0015 Iter 0080 / 0263 | Iter Loss 0.0414 | Iter Mean Loss 0.0433\n",
      "CL Training: Epoch 0015 Iter 0080 / 0263 | Iter Loss 0.1072 | Iter Mean Loss 0.1074\n",
      "CF Training: Epoch 0015 Iter 0100 / 0263 | Iter Loss 0.0210 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0015 Iter 0100 / 0263 | Iter Loss 0.0508 | Iter Mean Loss 0.0443\n",
      "CL Training: Epoch 0015 Iter 0100 / 0263 | Iter Loss 0.1070 | Iter Mean Loss 0.1073\n",
      "CF Training: Epoch 0015 Iter 0120 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0015 Iter 0120 / 0263 | Iter Loss 0.0537 | Iter Mean Loss 0.0454\n",
      "CL Training: Epoch 0015 Iter 0120 / 0263 | Iter Loss 0.1066 | Iter Mean Loss 0.1072\n",
      "CF Training: Epoch 0015 Iter 0140 / 0263 | Iter Loss 0.0199 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0015 Iter 0140 / 0263 | Iter Loss 0.0498 | Iter Mean Loss 0.0465\n",
      "CL Training: Epoch 0015 Iter 0140 / 0263 | Iter Loss 0.1070 | Iter Mean Loss 0.1072\n",
      "CF Training: Epoch 0015 Iter 0160 / 0263 | Iter Loss 0.0204 | Iter Mean Loss 0.0211\n",
      "KG Training: Epoch 0015 Iter 0160 / 0263 | Iter Loss 0.0569 | Iter Mean Loss 0.0476\n",
      "CL Training: Epoch 0015 Iter 0160 / 0263 | Iter Loss 0.1063 | Iter Mean Loss 0.1071\n",
      "CF Training: Epoch 0015 Iter 0180 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0015 Iter 0180 / 0263 | Iter Loss 0.0568 | Iter Mean Loss 0.0486\n",
      "CL Training: Epoch 0015 Iter 0180 / 0263 | Iter Loss 0.1065 | Iter Mean Loss 0.1071\n",
      "CF Training: Epoch 0015 Iter 0200 / 0263 | Iter Loss 0.0180 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0015 Iter 0200 / 0263 | Iter Loss 0.0613 | Iter Mean Loss 0.0498\n",
      "CL Training: Epoch 0015 Iter 0200 / 0263 | Iter Loss 0.1065 | Iter Mean Loss 0.1070\n",
      "CF Training: Epoch 0015 Iter 0220 / 0263 | Iter Loss 0.0180 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0015 Iter 0220 / 0263 | Iter Loss 0.0658 | Iter Mean Loss 0.0508\n",
      "CL Training: Epoch 0015 Iter 0220 / 0263 | Iter Loss 0.1068 | Iter Mean Loss 0.1070\n",
      "CF Training: Epoch 0015 Iter 0240 / 0263 | Iter Loss 0.0199 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0015 Iter 0240 / 0263 | Iter Loss 0.0690 | Iter Mean Loss 0.0519\n",
      "CL Training: Epoch 0015 Iter 0240 / 0263 | Iter Loss 0.1064 | Iter Mean Loss 0.1069\n",
      "CF Training: Epoch 0015 Iter 0260 / 0263 | Iter Loss 0.0182 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0015 Iter 0260 / 0263 | Iter Loss 0.0708 | Iter Mean Loss 0.0531\n",
      "CL Training: Epoch 0015 Iter 0260 / 0263 | Iter Loss 0.1063 | Iter Mean Loss 0.1069\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.964639 s\n",
      "Measure time: 0.017739 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 16, Hit Ratio:0.19918  |  Precision:0.12266  |  Recall:0.2018  |  NDCG:0.20398\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0016 Iter 0000 / 0263 | Iter Loss 0.0255 | Iter Mean Loss 0.0255\n",
      "KG Training: Epoch 0016 Iter 0000 / 0263 | Iter Loss 0.0334 | Iter Mean Loss 0.0334\n",
      "CL Training: Epoch 0016 Iter 0000 / 0263 | Iter Loss 0.1068 | Iter Mean Loss 0.1068\n",
      "CF Training: Epoch 0016 Iter 0020 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0016 Iter 0020 / 0263 | Iter Loss 0.0403 | Iter Mean Loss 0.0383\n",
      "CL Training: Epoch 0016 Iter 0020 / 0263 | Iter Loss 0.1068 | Iter Mean Loss 0.1071\n",
      "CF Training: Epoch 0016 Iter 0040 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0214\n",
      "KG Training: Epoch 0016 Iter 0040 / 0263 | Iter Loss 0.0413 | Iter Mean Loss 0.0401\n",
      "CL Training: Epoch 0016 Iter 0040 / 0263 | Iter Loss 0.1063 | Iter Mean Loss 0.1070\n",
      "CF Training: Epoch 0016 Iter 0060 / 0263 | Iter Loss 0.0226 | Iter Mean Loss 0.0215\n",
      "KG Training: Epoch 0016 Iter 0060 / 0263 | Iter Loss 0.0423 | Iter Mean Loss 0.0413\n",
      "CL Training: Epoch 0016 Iter 0060 / 0263 | Iter Loss 0.1069 | Iter Mean Loss 0.1069\n",
      "CF Training: Epoch 0016 Iter 0080 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0016 Iter 0080 / 0263 | Iter Loss 0.0458 | Iter Mean Loss 0.0422\n",
      "CL Training: Epoch 0016 Iter 0080 / 0263 | Iter Loss 0.1064 | Iter Mean Loss 0.1068\n",
      "CF Training: Epoch 0016 Iter 0100 / 0263 | Iter Loss 0.0255 | Iter Mean Loss 0.0214\n",
      "KG Training: Epoch 0016 Iter 0100 / 0263 | Iter Loss 0.0471 | Iter Mean Loss 0.0430\n",
      "CL Training: Epoch 0016 Iter 0100 / 0263 | Iter Loss 0.1064 | Iter Mean Loss 0.1067\n",
      "CF Training: Epoch 0016 Iter 0120 / 0263 | Iter Loss 0.0168 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0016 Iter 0120 / 0263 | Iter Loss 0.0474 | Iter Mean Loss 0.0440\n",
      "CL Training: Epoch 0016 Iter 0120 / 0263 | Iter Loss 0.1060 | Iter Mean Loss 0.1066\n",
      "CF Training: Epoch 0016 Iter 0140 / 0263 | Iter Loss 0.0210 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0016 Iter 0140 / 0263 | Iter Loss 0.0541 | Iter Mean Loss 0.0450\n",
      "CL Training: Epoch 0016 Iter 0140 / 0263 | Iter Loss 0.1061 | Iter Mean Loss 0.1066\n",
      "CF Training: Epoch 0016 Iter 0160 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0016 Iter 0160 / 0263 | Iter Loss 0.0511 | Iter Mean Loss 0.0461\n",
      "CL Training: Epoch 0016 Iter 0160 / 0263 | Iter Loss 0.1063 | Iter Mean Loss 0.1065\n",
      "CF Training: Epoch 0016 Iter 0180 / 0263 | Iter Loss 0.0237 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0016 Iter 0180 / 0263 | Iter Loss 0.0591 | Iter Mean Loss 0.0471\n",
      "CL Training: Epoch 0016 Iter 0180 / 0263 | Iter Loss 0.1061 | Iter Mean Loss 0.1065\n",
      "CF Training: Epoch 0016 Iter 0200 / 0263 | Iter Loss 0.0168 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0016 Iter 0200 / 0263 | Iter Loss 0.0567 | Iter Mean Loss 0.0481\n",
      "CL Training: Epoch 0016 Iter 0200 / 0263 | Iter Loss 0.1061 | Iter Mean Loss 0.1065\n",
      "CF Training: Epoch 0016 Iter 0220 / 0263 | Iter Loss 0.0163 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0016 Iter 0220 / 0263 | Iter Loss 0.0564 | Iter Mean Loss 0.0492\n",
      "CL Training: Epoch 0016 Iter 0220 / 0263 | Iter Loss 0.1059 | Iter Mean Loss 0.1064\n",
      "CF Training: Epoch 0016 Iter 0240 / 0263 | Iter Loss 0.0194 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0016 Iter 0240 / 0263 | Iter Loss 0.0631 | Iter Mean Loss 0.0503\n",
      "CL Training: Epoch 0016 Iter 0240 / 0263 | Iter Loss 0.1060 | Iter Mean Loss 0.1064\n",
      "CF Training: Epoch 0016 Iter 0260 / 0263 | Iter Loss 0.0155 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0016 Iter 0260 / 0263 | Iter Loss 0.0739 | Iter Mean Loss 0.0515\n",
      "CL Training: Epoch 0016 Iter 0260 / 0263 | Iter Loss 0.1062 | Iter Mean Loss 0.1064\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.843687 s\n",
      "Measure time: 0.017556 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 17, Hit Ratio:0.20452  |  Precision:0.12596  |  Recall:0.20788  |  NDCG:0.2114\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0017 Iter 0000 / 0263 | Iter Loss 0.0238 | Iter Mean Loss 0.0238\n",
      "KG Training: Epoch 0017 Iter 0000 / 0263 | Iter Loss 0.0307 | Iter Mean Loss 0.0307\n",
      "CL Training: Epoch 0017 Iter 0000 / 0263 | Iter Loss 0.1058 | Iter Mean Loss 0.1058\n",
      "CF Training: Epoch 0017 Iter 0020 / 0263 | Iter Loss 0.0233 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0017 Iter 0020 / 0263 | Iter Loss 0.0394 | Iter Mean Loss 0.0372\n",
      "CL Training: Epoch 0017 Iter 0020 / 0263 | Iter Loss 0.1065 | Iter Mean Loss 0.1064\n",
      "CF Training: Epoch 0017 Iter 0040 / 0263 | Iter Loss 0.0264 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0017 Iter 0040 / 0263 | Iter Loss 0.0406 | Iter Mean Loss 0.0393\n",
      "CL Training: Epoch 0017 Iter 0040 / 0263 | Iter Loss 0.1061 | Iter Mean Loss 0.1063\n",
      "CF Training: Epoch 0017 Iter 0060 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0017 Iter 0060 / 0263 | Iter Loss 0.0441 | Iter Mean Loss 0.0405\n",
      "CL Training: Epoch 0017 Iter 0060 / 0263 | Iter Loss 0.1059 | Iter Mean Loss 0.1062\n",
      "CF Training: Epoch 0017 Iter 0080 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0017 Iter 0080 / 0263 | Iter Loss 0.0426 | Iter Mean Loss 0.0413\n",
      "CL Training: Epoch 0017 Iter 0080 / 0263 | Iter Loss 0.1056 | Iter Mean Loss 0.1061\n",
      "CF Training: Epoch 0017 Iter 0100 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0017 Iter 0100 / 0263 | Iter Loss 0.0428 | Iter Mean Loss 0.0420\n",
      "CL Training: Epoch 0017 Iter 0100 / 0263 | Iter Loss 0.1064 | Iter Mean Loss 0.1061\n",
      "CF Training: Epoch 0017 Iter 0120 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0017 Iter 0120 / 0263 | Iter Loss 0.0492 | Iter Mean Loss 0.0430\n",
      "CL Training: Epoch 0017 Iter 0120 / 0263 | Iter Loss 0.1057 | Iter Mean Loss 0.1060\n",
      "CF Training: Epoch 0017 Iter 0140 / 0263 | Iter Loss 0.0216 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0017 Iter 0140 / 0263 | Iter Loss 0.0556 | Iter Mean Loss 0.0439\n",
      "CL Training: Epoch 0017 Iter 0140 / 0263 | Iter Loss 0.1061 | Iter Mean Loss 0.1060\n",
      "CF Training: Epoch 0017 Iter 0160 / 0263 | Iter Loss 0.0169 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0017 Iter 0160 / 0263 | Iter Loss 0.0519 | Iter Mean Loss 0.0450\n",
      "CL Training: Epoch 0017 Iter 0160 / 0263 | Iter Loss 0.1054 | Iter Mean Loss 0.1060\n",
      "CF Training: Epoch 0017 Iter 0180 / 0263 | Iter Loss 0.0281 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0017 Iter 0180 / 0263 | Iter Loss 0.0538 | Iter Mean Loss 0.0460\n",
      "CL Training: Epoch 0017 Iter 0180 / 0263 | Iter Loss 0.1056 | Iter Mean Loss 0.1059\n",
      "CF Training: Epoch 0017 Iter 0200 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0017 Iter 0200 / 0263 | Iter Loss 0.0596 | Iter Mean Loss 0.0471\n",
      "CL Training: Epoch 0017 Iter 0200 / 0263 | Iter Loss 0.1056 | Iter Mean Loss 0.1059\n",
      "CF Training: Epoch 0017 Iter 0220 / 0263 | Iter Loss 0.0277 | Iter Mean Loss 0.0210\n",
      "KG Training: Epoch 0017 Iter 0220 / 0263 | Iter Loss 0.0532 | Iter Mean Loss 0.0481\n",
      "CL Training: Epoch 0017 Iter 0220 / 0263 | Iter Loss 0.1060 | Iter Mean Loss 0.1059\n",
      "CF Training: Epoch 0017 Iter 0240 / 0263 | Iter Loss 0.0192 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0017 Iter 0240 / 0263 | Iter Loss 0.0598 | Iter Mean Loss 0.0491\n",
      "CL Training: Epoch 0017 Iter 0240 / 0263 | Iter Loss 0.1060 | Iter Mean Loss 0.1059\n",
      "CF Training: Epoch 0017 Iter 0260 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0017 Iter 0260 / 0263 | Iter Loss 0.0726 | Iter Mean Loss 0.0503\n",
      "CL Training: Epoch 0017 Iter 0260 / 0263 | Iter Loss 0.1060 | Iter Mean Loss 0.1059\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.239397 s\n",
      "Measure time: 0.017390 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 18, Hit Ratio:0.19224  |  Precision:0.11839  |  Recall:0.19432  |  NDCG:0.19474\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0018 Iter 0000 / 0263 | Iter Loss 0.0213 | Iter Mean Loss 0.0213\n",
      "KG Training: Epoch 0018 Iter 0000 / 0263 | Iter Loss 0.0310 | Iter Mean Loss 0.0310\n",
      "CL Training: Epoch 0018 Iter 0000 / 0263 | Iter Loss 0.1061 | Iter Mean Loss 0.1061\n",
      "CF Training: Epoch 0018 Iter 0020 / 0263 | Iter Loss 0.0298 | Iter Mean Loss 0.0224\n",
      "KG Training: Epoch 0018 Iter 0020 / 0263 | Iter Loss 0.0412 | Iter Mean Loss 0.0363\n",
      "CL Training: Epoch 0018 Iter 0020 / 0263 | Iter Loss 0.1070 | Iter Mean Loss 0.1063\n",
      "CF Training: Epoch 0018 Iter 0040 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0211\n",
      "KG Training: Epoch 0018 Iter 0040 / 0263 | Iter Loss 0.0389 | Iter Mean Loss 0.0376\n",
      "CL Training: Epoch 0018 Iter 0040 / 0263 | Iter Loss 0.1056 | Iter Mean Loss 0.1062\n",
      "CF Training: Epoch 0018 Iter 0060 / 0263 | Iter Loss 0.0183 | Iter Mean Loss 0.0212\n",
      "KG Training: Epoch 0018 Iter 0060 / 0263 | Iter Loss 0.0411 | Iter Mean Loss 0.0386\n",
      "CL Training: Epoch 0018 Iter 0060 / 0263 | Iter Loss 0.1060 | Iter Mean Loss 0.1060\n",
      "CF Training: Epoch 0018 Iter 0080 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0018 Iter 0080 / 0263 | Iter Loss 0.0436 | Iter Mean Loss 0.0394\n",
      "CL Training: Epoch 0018 Iter 0080 / 0263 | Iter Loss 0.1058 | Iter Mean Loss 0.1060\n",
      "CF Training: Epoch 0018 Iter 0100 / 0263 | Iter Loss 0.0259 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0018 Iter 0100 / 0263 | Iter Loss 0.0427 | Iter Mean Loss 0.0403\n",
      "CL Training: Epoch 0018 Iter 0100 / 0263 | Iter Loss 0.1056 | Iter Mean Loss 0.1059\n",
      "CF Training: Epoch 0018 Iter 0120 / 0263 | Iter Loss 0.0229 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0018 Iter 0120 / 0263 | Iter Loss 0.0478 | Iter Mean Loss 0.0414\n",
      "CL Training: Epoch 0018 Iter 0120 / 0263 | Iter Loss 0.1053 | Iter Mean Loss 0.1058\n",
      "CF Training: Epoch 0018 Iter 0140 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0018 Iter 0140 / 0263 | Iter Loss 0.0547 | Iter Mean Loss 0.0426\n",
      "CL Training: Epoch 0018 Iter 0140 / 0263 | Iter Loss 0.1053 | Iter Mean Loss 0.1057\n",
      "CF Training: Epoch 0018 Iter 0160 / 0263 | Iter Loss 0.0222 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0018 Iter 0160 / 0263 | Iter Loss 0.0480 | Iter Mean Loss 0.0435\n",
      "CL Training: Epoch 0018 Iter 0160 / 0263 | Iter Loss 0.1053 | Iter Mean Loss 0.1056\n",
      "CF Training: Epoch 0018 Iter 0180 / 0263 | Iter Loss 0.0194 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0018 Iter 0180 / 0263 | Iter Loss 0.0560 | Iter Mean Loss 0.0445\n",
      "CL Training: Epoch 0018 Iter 0180 / 0263 | Iter Loss 0.1053 | Iter Mean Loss 0.1056\n",
      "CF Training: Epoch 0018 Iter 0200 / 0263 | Iter Loss 0.0186 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0018 Iter 0200 / 0263 | Iter Loss 0.0578 | Iter Mean Loss 0.0456\n",
      "CL Training: Epoch 0018 Iter 0200 / 0263 | Iter Loss 0.1048 | Iter Mean Loss 0.1056\n",
      "CF Training: Epoch 0018 Iter 0220 / 0263 | Iter Loss 0.0252 | Iter Mean Loss 0.0210\n",
      "KG Training: Epoch 0018 Iter 0220 / 0263 | Iter Loss 0.0580 | Iter Mean Loss 0.0468\n",
      "CL Training: Epoch 0018 Iter 0220 / 0263 | Iter Loss 0.1052 | Iter Mean Loss 0.1055\n",
      "CF Training: Epoch 0018 Iter 0240 / 0263 | Iter Loss 0.0242 | Iter Mean Loss 0.0211\n",
      "KG Training: Epoch 0018 Iter 0240 / 0263 | Iter Loss 0.0637 | Iter Mean Loss 0.0478\n",
      "CL Training: Epoch 0018 Iter 0240 / 0263 | Iter Loss 0.1053 | Iter Mean Loss 0.1055\n",
      "CF Training: Epoch 0018 Iter 0260 / 0263 | Iter Loss 0.0140 | Iter Mean Loss 0.0210\n",
      "KG Training: Epoch 0018 Iter 0260 / 0263 | Iter Loss 0.0646 | Iter Mean Loss 0.0491\n",
      "CL Training: Epoch 0018 Iter 0260 / 0263 | Iter Loss 0.1056 | Iter Mean Loss 0.1055\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.235325 s\n",
      "Measure time: 0.017431 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 19, Hit Ratio:0.19914  |  Precision:0.12264  |  Recall:0.20142  |  NDCG:0.20636\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0019 Iter 0000 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0160\n",
      "KG Training: Epoch 0019 Iter 0000 / 0263 | Iter Loss 0.0308 | Iter Mean Loss 0.0308\n",
      "CL Training: Epoch 0019 Iter 0000 / 0263 | Iter Loss 0.1054 | Iter Mean Loss 0.1054\n",
      "CF Training: Epoch 0019 Iter 0020 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0213\n",
      "KG Training: Epoch 0019 Iter 0020 / 0263 | Iter Loss 0.0402 | Iter Mean Loss 0.0355\n",
      "CL Training: Epoch 0019 Iter 0020 / 0263 | Iter Loss 0.1057 | Iter Mean Loss 0.1057\n",
      "CF Training: Epoch 0019 Iter 0040 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0019 Iter 0040 / 0263 | Iter Loss 0.0399 | Iter Mean Loss 0.0370\n",
      "CL Training: Epoch 0019 Iter 0040 / 0263 | Iter Loss 0.1049 | Iter Mean Loss 0.1055\n",
      "CF Training: Epoch 0019 Iter 0060 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0210\n",
      "KG Training: Epoch 0019 Iter 0060 / 0263 | Iter Loss 0.0360 | Iter Mean Loss 0.0379\n",
      "CL Training: Epoch 0019 Iter 0060 / 0263 | Iter Loss 0.1049 | Iter Mean Loss 0.1054\n",
      "CF Training: Epoch 0019 Iter 0080 / 0263 | Iter Loss 0.0254 | Iter Mean Loss 0.0211\n",
      "KG Training: Epoch 0019 Iter 0080 / 0263 | Iter Loss 0.0389 | Iter Mean Loss 0.0387\n",
      "CL Training: Epoch 0019 Iter 0080 / 0263 | Iter Loss 0.1050 | Iter Mean Loss 0.1053\n",
      "CF Training: Epoch 0019 Iter 0100 / 0263 | Iter Loss 0.0260 | Iter Mean Loss 0.0215\n",
      "KG Training: Epoch 0019 Iter 0100 / 0263 | Iter Loss 0.0463 | Iter Mean Loss 0.0396\n",
      "CL Training: Epoch 0019 Iter 0100 / 0263 | Iter Loss 0.1051 | Iter Mean Loss 0.1053\n",
      "CF Training: Epoch 0019 Iter 0120 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0212\n",
      "KG Training: Epoch 0019 Iter 0120 / 0263 | Iter Loss 0.0453 | Iter Mean Loss 0.0405\n",
      "CL Training: Epoch 0019 Iter 0120 / 0263 | Iter Loss 0.1047 | Iter Mean Loss 0.1052\n",
      "CF Training: Epoch 0019 Iter 0140 / 0263 | Iter Loss 0.0168 | Iter Mean Loss 0.0212\n",
      "KG Training: Epoch 0019 Iter 0140 / 0263 | Iter Loss 0.0482 | Iter Mean Loss 0.0416\n",
      "CL Training: Epoch 0019 Iter 0140 / 0263 | Iter Loss 0.1047 | Iter Mean Loss 0.1052\n",
      "CF Training: Epoch 0019 Iter 0160 / 0263 | Iter Loss 0.0209 | Iter Mean Loss 0.0211\n",
      "KG Training: Epoch 0019 Iter 0160 / 0263 | Iter Loss 0.0518 | Iter Mean Loss 0.0428\n",
      "CL Training: Epoch 0019 Iter 0160 / 0263 | Iter Loss 0.1044 | Iter Mean Loss 0.1051\n",
      "CF Training: Epoch 0019 Iter 0180 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0212\n",
      "KG Training: Epoch 0019 Iter 0180 / 0263 | Iter Loss 0.0528 | Iter Mean Loss 0.0439\n",
      "CL Training: Epoch 0019 Iter 0180 / 0263 | Iter Loss 0.1047 | Iter Mean Loss 0.1051\n",
      "CF Training: Epoch 0019 Iter 0200 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0211\n",
      "KG Training: Epoch 0019 Iter 0200 / 0263 | Iter Loss 0.0602 | Iter Mean Loss 0.0450\n",
      "CL Training: Epoch 0019 Iter 0200 / 0263 | Iter Loss 0.1047 | Iter Mean Loss 0.1050\n",
      "CF Training: Epoch 0019 Iter 0220 / 0263 | Iter Loss 0.0271 | Iter Mean Loss 0.0211\n",
      "KG Training: Epoch 0019 Iter 0220 / 0263 | Iter Loss 0.0549 | Iter Mean Loss 0.0460\n",
      "CL Training: Epoch 0019 Iter 0220 / 0263 | Iter Loss 0.1046 | Iter Mean Loss 0.1050\n",
      "CF Training: Epoch 0019 Iter 0240 / 0263 | Iter Loss 0.0222 | Iter Mean Loss 0.0211\n",
      "KG Training: Epoch 0019 Iter 0240 / 0263 | Iter Loss 0.0598 | Iter Mean Loss 0.0470\n",
      "CL Training: Epoch 0019 Iter 0240 / 0263 | Iter Loss 0.1049 | Iter Mean Loss 0.1050\n",
      "CF Training: Epoch 0019 Iter 0260 / 0263 | Iter Loss 0.0213 | Iter Mean Loss 0.0210\n",
      "KG Training: Epoch 0019 Iter 0260 / 0263 | Iter Loss 0.0670 | Iter Mean Loss 0.0482\n",
      "CL Training: Epoch 0019 Iter 0260 / 0263 | Iter Loss 0.1045 | Iter Mean Loss 0.1050\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.236646 s\n",
      "Measure time: 0.016867 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 20, Hit Ratio:0.21142  |  Precision:0.1302  |  Recall:0.21352  |  NDCG:0.22728\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0020 Iter 0000 / 0263 | Iter Loss 0.0180 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0020 Iter 0000 / 0263 | Iter Loss 0.0314 | Iter Mean Loss 0.0314\n",
      "CL Training: Epoch 0020 Iter 0000 / 0263 | Iter Loss 0.1050 | Iter Mean Loss 0.1050\n",
      "CF Training: Epoch 0020 Iter 0020 / 0263 | Iter Loss 0.0170 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0020 Iter 0020 / 0263 | Iter Loss 0.0346 | Iter Mean Loss 0.0344\n",
      "CL Training: Epoch 0020 Iter 0020 / 0263 | Iter Loss 0.1056 | Iter Mean Loss 0.1051\n",
      "CF Training: Epoch 0020 Iter 0040 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0020 Iter 0040 / 0263 | Iter Loss 0.0387 | Iter Mean Loss 0.0361\n",
      "CL Training: Epoch 0020 Iter 0040 / 0263 | Iter Loss 0.1047 | Iter Mean Loss 0.1050\n",
      "CF Training: Epoch 0020 Iter 0060 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0020 Iter 0060 / 0263 | Iter Loss 0.0392 | Iter Mean Loss 0.0373\n",
      "CL Training: Epoch 0020 Iter 0060 / 0263 | Iter Loss 0.1045 | Iter Mean Loss 0.1050\n",
      "CF Training: Epoch 0020 Iter 0080 / 0263 | Iter Loss 0.0233 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0020 Iter 0080 / 0263 | Iter Loss 0.0398 | Iter Mean Loss 0.0378\n",
      "CL Training: Epoch 0020 Iter 0080 / 0263 | Iter Loss 0.1046 | Iter Mean Loss 0.1049\n",
      "CF Training: Epoch 0020 Iter 0100 / 0263 | Iter Loss 0.0229 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0020 Iter 0100 / 0263 | Iter Loss 0.0405 | Iter Mean Loss 0.0385\n",
      "CL Training: Epoch 0020 Iter 0100 / 0263 | Iter Loss 0.1049 | Iter Mean Loss 0.1048\n",
      "CF Training: Epoch 0020 Iter 0120 / 0263 | Iter Loss 0.0238 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0020 Iter 0120 / 0263 | Iter Loss 0.0514 | Iter Mean Loss 0.0396\n",
      "CL Training: Epoch 0020 Iter 0120 / 0263 | Iter Loss 0.1044 | Iter Mean Loss 0.1048\n",
      "CF Training: Epoch 0020 Iter 0140 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0020 Iter 0140 / 0263 | Iter Loss 0.0518 | Iter Mean Loss 0.0407\n",
      "CL Training: Epoch 0020 Iter 0140 / 0263 | Iter Loss 0.1042 | Iter Mean Loss 0.1047\n",
      "CF Training: Epoch 0020 Iter 0160 / 0263 | Iter Loss 0.0217 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0020 Iter 0160 / 0263 | Iter Loss 0.0508 | Iter Mean Loss 0.0419\n",
      "CL Training: Epoch 0020 Iter 0160 / 0263 | Iter Loss 0.1043 | Iter Mean Loss 0.1046\n",
      "CF Training: Epoch 0020 Iter 0180 / 0263 | Iter Loss 0.0168 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0020 Iter 0180 / 0263 | Iter Loss 0.0576 | Iter Mean Loss 0.0430\n",
      "CL Training: Epoch 0020 Iter 0180 / 0263 | Iter Loss 0.1044 | Iter Mean Loss 0.1046\n",
      "CF Training: Epoch 0020 Iter 0200 / 0263 | Iter Loss 0.0227 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0020 Iter 0200 / 0263 | Iter Loss 0.0560 | Iter Mean Loss 0.0442\n",
      "CL Training: Epoch 0020 Iter 0200 / 0263 | Iter Loss 0.1045 | Iter Mean Loss 0.1046\n",
      "CF Training: Epoch 0020 Iter 0220 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0020 Iter 0220 / 0263 | Iter Loss 0.0583 | Iter Mean Loss 0.0453\n",
      "CL Training: Epoch 0020 Iter 0220 / 0263 | Iter Loss 0.1043 | Iter Mean Loss 0.1045\n",
      "CF Training: Epoch 0020 Iter 0240 / 0263 | Iter Loss 0.0178 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0020 Iter 0240 / 0263 | Iter Loss 0.0597 | Iter Mean Loss 0.0464\n",
      "CL Training: Epoch 0020 Iter 0240 / 0263 | Iter Loss 0.1041 | Iter Mean Loss 0.1045\n",
      "CF Training: Epoch 0020 Iter 0260 / 0263 | Iter Loss 0.0340 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0020 Iter 0260 / 0263 | Iter Loss 0.0662 | Iter Mean Loss 0.0475\n",
      "CL Training: Epoch 0020 Iter 0260 / 0263 | Iter Loss 0.1044 | Iter Mean Loss 0.1045\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.231410 s\n",
      "Measure time: 0.017362 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 21, Hit Ratio:0.21155  |  Precision:0.13028  |  Recall:0.21311  |  NDCG:0.2201\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0021 Iter 0000 / 0263 | Iter Loss 0.0182 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0021 Iter 0000 / 0263 | Iter Loss 0.0308 | Iter Mean Loss 0.0308\n",
      "CL Training: Epoch 0021 Iter 0000 / 0263 | Iter Loss 0.1045 | Iter Mean Loss 0.1045\n",
      "CF Training: Epoch 0021 Iter 0020 / 0263 | Iter Loss 0.0219 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0021 Iter 0020 / 0263 | Iter Loss 0.0367 | Iter Mean Loss 0.0339\n",
      "CL Training: Epoch 0021 Iter 0020 / 0263 | Iter Loss 0.1045 | Iter Mean Loss 0.1048\n",
      "CF Training: Epoch 0021 Iter 0040 / 0263 | Iter Loss 0.0271 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0021 Iter 0040 / 0263 | Iter Loss 0.0399 | Iter Mean Loss 0.0353\n",
      "CL Training: Epoch 0021 Iter 0040 / 0263 | Iter Loss 0.1047 | Iter Mean Loss 0.1046\n",
      "CF Training: Epoch 0021 Iter 0060 / 0263 | Iter Loss 0.0193 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0021 Iter 0060 / 0263 | Iter Loss 0.0356 | Iter Mean Loss 0.0360\n",
      "CL Training: Epoch 0021 Iter 0060 / 0263 | Iter Loss 0.1045 | Iter Mean Loss 0.1045\n",
      "CF Training: Epoch 0021 Iter 0080 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0021 Iter 0080 / 0263 | Iter Loss 0.0370 | Iter Mean Loss 0.0368\n",
      "CL Training: Epoch 0021 Iter 0080 / 0263 | Iter Loss 0.1038 | Iter Mean Loss 0.1044\n",
      "CF Training: Epoch 0021 Iter 0100 / 0263 | Iter Loss 0.0180 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0021 Iter 0100 / 0263 | Iter Loss 0.0421 | Iter Mean Loss 0.0377\n",
      "CL Training: Epoch 0021 Iter 0100 / 0263 | Iter Loss 0.1041 | Iter Mean Loss 0.1044\n",
      "CF Training: Epoch 0021 Iter 0120 / 0263 | Iter Loss 0.0200 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0021 Iter 0120 / 0263 | Iter Loss 0.0454 | Iter Mean Loss 0.0389\n",
      "CL Training: Epoch 0021 Iter 0120 / 0263 | Iter Loss 0.1041 | Iter Mean Loss 0.1043\n",
      "CF Training: Epoch 0021 Iter 0140 / 0263 | Iter Loss 0.0191 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0021 Iter 0140 / 0263 | Iter Loss 0.0471 | Iter Mean Loss 0.0399\n",
      "CL Training: Epoch 0021 Iter 0140 / 0263 | Iter Loss 0.1041 | Iter Mean Loss 0.1043\n",
      "CF Training: Epoch 0021 Iter 0160 / 0263 | Iter Loss 0.0297 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0021 Iter 0160 / 0263 | Iter Loss 0.0539 | Iter Mean Loss 0.0411\n",
      "CL Training: Epoch 0021 Iter 0160 / 0263 | Iter Loss 0.1039 | Iter Mean Loss 0.1043\n",
      "CF Training: Epoch 0021 Iter 0180 / 0263 | Iter Loss 0.0237 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0021 Iter 0180 / 0263 | Iter Loss 0.0522 | Iter Mean Loss 0.0421\n",
      "CL Training: Epoch 0021 Iter 0180 / 0263 | Iter Loss 0.1039 | Iter Mean Loss 0.1042\n",
      "CF Training: Epoch 0021 Iter 0200 / 0263 | Iter Loss 0.0245 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0021 Iter 0200 / 0263 | Iter Loss 0.0592 | Iter Mean Loss 0.0432\n",
      "CL Training: Epoch 0021 Iter 0200 / 0263 | Iter Loss 0.1045 | Iter Mean Loss 0.1042\n",
      "CF Training: Epoch 0021 Iter 0220 / 0263 | Iter Loss 0.0210 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0021 Iter 0220 / 0263 | Iter Loss 0.0569 | Iter Mean Loss 0.0443\n",
      "CL Training: Epoch 0021 Iter 0220 / 0263 | Iter Loss 0.1043 | Iter Mean Loss 0.1042\n",
      "CF Training: Epoch 0021 Iter 0240 / 0263 | Iter Loss 0.0256 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0021 Iter 0240 / 0263 | Iter Loss 0.0644 | Iter Mean Loss 0.0454\n",
      "CL Training: Epoch 0021 Iter 0240 / 0263 | Iter Loss 0.1042 | Iter Mean Loss 0.1042\n",
      "CF Training: Epoch 0021 Iter 0260 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0021 Iter 0260 / 0263 | Iter Loss 0.0760 | Iter Mean Loss 0.0466\n",
      "CL Training: Epoch 0021 Iter 0260 / 0263 | Iter Loss 0.1040 | Iter Mean Loss 0.1042\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.235525 s\n",
      "Measure time: 0.017227 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 22, Hit Ratio:0.20866  |  Precision:0.1285  |  Recall:0.21039  |  NDCG:0.22104\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0022 Iter 0000 / 0263 | Iter Loss 0.0197 | Iter Mean Loss 0.0197\n",
      "KG Training: Epoch 0022 Iter 0000 / 0263 | Iter Loss 0.0299 | Iter Mean Loss 0.0299\n",
      "CL Training: Epoch 0022 Iter 0000 / 0263 | Iter Loss 0.1043 | Iter Mean Loss 0.1043\n",
      "CF Training: Epoch 0022 Iter 0020 / 0263 | Iter Loss 0.0248 | Iter Mean Loss 0.0213\n",
      "KG Training: Epoch 0022 Iter 0020 / 0263 | Iter Loss 0.0374 | Iter Mean Loss 0.0331\n",
      "CL Training: Epoch 0022 Iter 0020 / 0263 | Iter Loss 0.1046 | Iter Mean Loss 0.1044\n",
      "CF Training: Epoch 0022 Iter 0040 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0022 Iter 0040 / 0263 | Iter Loss 0.0394 | Iter Mean Loss 0.0349\n",
      "CL Training: Epoch 0022 Iter 0040 / 0263 | Iter Loss 0.1037 | Iter Mean Loss 0.1042\n",
      "CF Training: Epoch 0022 Iter 0060 / 0263 | Iter Loss 0.0123 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0022 Iter 0060 / 0263 | Iter Loss 0.0384 | Iter Mean Loss 0.0356\n",
      "CL Training: Epoch 0022 Iter 0060 / 0263 | Iter Loss 0.1039 | Iter Mean Loss 0.1041\n",
      "CF Training: Epoch 0022 Iter 0080 / 0263 | Iter Loss 0.0250 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0022 Iter 0080 / 0263 | Iter Loss 0.0392 | Iter Mean Loss 0.0365\n",
      "CL Training: Epoch 0022 Iter 0080 / 0263 | Iter Loss 0.1038 | Iter Mean Loss 0.1040\n",
      "CF Training: Epoch 0022 Iter 0100 / 0263 | Iter Loss 0.0216 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0022 Iter 0100 / 0263 | Iter Loss 0.0426 | Iter Mean Loss 0.0374\n",
      "CL Training: Epoch 0022 Iter 0100 / 0263 | Iter Loss 0.1036 | Iter Mean Loss 0.1040\n",
      "CF Training: Epoch 0022 Iter 0120 / 0263 | Iter Loss 0.0220 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0022 Iter 0120 / 0263 | Iter Loss 0.0472 | Iter Mean Loss 0.0385\n",
      "CL Training: Epoch 0022 Iter 0120 / 0263 | Iter Loss 0.1035 | Iter Mean Loss 0.1039\n",
      "CF Training: Epoch 0022 Iter 0140 / 0263 | Iter Loss 0.0174 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0022 Iter 0140 / 0263 | Iter Loss 0.0451 | Iter Mean Loss 0.0395\n",
      "CL Training: Epoch 0022 Iter 0140 / 0263 | Iter Loss 0.1034 | Iter Mean Loss 0.1038\n",
      "CF Training: Epoch 0022 Iter 0160 / 0263 | Iter Loss 0.0218 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0022 Iter 0160 / 0263 | Iter Loss 0.0491 | Iter Mean Loss 0.0407\n",
      "CL Training: Epoch 0022 Iter 0160 / 0263 | Iter Loss 0.1034 | Iter Mean Loss 0.1038\n",
      "CF Training: Epoch 0022 Iter 0180 / 0263 | Iter Loss 0.0172 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0022 Iter 0180 / 0263 | Iter Loss 0.0514 | Iter Mean Loss 0.0417\n",
      "CL Training: Epoch 0022 Iter 0180 / 0263 | Iter Loss 0.1034 | Iter Mean Loss 0.1038\n",
      "CF Training: Epoch 0022 Iter 0200 / 0263 | Iter Loss 0.0193 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0022 Iter 0200 / 0263 | Iter Loss 0.0509 | Iter Mean Loss 0.0428\n",
      "CL Training: Epoch 0022 Iter 0200 / 0263 | Iter Loss 0.1035 | Iter Mean Loss 0.1037\n",
      "CF Training: Epoch 0022 Iter 0220 / 0263 | Iter Loss 0.0225 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0022 Iter 0220 / 0263 | Iter Loss 0.0549 | Iter Mean Loss 0.0437\n",
      "CL Training: Epoch 0022 Iter 0220 / 0263 | Iter Loss 0.1035 | Iter Mean Loss 0.1037\n",
      "CF Training: Epoch 0022 Iter 0240 / 0263 | Iter Loss 0.0233 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0022 Iter 0240 / 0263 | Iter Loss 0.0593 | Iter Mean Loss 0.0447\n",
      "CL Training: Epoch 0022 Iter 0240 / 0263 | Iter Loss 0.1035 | Iter Mean Loss 0.1037\n",
      "CF Training: Epoch 0022 Iter 0260 / 0263 | Iter Loss 0.0183 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0022 Iter 0260 / 0263 | Iter Loss 0.0711 | Iter Mean Loss 0.0460\n",
      "CL Training: Epoch 0022 Iter 0260 / 0263 | Iter Loss 0.1037 | Iter Mean Loss 0.1037\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.234857 s\n",
      "Measure time: 0.017268 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 23, Hit Ratio:0.20198  |  Precision:0.12439  |  Recall:0.20339  |  NDCG:0.21158\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0023 Iter 0000 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0023 Iter 0000 / 0263 | Iter Loss 0.0268 | Iter Mean Loss 0.0268\n",
      "CL Training: Epoch 0023 Iter 0000 / 0263 | Iter Loss 0.1038 | Iter Mean Loss 0.1038\n",
      "CF Training: Epoch 0023 Iter 0020 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0023 Iter 0020 / 0263 | Iter Loss 0.0354 | Iter Mean Loss 0.0328\n",
      "CL Training: Epoch 0023 Iter 0020 / 0263 | Iter Loss 0.1037 | Iter Mean Loss 0.1041\n",
      "CF Training: Epoch 0023 Iter 0040 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0023 Iter 0040 / 0263 | Iter Loss 0.0356 | Iter Mean Loss 0.0343\n",
      "CL Training: Epoch 0023 Iter 0040 / 0263 | Iter Loss 0.1039 | Iter Mean Loss 0.1039\n",
      "CF Training: Epoch 0023 Iter 0060 / 0263 | Iter Loss 0.0241 | Iter Mean Loss 0.0211\n",
      "KG Training: Epoch 0023 Iter 0060 / 0263 | Iter Loss 0.0398 | Iter Mean Loss 0.0353\n",
      "CL Training: Epoch 0023 Iter 0060 / 0263 | Iter Loss 0.1036 | Iter Mean Loss 0.1039\n",
      "CF Training: Epoch 0023 Iter 0080 / 0263 | Iter Loss 0.0131 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0023 Iter 0080 / 0263 | Iter Loss 0.0374 | Iter Mean Loss 0.0359\n",
      "CL Training: Epoch 0023 Iter 0080 / 0263 | Iter Loss 0.1036 | Iter Mean Loss 0.1038\n",
      "CF Training: Epoch 0023 Iter 0100 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0023 Iter 0100 / 0263 | Iter Loss 0.0395 | Iter Mean Loss 0.0368\n",
      "CL Training: Epoch 0023 Iter 0100 / 0263 | Iter Loss 0.1034 | Iter Mean Loss 0.1037\n",
      "CF Training: Epoch 0023 Iter 0120 / 0263 | Iter Loss 0.0195 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0023 Iter 0120 / 0263 | Iter Loss 0.0405 | Iter Mean Loss 0.0376\n",
      "CL Training: Epoch 0023 Iter 0120 / 0263 | Iter Loss 0.1037 | Iter Mean Loss 0.1036\n",
      "CF Training: Epoch 0023 Iter 0140 / 0263 | Iter Loss 0.0223 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0023 Iter 0140 / 0263 | Iter Loss 0.0456 | Iter Mean Loss 0.0386\n",
      "CL Training: Epoch 0023 Iter 0140 / 0263 | Iter Loss 0.1029 | Iter Mean Loss 0.1036\n",
      "CF Training: Epoch 0023 Iter 0160 / 0263 | Iter Loss 0.0212 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0023 Iter 0160 / 0263 | Iter Loss 0.0515 | Iter Mean Loss 0.0397\n",
      "CL Training: Epoch 0023 Iter 0160 / 0263 | Iter Loss 0.1026 | Iter Mean Loss 0.1035\n",
      "CF Training: Epoch 0023 Iter 0180 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0023 Iter 0180 / 0263 | Iter Loss 0.0514 | Iter Mean Loss 0.0408\n",
      "CL Training: Epoch 0023 Iter 0180 / 0263 | Iter Loss 0.1030 | Iter Mean Loss 0.1035\n",
      "CF Training: Epoch 0023 Iter 0200 / 0263 | Iter Loss 0.0162 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0023 Iter 0200 / 0263 | Iter Loss 0.0545 | Iter Mean Loss 0.0419\n",
      "CL Training: Epoch 0023 Iter 0200 / 0263 | Iter Loss 0.1029 | Iter Mean Loss 0.1034\n",
      "CF Training: Epoch 0023 Iter 0220 / 0263 | Iter Loss 0.0209 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0023 Iter 0220 / 0263 | Iter Loss 0.0547 | Iter Mean Loss 0.0430\n",
      "CL Training: Epoch 0023 Iter 0220 / 0263 | Iter Loss 0.1030 | Iter Mean Loss 0.1034\n",
      "CF Training: Epoch 0023 Iter 0240 / 0263 | Iter Loss 0.0200 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0023 Iter 0240 / 0263 | Iter Loss 0.0585 | Iter Mean Loss 0.0441\n",
      "CL Training: Epoch 0023 Iter 0240 / 0263 | Iter Loss 0.1030 | Iter Mean Loss 0.1034\n",
      "CF Training: Epoch 0023 Iter 0260 / 0263 | Iter Loss 0.0258 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0023 Iter 0260 / 0263 | Iter Loss 0.0705 | Iter Mean Loss 0.0454\n",
      "CL Training: Epoch 0023 Iter 0260 / 0263 | Iter Loss 0.1028 | Iter Mean Loss 0.1034\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.236619 s\n",
      "Measure time: 0.017442 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 24, Hit Ratio:0.21138  |  Precision:0.13018  |  Recall:0.21256  |  NDCG:0.22237\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0024 Iter 0000 / 0263 | Iter Loss 0.0231 | Iter Mean Loss 0.0231\n",
      "KG Training: Epoch 0024 Iter 0000 / 0263 | Iter Loss 0.0273 | Iter Mean Loss 0.0273\n",
      "CL Training: Epoch 0024 Iter 0000 / 0263 | Iter Loss 0.1029 | Iter Mean Loss 0.1029\n",
      "CF Training: Epoch 0024 Iter 0020 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0024 Iter 0020 / 0263 | Iter Loss 0.0362 | Iter Mean Loss 0.0316\n",
      "CL Training: Epoch 0024 Iter 0020 / 0263 | Iter Loss 0.1030 | Iter Mean Loss 0.1035\n",
      "CF Training: Epoch 0024 Iter 0040 / 0263 | Iter Loss 0.0200 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0024 Iter 0040 / 0263 | Iter Loss 0.0343 | Iter Mean Loss 0.0334\n",
      "CL Training: Epoch 0024 Iter 0040 / 0263 | Iter Loss 0.1025 | Iter Mean Loss 0.1033\n",
      "CF Training: Epoch 0024 Iter 0060 / 0263 | Iter Loss 0.0224 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0024 Iter 0060 / 0263 | Iter Loss 0.0350 | Iter Mean Loss 0.0344\n",
      "CL Training: Epoch 0024 Iter 0060 / 0263 | Iter Loss 0.1025 | Iter Mean Loss 0.1031\n",
      "CF Training: Epoch 0024 Iter 0080 / 0263 | Iter Loss 0.0153 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0024 Iter 0080 / 0263 | Iter Loss 0.0358 | Iter Mean Loss 0.0351\n",
      "CL Training: Epoch 0024 Iter 0080 / 0263 | Iter Loss 0.1028 | Iter Mean Loss 0.1030\n",
      "CF Training: Epoch 0024 Iter 0100 / 0263 | Iter Loss 0.0186 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0024 Iter 0100 / 0263 | Iter Loss 0.0417 | Iter Mean Loss 0.0358\n",
      "CL Training: Epoch 0024 Iter 0100 / 0263 | Iter Loss 0.1026 | Iter Mean Loss 0.1030\n",
      "CF Training: Epoch 0024 Iter 0120 / 0263 | Iter Loss 0.0166 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0024 Iter 0120 / 0263 | Iter Loss 0.0462 | Iter Mean Loss 0.0369\n",
      "CL Training: Epoch 0024 Iter 0120 / 0263 | Iter Loss 0.1026 | Iter Mean Loss 0.1029\n",
      "CF Training: Epoch 0024 Iter 0140 / 0263 | Iter Loss 0.0240 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0024 Iter 0140 / 0263 | Iter Loss 0.0491 | Iter Mean Loss 0.0379\n",
      "CL Training: Epoch 0024 Iter 0140 / 0263 | Iter Loss 0.1026 | Iter Mean Loss 0.1029\n",
      "CF Training: Epoch 0024 Iter 0160 / 0263 | Iter Loss 0.0133 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0024 Iter 0160 / 0263 | Iter Loss 0.0444 | Iter Mean Loss 0.0391\n",
      "CL Training: Epoch 0024 Iter 0160 / 0263 | Iter Loss 0.1028 | Iter Mean Loss 0.1029\n",
      "CF Training: Epoch 0024 Iter 0180 / 0263 | Iter Loss 0.0150 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0024 Iter 0180 / 0263 | Iter Loss 0.0569 | Iter Mean Loss 0.0402\n",
      "CL Training: Epoch 0024 Iter 0180 / 0263 | Iter Loss 0.1024 | Iter Mean Loss 0.1029\n",
      "CF Training: Epoch 0024 Iter 0200 / 0263 | Iter Loss 0.0263 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0024 Iter 0200 / 0263 | Iter Loss 0.0583 | Iter Mean Loss 0.0412\n",
      "CL Training: Epoch 0024 Iter 0200 / 0263 | Iter Loss 0.1028 | Iter Mean Loss 0.1028\n",
      "CF Training: Epoch 0024 Iter 0220 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0024 Iter 0220 / 0263 | Iter Loss 0.0528 | Iter Mean Loss 0.0422\n",
      "CL Training: Epoch 0024 Iter 0220 / 0263 | Iter Loss 0.1030 | Iter Mean Loss 0.1028\n",
      "CF Training: Epoch 0024 Iter 0240 / 0263 | Iter Loss 0.0169 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0024 Iter 0240 / 0263 | Iter Loss 0.0592 | Iter Mean Loss 0.0433\n",
      "CL Training: Epoch 0024 Iter 0240 / 0263 | Iter Loss 0.1027 | Iter Mean Loss 0.1028\n",
      "CF Training: Epoch 0024 Iter 0260 / 0263 | Iter Loss 0.0265 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0024 Iter 0260 / 0263 | Iter Loss 0.0654 | Iter Mean Loss 0.0446\n",
      "CL Training: Epoch 0024 Iter 0260 / 0263 | Iter Loss 0.1025 | Iter Mean Loss 0.1028\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.236594 s\n",
      "Measure time: 0.017214 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 25, Hit Ratio:0.20319  |  Precision:0.12513  |  Recall:0.20548  |  NDCG:0.2101\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0025 Iter 0000 / 0263 | Iter Loss 0.0158 | Iter Mean Loss 0.0158\n",
      "KG Training: Epoch 0025 Iter 0000 / 0263 | Iter Loss 0.0298 | Iter Mean Loss 0.0298\n",
      "CL Training: Epoch 0025 Iter 0000 / 0263 | Iter Loss 0.1025 | Iter Mean Loss 0.1025\n",
      "CF Training: Epoch 0025 Iter 0020 / 0263 | Iter Loss 0.0201 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0025 Iter 0020 / 0263 | Iter Loss 0.0314 | Iter Mean Loss 0.0322\n",
      "CL Training: Epoch 0025 Iter 0020 / 0263 | Iter Loss 0.1028 | Iter Mean Loss 0.1029\n",
      "CF Training: Epoch 0025 Iter 0040 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0025 Iter 0040 / 0263 | Iter Loss 0.0344 | Iter Mean Loss 0.0334\n",
      "CL Training: Epoch 0025 Iter 0040 / 0263 | Iter Loss 0.1025 | Iter Mean Loss 0.1028\n",
      "CF Training: Epoch 0025 Iter 0060 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0025 Iter 0060 / 0263 | Iter Loss 0.0378 | Iter Mean Loss 0.0343\n",
      "CL Training: Epoch 0025 Iter 0060 / 0263 | Iter Loss 0.1021 | Iter Mean Loss 0.1026\n",
      "CF Training: Epoch 0025 Iter 0080 / 0263 | Iter Loss 0.0242 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0025 Iter 0080 / 0263 | Iter Loss 0.0387 | Iter Mean Loss 0.0351\n",
      "CL Training: Epoch 0025 Iter 0080 / 0263 | Iter Loss 0.1023 | Iter Mean Loss 0.1026\n",
      "CF Training: Epoch 0025 Iter 0100 / 0263 | Iter Loss 0.0151 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0025 Iter 0100 / 0263 | Iter Loss 0.0387 | Iter Mean Loss 0.0357\n",
      "CL Training: Epoch 0025 Iter 0100 / 0263 | Iter Loss 0.1019 | Iter Mean Loss 0.1025\n",
      "CF Training: Epoch 0025 Iter 0120 / 0263 | Iter Loss 0.0195 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0025 Iter 0120 / 0263 | Iter Loss 0.0466 | Iter Mean Loss 0.0366\n",
      "CL Training: Epoch 0025 Iter 0120 / 0263 | Iter Loss 0.1022 | Iter Mean Loss 0.1024\n",
      "CF Training: Epoch 0025 Iter 0140 / 0263 | Iter Loss 0.0224 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0025 Iter 0140 / 0263 | Iter Loss 0.0423 | Iter Mean Loss 0.0376\n",
      "CL Training: Epoch 0025 Iter 0140 / 0263 | Iter Loss 0.1017 | Iter Mean Loss 0.1024\n",
      "CF Training: Epoch 0025 Iter 0160 / 0263 | Iter Loss 0.0255 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0025 Iter 0160 / 0263 | Iter Loss 0.0474 | Iter Mean Loss 0.0388\n",
      "CL Training: Epoch 0025 Iter 0160 / 0263 | Iter Loss 0.1024 | Iter Mean Loss 0.1024\n",
      "CF Training: Epoch 0025 Iter 0180 / 0263 | Iter Loss 0.0227 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0025 Iter 0180 / 0263 | Iter Loss 0.0465 | Iter Mean Loss 0.0399\n",
      "CL Training: Epoch 0025 Iter 0180 / 0263 | Iter Loss 0.1026 | Iter Mean Loss 0.1024\n",
      "CF Training: Epoch 0025 Iter 0200 / 0263 | Iter Loss 0.0275 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0025 Iter 0200 / 0263 | Iter Loss 0.0495 | Iter Mean Loss 0.0411\n",
      "CL Training: Epoch 0025 Iter 0200 / 0263 | Iter Loss 0.1024 | Iter Mean Loss 0.1024\n",
      "CF Training: Epoch 0025 Iter 0220 / 0263 | Iter Loss 0.0202 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0025 Iter 0220 / 0263 | Iter Loss 0.0533 | Iter Mean Loss 0.0422\n",
      "CL Training: Epoch 0025 Iter 0220 / 0263 | Iter Loss 0.1022 | Iter Mean Loss 0.1024\n",
      "CF Training: Epoch 0025 Iter 0240 / 0263 | Iter Loss 0.0193 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0025 Iter 0240 / 0263 | Iter Loss 0.0564 | Iter Mean Loss 0.0433\n",
      "CL Training: Epoch 0025 Iter 0240 / 0263 | Iter Loss 0.1023 | Iter Mean Loss 0.1024\n",
      "CF Training: Epoch 0025 Iter 0260 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0025 Iter 0260 / 0263 | Iter Loss 0.0670 | Iter Mean Loss 0.0446\n",
      "CL Training: Epoch 0025 Iter 0260 / 0263 | Iter Loss 0.1025 | Iter Mean Loss 0.1024\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.235999 s\n",
      "Measure time: 0.017210 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 26, Hit Ratio:0.21116  |  Precision:0.13004  |  Recall:0.21288  |  NDCG:0.22428\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0026 Iter 0000 / 0263 | Iter Loss 0.0191 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0026 Iter 0000 / 0263 | Iter Loss 0.0277 | Iter Mean Loss 0.0277\n",
      "CL Training: Epoch 0026 Iter 0000 / 0263 | Iter Loss 0.1023 | Iter Mean Loss 0.1023\n",
      "CF Training: Epoch 0026 Iter 0020 / 0263 | Iter Loss 0.0200 | Iter Mean Loss 0.0210\n",
      "KG Training: Epoch 0026 Iter 0020 / 0263 | Iter Loss 0.0317 | Iter Mean Loss 0.0321\n",
      "CL Training: Epoch 0026 Iter 0020 / 0263 | Iter Loss 0.1028 | Iter Mean Loss 0.1026\n",
      "CF Training: Epoch 0026 Iter 0040 / 0263 | Iter Loss 0.0206 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0026 Iter 0040 / 0263 | Iter Loss 0.0362 | Iter Mean Loss 0.0334\n",
      "CL Training: Epoch 0026 Iter 0040 / 0263 | Iter Loss 0.1022 | Iter Mean Loss 0.1025\n",
      "CF Training: Epoch 0026 Iter 0060 / 0263 | Iter Loss 0.0183 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0026 Iter 0060 / 0263 | Iter Loss 0.0343 | Iter Mean Loss 0.0340\n",
      "CL Training: Epoch 0026 Iter 0060 / 0263 | Iter Loss 0.1023 | Iter Mean Loss 0.1024\n",
      "CF Training: Epoch 0026 Iter 0080 / 0263 | Iter Loss 0.0214 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0026 Iter 0080 / 0263 | Iter Loss 0.0359 | Iter Mean Loss 0.0345\n",
      "CL Training: Epoch 0026 Iter 0080 / 0263 | Iter Loss 0.1021 | Iter Mean Loss 0.1023\n",
      "CF Training: Epoch 0026 Iter 0100 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0026 Iter 0100 / 0263 | Iter Loss 0.0434 | Iter Mean Loss 0.0352\n",
      "CL Training: Epoch 0026 Iter 0100 / 0263 | Iter Loss 0.1022 | Iter Mean Loss 0.1023\n",
      "CF Training: Epoch 0026 Iter 0120 / 0263 | Iter Loss 0.0209 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0026 Iter 0120 / 0263 | Iter Loss 0.0420 | Iter Mean Loss 0.0362\n",
      "CL Training: Epoch 0026 Iter 0120 / 0263 | Iter Loss 0.1019 | Iter Mean Loss 0.1023\n",
      "CF Training: Epoch 0026 Iter 0140 / 0263 | Iter Loss 0.0193 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0026 Iter 0140 / 0263 | Iter Loss 0.0457 | Iter Mean Loss 0.0371\n",
      "CL Training: Epoch 0026 Iter 0140 / 0263 | Iter Loss 0.1019 | Iter Mean Loss 0.1022\n",
      "CF Training: Epoch 0026 Iter 0160 / 0263 | Iter Loss 0.0188 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0026 Iter 0160 / 0263 | Iter Loss 0.0490 | Iter Mean Loss 0.0384\n",
      "CL Training: Epoch 0026 Iter 0160 / 0263 | Iter Loss 0.1020 | Iter Mean Loss 0.1022\n",
      "CF Training: Epoch 0026 Iter 0180 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0026 Iter 0180 / 0263 | Iter Loss 0.0508 | Iter Mean Loss 0.0395\n",
      "CL Training: Epoch 0026 Iter 0180 / 0263 | Iter Loss 0.1020 | Iter Mean Loss 0.1022\n",
      "CF Training: Epoch 0026 Iter 0200 / 0263 | Iter Loss 0.0161 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0026 Iter 0200 / 0263 | Iter Loss 0.0539 | Iter Mean Loss 0.0407\n",
      "CL Training: Epoch 0026 Iter 0200 / 0263 | Iter Loss 0.1018 | Iter Mean Loss 0.1021\n",
      "CF Training: Epoch 0026 Iter 0220 / 0263 | Iter Loss 0.0236 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0026 Iter 0220 / 0263 | Iter Loss 0.0502 | Iter Mean Loss 0.0417\n",
      "CL Training: Epoch 0026 Iter 0220 / 0263 | Iter Loss 0.1021 | Iter Mean Loss 0.1021\n",
      "CF Training: Epoch 0026 Iter 0240 / 0263 | Iter Loss 0.0174 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0026 Iter 0240 / 0263 | Iter Loss 0.0519 | Iter Mean Loss 0.0426\n",
      "CL Training: Epoch 0026 Iter 0240 / 0263 | Iter Loss 0.1019 | Iter Mean Loss 0.1021\n",
      "CF Training: Epoch 0026 Iter 0260 / 0263 | Iter Loss 0.0225 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0026 Iter 0260 / 0263 | Iter Loss 0.0661 | Iter Mean Loss 0.0439\n",
      "CL Training: Epoch 0026 Iter 0260 / 0263 | Iter Loss 0.1019 | Iter Mean Loss 0.1021\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.235140 s\n",
      "Measure time: 0.016912 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 27, Hit Ratio:0.19983  |  Precision:0.12306  |  Recall:0.20253  |  NDCG:0.20684\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0027 Iter 0000 / 0263 | Iter Loss 0.0161 | Iter Mean Loss 0.0161\n",
      "KG Training: Epoch 0027 Iter 0000 / 0263 | Iter Loss 0.0274 | Iter Mean Loss 0.0274\n",
      "CL Training: Epoch 0027 Iter 0000 / 0263 | Iter Loss 0.1025 | Iter Mean Loss 0.1025\n",
      "CF Training: Epoch 0027 Iter 0020 / 0263 | Iter Loss 0.0202 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0027 Iter 0020 / 0263 | Iter Loss 0.0331 | Iter Mean Loss 0.0308\n",
      "CL Training: Epoch 0027 Iter 0020 / 0263 | Iter Loss 0.1022 | Iter Mean Loss 0.1026\n",
      "CF Training: Epoch 0027 Iter 0040 / 0263 | Iter Loss 0.0197 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0027 Iter 0040 / 0263 | Iter Loss 0.0339 | Iter Mean Loss 0.0322\n",
      "CL Training: Epoch 0027 Iter 0040 / 0263 | Iter Loss 0.1020 | Iter Mean Loss 0.1023\n",
      "CF Training: Epoch 0027 Iter 0060 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0027 Iter 0060 / 0263 | Iter Loss 0.0336 | Iter Mean Loss 0.0330\n",
      "CL Training: Epoch 0027 Iter 0060 / 0263 | Iter Loss 0.1020 | Iter Mean Loss 0.1022\n",
      "CF Training: Epoch 0027 Iter 0080 / 0263 | Iter Loss 0.0174 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0027 Iter 0080 / 0263 | Iter Loss 0.0351 | Iter Mean Loss 0.0336\n",
      "CL Training: Epoch 0027 Iter 0080 / 0263 | Iter Loss 0.1015 | Iter Mean Loss 0.1020\n",
      "CF Training: Epoch 0027 Iter 0100 / 0263 | Iter Loss 0.0235 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0027 Iter 0100 / 0263 | Iter Loss 0.0389 | Iter Mean Loss 0.0342\n",
      "CL Training: Epoch 0027 Iter 0100 / 0263 | Iter Loss 0.1018 | Iter Mean Loss 0.1020\n",
      "CF Training: Epoch 0027 Iter 0120 / 0263 | Iter Loss 0.0243 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0027 Iter 0120 / 0263 | Iter Loss 0.0426 | Iter Mean Loss 0.0352\n",
      "CL Training: Epoch 0027 Iter 0120 / 0263 | Iter Loss 0.1016 | Iter Mean Loss 0.1019\n",
      "CF Training: Epoch 0027 Iter 0140 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0027 Iter 0140 / 0263 | Iter Loss 0.0428 | Iter Mean Loss 0.0363\n",
      "CL Training: Epoch 0027 Iter 0140 / 0263 | Iter Loss 0.1019 | Iter Mean Loss 0.1019\n",
      "CF Training: Epoch 0027 Iter 0160 / 0263 | Iter Loss 0.0230 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0027 Iter 0160 / 0263 | Iter Loss 0.0488 | Iter Mean Loss 0.0376\n",
      "CL Training: Epoch 0027 Iter 0160 / 0263 | Iter Loss 0.1013 | Iter Mean Loss 0.1018\n",
      "CF Training: Epoch 0027 Iter 0180 / 0263 | Iter Loss 0.0302 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0027 Iter 0180 / 0263 | Iter Loss 0.0495 | Iter Mean Loss 0.0387\n",
      "CL Training: Epoch 0027 Iter 0180 / 0263 | Iter Loss 0.1016 | Iter Mean Loss 0.1018\n",
      "CF Training: Epoch 0027 Iter 0200 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0027 Iter 0200 / 0263 | Iter Loss 0.0496 | Iter Mean Loss 0.0397\n",
      "CL Training: Epoch 0027 Iter 0200 / 0263 | Iter Loss 0.1020 | Iter Mean Loss 0.1018\n",
      "CF Training: Epoch 0027 Iter 0220 / 0263 | Iter Loss 0.0145 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0027 Iter 0220 / 0263 | Iter Loss 0.0481 | Iter Mean Loss 0.0407\n",
      "CL Training: Epoch 0027 Iter 0220 / 0263 | Iter Loss 0.1018 | Iter Mean Loss 0.1018\n",
      "CF Training: Epoch 0027 Iter 0240 / 0263 | Iter Loss 0.0225 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0027 Iter 0240 / 0263 | Iter Loss 0.0516 | Iter Mean Loss 0.0416\n",
      "CL Training: Epoch 0027 Iter 0240 / 0263 | Iter Loss 0.1021 | Iter Mean Loss 0.1018\n",
      "CF Training: Epoch 0027 Iter 0260 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0027 Iter 0260 / 0263 | Iter Loss 0.0704 | Iter Mean Loss 0.0427\n",
      "CL Training: Epoch 0027 Iter 0260 / 0263 | Iter Loss 0.1016 | Iter Mean Loss 0.1017\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.230730 s\n",
      "Measure time: 0.017233 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 28, Hit Ratio:0.2109  |  Precision:0.12988  |  Recall:0.21331  |  NDCG:0.22273\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0028 Iter 0000 / 0263 | Iter Loss 0.0235 | Iter Mean Loss 0.0235\n",
      "KG Training: Epoch 0028 Iter 0000 / 0263 | Iter Loss 0.0252 | Iter Mean Loss 0.0252\n",
      "CL Training: Epoch 0028 Iter 0000 / 0263 | Iter Loss 0.1017 | Iter Mean Loss 0.1017\n",
      "CF Training: Epoch 0028 Iter 0020 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0028 Iter 0020 / 0263 | Iter Loss 0.0320 | Iter Mean Loss 0.0302\n",
      "CL Training: Epoch 0028 Iter 0020 / 0263 | Iter Loss 0.1020 | Iter Mean Loss 0.1018\n",
      "CF Training: Epoch 0028 Iter 0040 / 0263 | Iter Loss 0.0233 | Iter Mean Loss 0.0195\n",
      "KG Training: Epoch 0028 Iter 0040 / 0263 | Iter Loss 0.0307 | Iter Mean Loss 0.0316\n",
      "CL Training: Epoch 0028 Iter 0040 / 0263 | Iter Loss 0.1014 | Iter Mean Loss 0.1017\n",
      "CF Training: Epoch 0028 Iter 0060 / 0263 | Iter Loss 0.0234 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0028 Iter 0060 / 0263 | Iter Loss 0.0326 | Iter Mean Loss 0.0326\n",
      "CL Training: Epoch 0028 Iter 0060 / 0263 | Iter Loss 0.1013 | Iter Mean Loss 0.1016\n",
      "CF Training: Epoch 0028 Iter 0080 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0028 Iter 0080 / 0263 | Iter Loss 0.0361 | Iter Mean Loss 0.0329\n",
      "CL Training: Epoch 0028 Iter 0080 / 0263 | Iter Loss 0.1014 | Iter Mean Loss 0.1016\n",
      "CF Training: Epoch 0028 Iter 0100 / 0263 | Iter Loss 0.0171 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0028 Iter 0100 / 0263 | Iter Loss 0.0364 | Iter Mean Loss 0.0337\n",
      "CL Training: Epoch 0028 Iter 0100 / 0263 | Iter Loss 0.1017 | Iter Mean Loss 0.1016\n",
      "CF Training: Epoch 0028 Iter 0120 / 0263 | Iter Loss 0.0192 | Iter Mean Loss 0.0197\n",
      "KG Training: Epoch 0028 Iter 0120 / 0263 | Iter Loss 0.0434 | Iter Mean Loss 0.0348\n",
      "CL Training: Epoch 0028 Iter 0120 / 0263 | Iter Loss 0.1013 | Iter Mean Loss 0.1015\n",
      "CF Training: Epoch 0028 Iter 0140 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0197\n",
      "KG Training: Epoch 0028 Iter 0140 / 0263 | Iter Loss 0.0514 | Iter Mean Loss 0.0360\n",
      "CL Training: Epoch 0028 Iter 0140 / 0263 | Iter Loss 0.1012 | Iter Mean Loss 0.1015\n",
      "CF Training: Epoch 0028 Iter 0160 / 0263 | Iter Loss 0.0289 | Iter Mean Loss 0.0197\n",
      "KG Training: Epoch 0028 Iter 0160 / 0263 | Iter Loss 0.0434 | Iter Mean Loss 0.0372\n",
      "CL Training: Epoch 0028 Iter 0160 / 0263 | Iter Loss 0.1013 | Iter Mean Loss 0.1014\n",
      "CF Training: Epoch 0028 Iter 0180 / 0263 | Iter Loss 0.0218 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0028 Iter 0180 / 0263 | Iter Loss 0.0537 | Iter Mean Loss 0.0384\n",
      "CL Training: Epoch 0028 Iter 0180 / 0263 | Iter Loss 0.1008 | Iter Mean Loss 0.1014\n",
      "CF Training: Epoch 0028 Iter 0200 / 0263 | Iter Loss 0.0224 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0028 Iter 0200 / 0263 | Iter Loss 0.0482 | Iter Mean Loss 0.0395\n",
      "CL Training: Epoch 0028 Iter 0200 / 0263 | Iter Loss 0.1011 | Iter Mean Loss 0.1014\n",
      "CF Training: Epoch 0028 Iter 0220 / 0263 | Iter Loss 0.0225 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0028 Iter 0220 / 0263 | Iter Loss 0.0495 | Iter Mean Loss 0.0405\n",
      "CL Training: Epoch 0028 Iter 0220 / 0263 | Iter Loss 0.1016 | Iter Mean Loss 0.1014\n",
      "CF Training: Epoch 0028 Iter 0240 / 0263 | Iter Loss 0.0188 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0028 Iter 0240 / 0263 | Iter Loss 0.0543 | Iter Mean Loss 0.0415\n",
      "CL Training: Epoch 0028 Iter 0240 / 0263 | Iter Loss 0.1012 | Iter Mean Loss 0.1014\n",
      "CF Training: Epoch 0028 Iter 0260 / 0263 | Iter Loss 0.0276 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0028 Iter 0260 / 0263 | Iter Loss 0.0642 | Iter Mean Loss 0.0428\n",
      "CL Training: Epoch 0028 Iter 0260 / 0263 | Iter Loss 0.1012 | Iter Mean Loss 0.1013\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.234285 s\n",
      "Measure time: 0.026735 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 29, Hit Ratio:0.20022  |  Precision:0.1233  |  Recall:0.20249  |  NDCG:0.20896\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0029 Iter 0000 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0164\n",
      "KG Training: Epoch 0029 Iter 0000 / 0263 | Iter Loss 0.0275 | Iter Mean Loss 0.0275\n",
      "CL Training: Epoch 0029 Iter 0000 / 0263 | Iter Loss 0.1012 | Iter Mean Loss 0.1012\n",
      "CF Training: Epoch 0029 Iter 0020 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0029 Iter 0020 / 0263 | Iter Loss 0.0326 | Iter Mean Loss 0.0301\n",
      "CL Training: Epoch 0029 Iter 0020 / 0263 | Iter Loss 0.1016 | Iter Mean Loss 0.1016\n",
      "CF Training: Epoch 0029 Iter 0040 / 0263 | Iter Loss 0.0283 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0029 Iter 0040 / 0263 | Iter Loss 0.0305 | Iter Mean Loss 0.0316\n",
      "CL Training: Epoch 0029 Iter 0040 / 0263 | Iter Loss 0.1010 | Iter Mean Loss 0.1014\n",
      "CF Training: Epoch 0029 Iter 0060 / 0263 | Iter Loss 0.0124 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0029 Iter 0060 / 0263 | Iter Loss 0.0347 | Iter Mean Loss 0.0324\n",
      "CL Training: Epoch 0029 Iter 0060 / 0263 | Iter Loss 0.1009 | Iter Mean Loss 0.1013\n",
      "CF Training: Epoch 0029 Iter 0080 / 0263 | Iter Loss 0.0216 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0029 Iter 0080 / 0263 | Iter Loss 0.0350 | Iter Mean Loss 0.0329\n",
      "CL Training: Epoch 0029 Iter 0080 / 0263 | Iter Loss 0.1009 | Iter Mean Loss 0.1012\n",
      "CF Training: Epoch 0029 Iter 0100 / 0263 | Iter Loss 0.0159 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0029 Iter 0100 / 0263 | Iter Loss 0.0365 | Iter Mean Loss 0.0339\n",
      "CL Training: Epoch 0029 Iter 0100 / 0263 | Iter Loss 0.1014 | Iter Mean Loss 0.1012\n",
      "CF Training: Epoch 0029 Iter 0120 / 0263 | Iter Loss 0.0251 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0029 Iter 0120 / 0263 | Iter Loss 0.0376 | Iter Mean Loss 0.0347\n",
      "CL Training: Epoch 0029 Iter 0120 / 0263 | Iter Loss 0.1009 | Iter Mean Loss 0.1011\n",
      "CF Training: Epoch 0029 Iter 0140 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0207\n",
      "KG Training: Epoch 0029 Iter 0140 / 0263 | Iter Loss 0.0455 | Iter Mean Loss 0.0359\n",
      "CL Training: Epoch 0029 Iter 0140 / 0263 | Iter Loss 0.1008 | Iter Mean Loss 0.1011\n",
      "CF Training: Epoch 0029 Iter 0160 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0029 Iter 0160 / 0263 | Iter Loss 0.0452 | Iter Mean Loss 0.0369\n",
      "CL Training: Epoch 0029 Iter 0160 / 0263 | Iter Loss 0.1008 | Iter Mean Loss 0.1011\n",
      "CF Training: Epoch 0029 Iter 0180 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0029 Iter 0180 / 0263 | Iter Loss 0.0438 | Iter Mean Loss 0.0379\n",
      "CL Training: Epoch 0029 Iter 0180 / 0263 | Iter Loss 0.1007 | Iter Mean Loss 0.1010\n",
      "CF Training: Epoch 0029 Iter 0200 / 0263 | Iter Loss 0.0274 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0029 Iter 0200 / 0263 | Iter Loss 0.0528 | Iter Mean Loss 0.0390\n",
      "CL Training: Epoch 0029 Iter 0200 / 0263 | Iter Loss 0.1007 | Iter Mean Loss 0.1010\n",
      "CF Training: Epoch 0029 Iter 0220 / 0263 | Iter Loss 0.0123 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0029 Iter 0220 / 0263 | Iter Loss 0.0497 | Iter Mean Loss 0.0401\n",
      "CL Training: Epoch 0029 Iter 0220 / 0263 | Iter Loss 0.1004 | Iter Mean Loss 0.1010\n",
      "CF Training: Epoch 0029 Iter 0240 / 0263 | Iter Loss 0.0213 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0029 Iter 0240 / 0263 | Iter Loss 0.0528 | Iter Mean Loss 0.0411\n",
      "CL Training: Epoch 0029 Iter 0240 / 0263 | Iter Loss 0.1012 | Iter Mean Loss 0.1009\n",
      "CF Training: Epoch 0029 Iter 0260 / 0263 | Iter Loss 0.0204 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0029 Iter 0260 / 0263 | Iter Loss 0.0618 | Iter Mean Loss 0.0422\n",
      "CL Training: Epoch 0029 Iter 0260 / 0263 | Iter Loss 0.1011 | Iter Mean Loss 0.1009\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.237445 s\n",
      "Measure time: 0.016760 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 30, Hit Ratio:0.20345  |  Precision:0.12529  |  Recall:0.20534  |  NDCG:0.21075\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0030 Iter 0000 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0160\n",
      "KG Training: Epoch 0030 Iter 0000 / 0263 | Iter Loss 0.0249 | Iter Mean Loss 0.0249\n",
      "CL Training: Epoch 0030 Iter 0000 / 0263 | Iter Loss 0.1012 | Iter Mean Loss 0.1012\n",
      "CF Training: Epoch 0030 Iter 0020 / 0263 | Iter Loss 0.0236 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0030 Iter 0020 / 0263 | Iter Loss 0.0338 | Iter Mean Loss 0.0303\n",
      "CL Training: Epoch 0030 Iter 0020 / 0263 | Iter Loss 0.1013 | Iter Mean Loss 0.1013\n",
      "CF Training: Epoch 0030 Iter 0040 / 0263 | Iter Loss 0.0231 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0030 Iter 0040 / 0263 | Iter Loss 0.0344 | Iter Mean Loss 0.0315\n",
      "CL Training: Epoch 0030 Iter 0040 / 0263 | Iter Loss 0.1007 | Iter Mean Loss 0.1011\n",
      "CF Training: Epoch 0030 Iter 0060 / 0263 | Iter Loss 0.0191 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0030 Iter 0060 / 0263 | Iter Loss 0.0359 | Iter Mean Loss 0.0322\n",
      "CL Training: Epoch 0030 Iter 0060 / 0263 | Iter Loss 0.1006 | Iter Mean Loss 0.1010\n",
      "CF Training: Epoch 0030 Iter 0080 / 0263 | Iter Loss 0.0213 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0030 Iter 0080 / 0263 | Iter Loss 0.0322 | Iter Mean Loss 0.0326\n",
      "CL Training: Epoch 0030 Iter 0080 / 0263 | Iter Loss 0.1007 | Iter Mean Loss 0.1009\n",
      "CF Training: Epoch 0030 Iter 0100 / 0263 | Iter Loss 0.0167 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0030 Iter 0100 / 0263 | Iter Loss 0.0357 | Iter Mean Loss 0.0332\n",
      "CL Training: Epoch 0030 Iter 0100 / 0263 | Iter Loss 0.1007 | Iter Mean Loss 0.1008\n",
      "CF Training: Epoch 0030 Iter 0120 / 0263 | Iter Loss 0.0202 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0030 Iter 0120 / 0263 | Iter Loss 0.0386 | Iter Mean Loss 0.0344\n",
      "CL Training: Epoch 0030 Iter 0120 / 0263 | Iter Loss 0.1008 | Iter Mean Loss 0.1009\n",
      "CF Training: Epoch 0030 Iter 0140 / 0263 | Iter Loss 0.0259 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0030 Iter 0140 / 0263 | Iter Loss 0.0419 | Iter Mean Loss 0.0355\n",
      "CL Training: Epoch 0030 Iter 0140 / 0263 | Iter Loss 0.1003 | Iter Mean Loss 0.1008\n",
      "CF Training: Epoch 0030 Iter 0160 / 0263 | Iter Loss 0.0209 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0030 Iter 0160 / 0263 | Iter Loss 0.0471 | Iter Mean Loss 0.0366\n",
      "CL Training: Epoch 0030 Iter 0160 / 0263 | Iter Loss 0.1008 | Iter Mean Loss 0.1008\n",
      "CF Training: Epoch 0030 Iter 0180 / 0263 | Iter Loss 0.0173 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0030 Iter 0180 / 0263 | Iter Loss 0.0453 | Iter Mean Loss 0.0377\n",
      "CL Training: Epoch 0030 Iter 0180 / 0263 | Iter Loss 0.1004 | Iter Mean Loss 0.1007\n",
      "CF Training: Epoch 0030 Iter 0200 / 0263 | Iter Loss 0.0196 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0030 Iter 0200 / 0263 | Iter Loss 0.0480 | Iter Mean Loss 0.0386\n",
      "CL Training: Epoch 0030 Iter 0200 / 0263 | Iter Loss 0.1008 | Iter Mean Loss 0.1007\n",
      "CF Training: Epoch 0030 Iter 0220 / 0263 | Iter Loss 0.0129 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0030 Iter 0220 / 0263 | Iter Loss 0.0471 | Iter Mean Loss 0.0397\n",
      "CL Training: Epoch 0030 Iter 0220 / 0263 | Iter Loss 0.1004 | Iter Mean Loss 0.1007\n",
      "CF Training: Epoch 0030 Iter 0240 / 0263 | Iter Loss 0.0149 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0030 Iter 0240 / 0263 | Iter Loss 0.0553 | Iter Mean Loss 0.0408\n",
      "CL Training: Epoch 0030 Iter 0240 / 0263 | Iter Loss 0.1003 | Iter Mean Loss 0.1007\n",
      "CF Training: Epoch 0030 Iter 0260 / 0263 | Iter Loss 0.0273 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0030 Iter 0260 / 0263 | Iter Loss 0.0596 | Iter Mean Loss 0.0420\n",
      "CL Training: Epoch 0030 Iter 0260 / 0263 | Iter Loss 0.1006 | Iter Mean Loss 0.1007\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.231028 s\n",
      "Measure time: 0.017354 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 31, Hit Ratio:0.20784  |  Precision:0.128  |  Recall:0.21042  |  NDCG:0.21538\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0031 Iter 0000 / 0263 | Iter Loss 0.0316 | Iter Mean Loss 0.0316\n",
      "KG Training: Epoch 0031 Iter 0000 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0246\n",
      "CL Training: Epoch 0031 Iter 0000 / 0263 | Iter Loss 0.1009 | Iter Mean Loss 0.1009\n",
      "CF Training: Epoch 0031 Iter 0020 / 0263 | Iter Loss 0.0222 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0031 Iter 0020 / 0263 | Iter Loss 0.0297 | Iter Mean Loss 0.0297\n",
      "CL Training: Epoch 0031 Iter 0020 / 0263 | Iter Loss 0.1009 | Iter Mean Loss 0.1008\n",
      "CF Training: Epoch 0031 Iter 0040 / 0263 | Iter Loss 0.0231 | Iter Mean Loss 0.0195\n",
      "KG Training: Epoch 0031 Iter 0040 / 0263 | Iter Loss 0.0309 | Iter Mean Loss 0.0311\n",
      "CL Training: Epoch 0031 Iter 0040 / 0263 | Iter Loss 0.1011 | Iter Mean Loss 0.1009\n",
      "CF Training: Epoch 0031 Iter 0060 / 0263 | Iter Loss 0.0188 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0031 Iter 0060 / 0263 | Iter Loss 0.0314 | Iter Mean Loss 0.0319\n",
      "CL Training: Epoch 0031 Iter 0060 / 0263 | Iter Loss 0.1005 | Iter Mean Loss 0.1008\n",
      "CF Training: Epoch 0031 Iter 0080 / 0263 | Iter Loss 0.0139 | Iter Mean Loss 0.0197\n",
      "KG Training: Epoch 0031 Iter 0080 / 0263 | Iter Loss 0.0323 | Iter Mean Loss 0.0324\n",
      "CL Training: Epoch 0031 Iter 0080 / 0263 | Iter Loss 0.1005 | Iter Mean Loss 0.1008\n",
      "CF Training: Epoch 0031 Iter 0100 / 0263 | Iter Loss 0.0190 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0031 Iter 0100 / 0263 | Iter Loss 0.0385 | Iter Mean Loss 0.0332\n",
      "CL Training: Epoch 0031 Iter 0100 / 0263 | Iter Loss 0.1002 | Iter Mean Loss 0.1007\n",
      "CF Training: Epoch 0031 Iter 0120 / 0263 | Iter Loss 0.0226 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0031 Iter 0120 / 0263 | Iter Loss 0.0488 | Iter Mean Loss 0.0343\n",
      "CL Training: Epoch 0031 Iter 0120 / 0263 | Iter Loss 0.0999 | Iter Mean Loss 0.1006\n",
      "CF Training: Epoch 0031 Iter 0140 / 0263 | Iter Loss 0.0200 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0031 Iter 0140 / 0263 | Iter Loss 0.0407 | Iter Mean Loss 0.0353\n",
      "CL Training: Epoch 0031 Iter 0140 / 0263 | Iter Loss 0.1001 | Iter Mean Loss 0.1005\n",
      "CF Training: Epoch 0031 Iter 0160 / 0263 | Iter Loss 0.0371 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0031 Iter 0160 / 0263 | Iter Loss 0.0437 | Iter Mean Loss 0.0366\n",
      "CL Training: Epoch 0031 Iter 0160 / 0263 | Iter Loss 0.1002 | Iter Mean Loss 0.1005\n",
      "CF Training: Epoch 0031 Iter 0180 / 0263 | Iter Loss 0.0212 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0031 Iter 0180 / 0263 | Iter Loss 0.0507 | Iter Mean Loss 0.0377\n",
      "CL Training: Epoch 0031 Iter 0180 / 0263 | Iter Loss 0.1005 | Iter Mean Loss 0.1005\n",
      "CF Training: Epoch 0031 Iter 0200 / 0263 | Iter Loss 0.0266 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0031 Iter 0200 / 0263 | Iter Loss 0.0490 | Iter Mean Loss 0.0388\n",
      "CL Training: Epoch 0031 Iter 0200 / 0263 | Iter Loss 0.0999 | Iter Mean Loss 0.1004\n",
      "CF Training: Epoch 0031 Iter 0220 / 0263 | Iter Loss 0.0122 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0031 Iter 0220 / 0263 | Iter Loss 0.0515 | Iter Mean Loss 0.0399\n",
      "CL Training: Epoch 0031 Iter 0220 / 0263 | Iter Loss 0.1006 | Iter Mean Loss 0.1004\n",
      "CF Training: Epoch 0031 Iter 0240 / 0263 | Iter Loss 0.0260 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0031 Iter 0240 / 0263 | Iter Loss 0.0515 | Iter Mean Loss 0.0410\n",
      "CL Training: Epoch 0031 Iter 0240 / 0263 | Iter Loss 0.1006 | Iter Mean Loss 0.1004\n",
      "CF Training: Epoch 0031 Iter 0260 / 0263 | Iter Loss 0.0252 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0031 Iter 0260 / 0263 | Iter Loss 0.0685 | Iter Mean Loss 0.0423\n",
      "CL Training: Epoch 0031 Iter 0260 / 0263 | Iter Loss 0.1007 | Iter Mean Loss 0.1004\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.235470 s\n",
      "Measure time: 0.017354 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 32, Hit Ratio:0.19595  |  Precision:0.12067  |  Recall:0.19849  |  NDCG:0.20237\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0032 Iter 0000 / 0263 | Iter Loss 0.0201 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0032 Iter 0000 / 0263 | Iter Loss 0.0253 | Iter Mean Loss 0.0253\n",
      "CL Training: Epoch 0032 Iter 0000 / 0263 | Iter Loss 0.1013 | Iter Mean Loss 0.1013\n",
      "CF Training: Epoch 0032 Iter 0020 / 0263 | Iter Loss 0.0185 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0032 Iter 0020 / 0263 | Iter Loss 0.0319 | Iter Mean Loss 0.0293\n",
      "CL Training: Epoch 0032 Iter 0020 / 0263 | Iter Loss 0.1007 | Iter Mean Loss 0.1009\n",
      "CF Training: Epoch 0032 Iter 0040 / 0263 | Iter Loss 0.0229 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0032 Iter 0040 / 0263 | Iter Loss 0.0312 | Iter Mean Loss 0.0308\n",
      "CL Training: Epoch 0032 Iter 0040 / 0263 | Iter Loss 0.0999 | Iter Mean Loss 0.1006\n",
      "CF Training: Epoch 0032 Iter 0060 / 0263 | Iter Loss 0.0134 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0032 Iter 0060 / 0263 | Iter Loss 0.0352 | Iter Mean Loss 0.0320\n",
      "CL Training: Epoch 0032 Iter 0060 / 0263 | Iter Loss 0.1003 | Iter Mean Loss 0.1005\n",
      "CF Training: Epoch 0032 Iter 0080 / 0263 | Iter Loss 0.0206 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0032 Iter 0080 / 0263 | Iter Loss 0.0380 | Iter Mean Loss 0.0328\n",
      "CL Training: Epoch 0032 Iter 0080 / 0263 | Iter Loss 0.1001 | Iter Mean Loss 0.1004\n",
      "CF Training: Epoch 0032 Iter 0100 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0032 Iter 0100 / 0263 | Iter Loss 0.0360 | Iter Mean Loss 0.0332\n",
      "CL Training: Epoch 0032 Iter 0100 / 0263 | Iter Loss 0.0999 | Iter Mean Loss 0.1003\n",
      "CF Training: Epoch 0032 Iter 0120 / 0263 | Iter Loss 0.0194 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0032 Iter 0120 / 0263 | Iter Loss 0.0390 | Iter Mean Loss 0.0342\n",
      "CL Training: Epoch 0032 Iter 0120 / 0263 | Iter Loss 0.0997 | Iter Mean Loss 0.1003\n",
      "CF Training: Epoch 0032 Iter 0140 / 0263 | Iter Loss 0.0237 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0032 Iter 0140 / 0263 | Iter Loss 0.0440 | Iter Mean Loss 0.0352\n",
      "CL Training: Epoch 0032 Iter 0140 / 0263 | Iter Loss 0.0996 | Iter Mean Loss 0.1002\n",
      "CF Training: Epoch 0032 Iter 0160 / 0263 | Iter Loss 0.0253 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0032 Iter 0160 / 0263 | Iter Loss 0.0513 | Iter Mean Loss 0.0363\n",
      "CL Training: Epoch 0032 Iter 0160 / 0263 | Iter Loss 0.0999 | Iter Mean Loss 0.1002\n",
      "CF Training: Epoch 0032 Iter 0180 / 0263 | Iter Loss 0.0233 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0032 Iter 0180 / 0263 | Iter Loss 0.0450 | Iter Mean Loss 0.0372\n",
      "CL Training: Epoch 0032 Iter 0180 / 0263 | Iter Loss 0.0998 | Iter Mean Loss 0.1001\n",
      "CF Training: Epoch 0032 Iter 0200 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0032 Iter 0200 / 0263 | Iter Loss 0.0485 | Iter Mean Loss 0.0383\n",
      "CL Training: Epoch 0032 Iter 0200 / 0263 | Iter Loss 0.1004 | Iter Mean Loss 0.1001\n",
      "CF Training: Epoch 0032 Iter 0220 / 0263 | Iter Loss 0.0201 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0032 Iter 0220 / 0263 | Iter Loss 0.0495 | Iter Mean Loss 0.0393\n",
      "CL Training: Epoch 0032 Iter 0220 / 0263 | Iter Loss 0.1000 | Iter Mean Loss 0.1002\n",
      "CF Training: Epoch 0032 Iter 0240 / 0263 | Iter Loss 0.0212 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0032 Iter 0240 / 0263 | Iter Loss 0.0491 | Iter Mean Loss 0.0403\n",
      "CL Training: Epoch 0032 Iter 0240 / 0263 | Iter Loss 0.1000 | Iter Mean Loss 0.1002\n",
      "CF Training: Epoch 0032 Iter 0260 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0032 Iter 0260 / 0263 | Iter Loss 0.0586 | Iter Mean Loss 0.0415\n",
      "CL Training: Epoch 0032 Iter 0260 / 0263 | Iter Loss 0.1004 | Iter Mean Loss 0.1001\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.233717 s\n",
      "Measure time: 0.016951 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 33, Hit Ratio:0.1947  |  Precision:0.1199  |  Recall:0.19726  |  NDCG:0.1998\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0033 Iter 0000 / 0263 | Iter Loss 0.0225 | Iter Mean Loss 0.0225\n",
      "KG Training: Epoch 0033 Iter 0000 / 0263 | Iter Loss 0.0257 | Iter Mean Loss 0.0257\n",
      "CL Training: Epoch 0033 Iter 0000 / 0263 | Iter Loss 0.0998 | Iter Mean Loss 0.0998\n",
      "CF Training: Epoch 0033 Iter 0020 / 0263 | Iter Loss 0.0163 | Iter Mean Loss 0.0197\n",
      "KG Training: Epoch 0033 Iter 0020 / 0263 | Iter Loss 0.0288 | Iter Mean Loss 0.0295\n",
      "CL Training: Epoch 0033 Iter 0020 / 0263 | Iter Loss 0.1006 | Iter Mean Loss 0.1003\n",
      "CF Training: Epoch 0033 Iter 0040 / 0263 | Iter Loss 0.0143 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0033 Iter 0040 / 0263 | Iter Loss 0.0292 | Iter Mean Loss 0.0303\n",
      "CL Training: Epoch 0033 Iter 0040 / 0263 | Iter Loss 0.0996 | Iter Mean Loss 0.1001\n",
      "CF Training: Epoch 0033 Iter 0060 / 0263 | Iter Loss 0.0212 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0033 Iter 0060 / 0263 | Iter Loss 0.0342 | Iter Mean Loss 0.0311\n",
      "CL Training: Epoch 0033 Iter 0060 / 0263 | Iter Loss 0.0999 | Iter Mean Loss 0.1000\n",
      "CF Training: Epoch 0033 Iter 0080 / 0263 | Iter Loss 0.0212 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0033 Iter 0080 / 0263 | Iter Loss 0.0326 | Iter Mean Loss 0.0317\n",
      "CL Training: Epoch 0033 Iter 0080 / 0263 | Iter Loss 0.0997 | Iter Mean Loss 0.1000\n",
      "CF Training: Epoch 0033 Iter 0100 / 0263 | Iter Loss 0.0171 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0033 Iter 0100 / 0263 | Iter Loss 0.0390 | Iter Mean Loss 0.0325\n",
      "CL Training: Epoch 0033 Iter 0100 / 0263 | Iter Loss 0.0999 | Iter Mean Loss 0.1000\n",
      "CF Training: Epoch 0033 Iter 0120 / 0263 | Iter Loss 0.0220 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0033 Iter 0120 / 0263 | Iter Loss 0.0385 | Iter Mean Loss 0.0337\n",
      "CL Training: Epoch 0033 Iter 0120 / 0263 | Iter Loss 0.0995 | Iter Mean Loss 0.1000\n",
      "CF Training: Epoch 0033 Iter 0140 / 0263 | Iter Loss 0.0292 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0033 Iter 0140 / 0263 | Iter Loss 0.0388 | Iter Mean Loss 0.0349\n",
      "CL Training: Epoch 0033 Iter 0140 / 0263 | Iter Loss 0.0997 | Iter Mean Loss 0.0999\n",
      "CF Training: Epoch 0033 Iter 0160 / 0263 | Iter Loss 0.0233 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0033 Iter 0160 / 0263 | Iter Loss 0.0494 | Iter Mean Loss 0.0360\n",
      "CL Training: Epoch 0033 Iter 0160 / 0263 | Iter Loss 0.0994 | Iter Mean Loss 0.0999\n",
      "CF Training: Epoch 0033 Iter 0180 / 0263 | Iter Loss 0.0192 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0033 Iter 0180 / 0263 | Iter Loss 0.0463 | Iter Mean Loss 0.0371\n",
      "CL Training: Epoch 0033 Iter 0180 / 0263 | Iter Loss 0.0995 | Iter Mean Loss 0.0998\n",
      "CF Training: Epoch 0033 Iter 0200 / 0263 | Iter Loss 0.0136 | Iter Mean Loss 0.0206\n",
      "KG Training: Epoch 0033 Iter 0200 / 0263 | Iter Loss 0.0507 | Iter Mean Loss 0.0382\n",
      "CL Training: Epoch 0033 Iter 0200 / 0263 | Iter Loss 0.0997 | Iter Mean Loss 0.0998\n",
      "CF Training: Epoch 0033 Iter 0220 / 0263 | Iter Loss 0.0197 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0033 Iter 0220 / 0263 | Iter Loss 0.0497 | Iter Mean Loss 0.0392\n",
      "CL Training: Epoch 0033 Iter 0220 / 0263 | Iter Loss 0.1000 | Iter Mean Loss 0.0998\n",
      "CF Training: Epoch 0033 Iter 0240 / 0263 | Iter Loss 0.0231 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0033 Iter 0240 / 0263 | Iter Loss 0.0501 | Iter Mean Loss 0.0402\n",
      "CL Training: Epoch 0033 Iter 0240 / 0263 | Iter Loss 0.0996 | Iter Mean Loss 0.0998\n",
      "CF Training: Epoch 0033 Iter 0260 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0204\n",
      "KG Training: Epoch 0033 Iter 0260 / 0263 | Iter Loss 0.0723 | Iter Mean Loss 0.0414\n",
      "CL Training: Epoch 0033 Iter 0260 / 0263 | Iter Loss 0.0999 | Iter Mean Loss 0.0998\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.235375 s\n",
      "Measure time: 0.017305 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 34, Hit Ratio:0.20802  |  Precision:0.12811  |  Recall:0.21088  |  NDCG:0.21575\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0034 Iter 0000 / 0263 | Iter Loss 0.0163 | Iter Mean Loss 0.0163\n",
      "KG Training: Epoch 0034 Iter 0000 / 0263 | Iter Loss 0.0242 | Iter Mean Loss 0.0242\n",
      "CL Training: Epoch 0034 Iter 0000 / 0263 | Iter Loss 0.1003 | Iter Mean Loss 0.1003\n",
      "CF Training: Epoch 0034 Iter 0020 / 0263 | Iter Loss 0.0151 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0034 Iter 0020 / 0263 | Iter Loss 0.0296 | Iter Mean Loss 0.0290\n",
      "CL Training: Epoch 0034 Iter 0020 / 0263 | Iter Loss 0.1001 | Iter Mean Loss 0.1003\n",
      "CF Training: Epoch 0034 Iter 0040 / 0263 | Iter Loss 0.0185 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0034 Iter 0040 / 0263 | Iter Loss 0.0332 | Iter Mean Loss 0.0302\n",
      "CL Training: Epoch 0034 Iter 0040 / 0263 | Iter Loss 0.0998 | Iter Mean Loss 0.1002\n",
      "CF Training: Epoch 0034 Iter 0060 / 0263 | Iter Loss 0.0196 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0034 Iter 0060 / 0263 | Iter Loss 0.0344 | Iter Mean Loss 0.0310\n",
      "CL Training: Epoch 0034 Iter 0060 / 0263 | Iter Loss 0.0995 | Iter Mean Loss 0.1000\n",
      "CF Training: Epoch 0034 Iter 0080 / 0263 | Iter Loss 0.0209 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0034 Iter 0080 / 0263 | Iter Loss 0.0343 | Iter Mean Loss 0.0316\n",
      "CL Training: Epoch 0034 Iter 0080 / 0263 | Iter Loss 0.0996 | Iter Mean Loss 0.0999\n",
      "CF Training: Epoch 0034 Iter 0100 / 0263 | Iter Loss 0.0226 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0034 Iter 0100 / 0263 | Iter Loss 0.0366 | Iter Mean Loss 0.0326\n",
      "CL Training: Epoch 0034 Iter 0100 / 0263 | Iter Loss 0.0999 | Iter Mean Loss 0.0998\n",
      "CF Training: Epoch 0034 Iter 0120 / 0263 | Iter Loss 0.0159 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0034 Iter 0120 / 0263 | Iter Loss 0.0418 | Iter Mean Loss 0.0337\n",
      "CL Training: Epoch 0034 Iter 0120 / 0263 | Iter Loss 0.0992 | Iter Mean Loss 0.0998\n",
      "CF Training: Epoch 0034 Iter 0140 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0034 Iter 0140 / 0263 | Iter Loss 0.0467 | Iter Mean Loss 0.0348\n",
      "CL Training: Epoch 0034 Iter 0140 / 0263 | Iter Loss 0.0996 | Iter Mean Loss 0.0997\n",
      "CF Training: Epoch 0034 Iter 0160 / 0263 | Iter Loss 0.0146 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0034 Iter 0160 / 0263 | Iter Loss 0.0528 | Iter Mean Loss 0.0360\n",
      "CL Training: Epoch 0034 Iter 0160 / 0263 | Iter Loss 0.0994 | Iter Mean Loss 0.0997\n",
      "CF Training: Epoch 0034 Iter 0180 / 0263 | Iter Loss 0.0227 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0034 Iter 0180 / 0263 | Iter Loss 0.0467 | Iter Mean Loss 0.0369\n",
      "CL Training: Epoch 0034 Iter 0180 / 0263 | Iter Loss 0.0993 | Iter Mean Loss 0.0996\n",
      "CF Training: Epoch 0034 Iter 0200 / 0263 | Iter Loss 0.0166 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0034 Iter 0200 / 0263 | Iter Loss 0.0533 | Iter Mean Loss 0.0379\n",
      "CL Training: Epoch 0034 Iter 0200 / 0263 | Iter Loss 0.0993 | Iter Mean Loss 0.0996\n",
      "CF Training: Epoch 0034 Iter 0220 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0034 Iter 0220 / 0263 | Iter Loss 0.0515 | Iter Mean Loss 0.0389\n",
      "CL Training: Epoch 0034 Iter 0220 / 0263 | Iter Loss 0.0993 | Iter Mean Loss 0.0996\n",
      "CF Training: Epoch 0034 Iter 0240 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0034 Iter 0240 / 0263 | Iter Loss 0.0501 | Iter Mean Loss 0.0399\n",
      "CL Training: Epoch 0034 Iter 0240 / 0263 | Iter Loss 0.1000 | Iter Mean Loss 0.0996\n",
      "CF Training: Epoch 0034 Iter 0260 / 0263 | Iter Loss 0.0123 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0034 Iter 0260 / 0263 | Iter Loss 0.0610 | Iter Mean Loss 0.0410\n",
      "CL Training: Epoch 0034 Iter 0260 / 0263 | Iter Loss 0.0997 | Iter Mean Loss 0.0996\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.233818 s\n",
      "Measure time: 0.016978 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 35, Hit Ratio:0.19823  |  Precision:0.12208  |  Recall:0.20001  |  NDCG:0.20654\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0035 Iter 0000 / 0263 | Iter Loss 0.0188 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0035 Iter 0000 / 0263 | Iter Loss 0.0243 | Iter Mean Loss 0.0243\n",
      "CL Training: Epoch 0035 Iter 0000 / 0263 | Iter Loss 0.0991 | Iter Mean Loss 0.0991\n",
      "CF Training: Epoch 0035 Iter 0020 / 0263 | Iter Loss 0.0204 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0035 Iter 0020 / 0263 | Iter Loss 0.0303 | Iter Mean Loss 0.0295\n",
      "CL Training: Epoch 0035 Iter 0020 / 0263 | Iter Loss 0.0997 | Iter Mean Loss 0.0997\n",
      "CF Training: Epoch 0035 Iter 0040 / 0263 | Iter Loss 0.0185 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0035 Iter 0040 / 0263 | Iter Loss 0.0322 | Iter Mean Loss 0.0306\n",
      "CL Training: Epoch 0035 Iter 0040 / 0263 | Iter Loss 0.0993 | Iter Mean Loss 0.0995\n",
      "CF Training: Epoch 0035 Iter 0060 / 0263 | Iter Loss 0.0233 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0035 Iter 0060 / 0263 | Iter Loss 0.0326 | Iter Mean Loss 0.0312\n",
      "CL Training: Epoch 0035 Iter 0060 / 0263 | Iter Loss 0.0994 | Iter Mean Loss 0.0994\n",
      "CF Training: Epoch 0035 Iter 0080 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0035 Iter 0080 / 0263 | Iter Loss 0.0350 | Iter Mean Loss 0.0316\n",
      "CL Training: Epoch 0035 Iter 0080 / 0263 | Iter Loss 0.0991 | Iter Mean Loss 0.0994\n",
      "CF Training: Epoch 0035 Iter 0100 / 0263 | Iter Loss 0.0199 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0035 Iter 0100 / 0263 | Iter Loss 0.0347 | Iter Mean Loss 0.0321\n",
      "CL Training: Epoch 0035 Iter 0100 / 0263 | Iter Loss 0.0992 | Iter Mean Loss 0.0994\n",
      "CF Training: Epoch 0035 Iter 0120 / 0263 | Iter Loss 0.0166 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0035 Iter 0120 / 0263 | Iter Loss 0.0406 | Iter Mean Loss 0.0329\n",
      "CL Training: Epoch 0035 Iter 0120 / 0263 | Iter Loss 0.0992 | Iter Mean Loss 0.0993\n",
      "CF Training: Epoch 0035 Iter 0140 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0035 Iter 0140 / 0263 | Iter Loss 0.0421 | Iter Mean Loss 0.0340\n",
      "CL Training: Epoch 0035 Iter 0140 / 0263 | Iter Loss 0.0990 | Iter Mean Loss 0.0993\n",
      "CF Training: Epoch 0035 Iter 0160 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0035 Iter 0160 / 0263 | Iter Loss 0.0411 | Iter Mean Loss 0.0350\n",
      "CL Training: Epoch 0035 Iter 0160 / 0263 | Iter Loss 0.0991 | Iter Mean Loss 0.0993\n",
      "CF Training: Epoch 0035 Iter 0180 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0035 Iter 0180 / 0263 | Iter Loss 0.0472 | Iter Mean Loss 0.0359\n",
      "CL Training: Epoch 0035 Iter 0180 / 0263 | Iter Loss 0.0989 | Iter Mean Loss 0.0992\n",
      "CF Training: Epoch 0035 Iter 0200 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0035 Iter 0200 / 0263 | Iter Loss 0.0477 | Iter Mean Loss 0.0369\n",
      "CL Training: Epoch 0035 Iter 0200 / 0263 | Iter Loss 0.0990 | Iter Mean Loss 0.0992\n",
      "CF Training: Epoch 0035 Iter 0220 / 0263 | Iter Loss 0.0223 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0035 Iter 0220 / 0263 | Iter Loss 0.0494 | Iter Mean Loss 0.0380\n",
      "CL Training: Epoch 0035 Iter 0220 / 0263 | Iter Loss 0.0991 | Iter Mean Loss 0.0992\n",
      "CF Training: Epoch 0035 Iter 0240 / 0263 | Iter Loss 0.0162 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0035 Iter 0240 / 0263 | Iter Loss 0.0487 | Iter Mean Loss 0.0390\n",
      "CL Training: Epoch 0035 Iter 0240 / 0263 | Iter Loss 0.0990 | Iter Mean Loss 0.0992\n",
      "CF Training: Epoch 0035 Iter 0260 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0035 Iter 0260 / 0263 | Iter Loss 0.0646 | Iter Mean Loss 0.0401\n",
      "CL Training: Epoch 0035 Iter 0260 / 0263 | Iter Loss 0.0994 | Iter Mean Loss 0.0992\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.233844 s\n",
      "Measure time: 0.017008 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 36, Hit Ratio:0.19604  |  Precision:0.12073  |  Recall:0.1991  |  NDCG:0.20448\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0036 Iter 0000 / 0263 | Iter Loss 0.0107 | Iter Mean Loss 0.0107\n",
      "KG Training: Epoch 0036 Iter 0000 / 0263 | Iter Loss 0.0241 | Iter Mean Loss 0.0241\n",
      "CL Training: Epoch 0036 Iter 0000 / 0263 | Iter Loss 0.0989 | Iter Mean Loss 0.0989\n",
      "CF Training: Epoch 0036 Iter 0020 / 0263 | Iter Loss 0.0144 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0036 Iter 0020 / 0263 | Iter Loss 0.0310 | Iter Mean Loss 0.0289\n",
      "CL Training: Epoch 0036 Iter 0020 / 0263 | Iter Loss 0.0992 | Iter Mean Loss 0.0993\n",
      "CF Training: Epoch 0036 Iter 0040 / 0263 | Iter Loss 0.0183 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0036 Iter 0040 / 0263 | Iter Loss 0.0311 | Iter Mean Loss 0.0299\n",
      "CL Training: Epoch 0036 Iter 0040 / 0263 | Iter Loss 0.0990 | Iter Mean Loss 0.0991\n",
      "CF Training: Epoch 0036 Iter 0060 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0036 Iter 0060 / 0263 | Iter Loss 0.0348 | Iter Mean Loss 0.0306\n",
      "CL Training: Epoch 0036 Iter 0060 / 0263 | Iter Loss 0.0989 | Iter Mean Loss 0.0990\n",
      "CF Training: Epoch 0036 Iter 0080 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0036 Iter 0080 / 0263 | Iter Loss 0.0318 | Iter Mean Loss 0.0312\n",
      "CL Training: Epoch 0036 Iter 0080 / 0263 | Iter Loss 0.0987 | Iter Mean Loss 0.0990\n",
      "CF Training: Epoch 0036 Iter 0100 / 0263 | Iter Loss 0.0185 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0036 Iter 0100 / 0263 | Iter Loss 0.0343 | Iter Mean Loss 0.0320\n",
      "CL Training: Epoch 0036 Iter 0100 / 0263 | Iter Loss 0.0988 | Iter Mean Loss 0.0989\n",
      "CF Training: Epoch 0036 Iter 0120 / 0263 | Iter Loss 0.0274 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0036 Iter 0120 / 0263 | Iter Loss 0.0401 | Iter Mean Loss 0.0331\n",
      "CL Training: Epoch 0036 Iter 0120 / 0263 | Iter Loss 0.0984 | Iter Mean Loss 0.0989\n",
      "CF Training: Epoch 0036 Iter 0140 / 0263 | Iter Loss 0.0259 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0036 Iter 0140 / 0263 | Iter Loss 0.0421 | Iter Mean Loss 0.0342\n",
      "CL Training: Epoch 0036 Iter 0140 / 0263 | Iter Loss 0.0982 | Iter Mean Loss 0.0988\n",
      "CF Training: Epoch 0036 Iter 0160 / 0263 | Iter Loss 0.0209 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0036 Iter 0160 / 0263 | Iter Loss 0.0446 | Iter Mean Loss 0.0355\n",
      "CL Training: Epoch 0036 Iter 0160 / 0263 | Iter Loss 0.0985 | Iter Mean Loss 0.0988\n",
      "CF Training: Epoch 0036 Iter 0180 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0036 Iter 0180 / 0263 | Iter Loss 0.0453 | Iter Mean Loss 0.0364\n",
      "CL Training: Epoch 0036 Iter 0180 / 0263 | Iter Loss 0.0989 | Iter Mean Loss 0.0988\n",
      "CF Training: Epoch 0036 Iter 0200 / 0263 | Iter Loss 0.0188 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0036 Iter 0200 / 0263 | Iter Loss 0.0493 | Iter Mean Loss 0.0375\n",
      "CL Training: Epoch 0036 Iter 0200 / 0263 | Iter Loss 0.0989 | Iter Mean Loss 0.0987\n",
      "CF Training: Epoch 0036 Iter 0220 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0036 Iter 0220 / 0263 | Iter Loss 0.0470 | Iter Mean Loss 0.0384\n",
      "CL Training: Epoch 0036 Iter 0220 / 0263 | Iter Loss 0.0986 | Iter Mean Loss 0.0987\n",
      "CF Training: Epoch 0036 Iter 0240 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0036 Iter 0240 / 0263 | Iter Loss 0.0509 | Iter Mean Loss 0.0394\n",
      "CL Training: Epoch 0036 Iter 0240 / 0263 | Iter Loss 0.0985 | Iter Mean Loss 0.0987\n",
      "CF Training: Epoch 0036 Iter 0260 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0036 Iter 0260 / 0263 | Iter Loss 0.0661 | Iter Mean Loss 0.0406\n",
      "CL Training: Epoch 0036 Iter 0260 / 0263 | Iter Loss 0.0984 | Iter Mean Loss 0.0987\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.236888 s\n",
      "Measure time: 0.017039 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 37, Hit Ratio:0.2006  |  Precision:0.12354  |  Recall:0.20365  |  NDCG:0.20998\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0037 Iter 0000 / 0263 | Iter Loss 0.0214 | Iter Mean Loss 0.0214\n",
      "KG Training: Epoch 0037 Iter 0000 / 0263 | Iter Loss 0.0249 | Iter Mean Loss 0.0249\n",
      "CL Training: Epoch 0037 Iter 0000 / 0263 | Iter Loss 0.0989 | Iter Mean Loss 0.0989\n",
      "CF Training: Epoch 0037 Iter 0020 / 0263 | Iter Loss 0.0157 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0037 Iter 0020 / 0263 | Iter Loss 0.0295 | Iter Mean Loss 0.0285\n",
      "CL Training: Epoch 0037 Iter 0020 / 0263 | Iter Loss 0.0990 | Iter Mean Loss 0.0991\n",
      "CF Training: Epoch 0037 Iter 0040 / 0263 | Iter Loss 0.0293 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0037 Iter 0040 / 0263 | Iter Loss 0.0323 | Iter Mean Loss 0.0298\n",
      "CL Training: Epoch 0037 Iter 0040 / 0263 | Iter Loss 0.0983 | Iter Mean Loss 0.0990\n",
      "CF Training: Epoch 0037 Iter 0060 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0037 Iter 0060 / 0263 | Iter Loss 0.0309 | Iter Mean Loss 0.0303\n",
      "CL Training: Epoch 0037 Iter 0060 / 0263 | Iter Loss 0.0987 | Iter Mean Loss 0.0989\n",
      "CF Training: Epoch 0037 Iter 0080 / 0263 | Iter Loss 0.0157 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0037 Iter 0080 / 0263 | Iter Loss 0.0352 | Iter Mean Loss 0.0309\n",
      "CL Training: Epoch 0037 Iter 0080 / 0263 | Iter Loss 0.0986 | Iter Mean Loss 0.0988\n",
      "CF Training: Epoch 0037 Iter 0100 / 0263 | Iter Loss 0.0166 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0037 Iter 0100 / 0263 | Iter Loss 0.0318 | Iter Mean Loss 0.0318\n",
      "CL Training: Epoch 0037 Iter 0100 / 0263 | Iter Loss 0.0988 | Iter Mean Loss 0.0988\n",
      "CF Training: Epoch 0037 Iter 0120 / 0263 | Iter Loss 0.0210 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0037 Iter 0120 / 0263 | Iter Loss 0.0380 | Iter Mean Loss 0.0328\n",
      "CL Training: Epoch 0037 Iter 0120 / 0263 | Iter Loss 0.0981 | Iter Mean Loss 0.0988\n",
      "CF Training: Epoch 0037 Iter 0140 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0037 Iter 0140 / 0263 | Iter Loss 0.0367 | Iter Mean Loss 0.0338\n",
      "CL Training: Epoch 0037 Iter 0140 / 0263 | Iter Loss 0.0983 | Iter Mean Loss 0.0987\n",
      "CF Training: Epoch 0037 Iter 0160 / 0263 | Iter Loss 0.0133 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0037 Iter 0160 / 0263 | Iter Loss 0.0477 | Iter Mean Loss 0.0350\n",
      "CL Training: Epoch 0037 Iter 0160 / 0263 | Iter Loss 0.0984 | Iter Mean Loss 0.0987\n",
      "CF Training: Epoch 0037 Iter 0180 / 0263 | Iter Loss 0.0186 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0037 Iter 0180 / 0263 | Iter Loss 0.0414 | Iter Mean Loss 0.0360\n",
      "CL Training: Epoch 0037 Iter 0180 / 0263 | Iter Loss 0.0987 | Iter Mean Loss 0.0987\n",
      "CF Training: Epoch 0037 Iter 0200 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0037 Iter 0200 / 0263 | Iter Loss 0.0463 | Iter Mean Loss 0.0370\n",
      "CL Training: Epoch 0037 Iter 0200 / 0263 | Iter Loss 0.0985 | Iter Mean Loss 0.0986\n",
      "CF Training: Epoch 0037 Iter 0220 / 0263 | Iter Loss 0.0169 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0037 Iter 0220 / 0263 | Iter Loss 0.0563 | Iter Mean Loss 0.0380\n",
      "CL Training: Epoch 0037 Iter 0220 / 0263 | Iter Loss 0.0985 | Iter Mean Loss 0.0986\n",
      "CF Training: Epoch 0037 Iter 0240 / 0263 | Iter Loss 0.0278 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0037 Iter 0240 / 0263 | Iter Loss 0.0473 | Iter Mean Loss 0.0389\n",
      "CL Training: Epoch 0037 Iter 0240 / 0263 | Iter Loss 0.0983 | Iter Mean Loss 0.0986\n",
      "CF Training: Epoch 0037 Iter 0260 / 0263 | Iter Loss 0.0191 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0037 Iter 0260 / 0263 | Iter Loss 0.0604 | Iter Mean Loss 0.0401\n",
      "CL Training: Epoch 0037 Iter 0260 / 0263 | Iter Loss 0.0986 | Iter Mean Loss 0.0986\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.234231 s\n",
      "Measure time: 0.017282 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 38, Hit Ratio:0.18699  |  Precision:0.11515  |  Recall:0.19061  |  NDCG:0.18681\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0038 Iter 0000 / 0263 | Iter Loss 0.0192 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0038 Iter 0000 / 0263 | Iter Loss 0.0236 | Iter Mean Loss 0.0236\n",
      "CL Training: Epoch 0038 Iter 0000 / 0263 | Iter Loss 0.0986 | Iter Mean Loss 0.0986\n",
      "CF Training: Epoch 0038 Iter 0020 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0038 Iter 0020 / 0263 | Iter Loss 0.0273 | Iter Mean Loss 0.0281\n",
      "CL Training: Epoch 0038 Iter 0020 / 0263 | Iter Loss 0.0985 | Iter Mean Loss 0.0986\n",
      "CF Training: Epoch 0038 Iter 0040 / 0263 | Iter Loss 0.0149 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0038 Iter 0040 / 0263 | Iter Loss 0.0296 | Iter Mean Loss 0.0294\n",
      "CL Training: Epoch 0038 Iter 0040 / 0263 | Iter Loss 0.0980 | Iter Mean Loss 0.0985\n",
      "CF Training: Epoch 0038 Iter 0060 / 0263 | Iter Loss 0.0231 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0038 Iter 0060 / 0263 | Iter Loss 0.0289 | Iter Mean Loss 0.0302\n",
      "CL Training: Epoch 0038 Iter 0060 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0984\n",
      "CF Training: Epoch 0038 Iter 0080 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0038 Iter 0080 / 0263 | Iter Loss 0.0311 | Iter Mean Loss 0.0309\n",
      "CL Training: Epoch 0038 Iter 0080 / 0263 | Iter Loss 0.0983 | Iter Mean Loss 0.0984\n",
      "CF Training: Epoch 0038 Iter 0100 / 0263 | Iter Loss 0.0232 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0038 Iter 0100 / 0263 | Iter Loss 0.0359 | Iter Mean Loss 0.0315\n",
      "CL Training: Epoch 0038 Iter 0100 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0983\n",
      "CF Training: Epoch 0038 Iter 0120 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0038 Iter 0120 / 0263 | Iter Loss 0.0395 | Iter Mean Loss 0.0325\n",
      "CL Training: Epoch 0038 Iter 0120 / 0263 | Iter Loss 0.0980 | Iter Mean Loss 0.0983\n",
      "CF Training: Epoch 0038 Iter 0140 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0038 Iter 0140 / 0263 | Iter Loss 0.0422 | Iter Mean Loss 0.0336\n",
      "CL Training: Epoch 0038 Iter 0140 / 0263 | Iter Loss 0.0981 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0038 Iter 0160 / 0263 | Iter Loss 0.0287 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0038 Iter 0160 / 0263 | Iter Loss 0.0420 | Iter Mean Loss 0.0348\n",
      "CL Training: Epoch 0038 Iter 0160 / 0263 | Iter Loss 0.0985 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0038 Iter 0180 / 0263 | Iter Loss 0.0212 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0038 Iter 0180 / 0263 | Iter Loss 0.0433 | Iter Mean Loss 0.0357\n",
      "CL Training: Epoch 0038 Iter 0180 / 0263 | Iter Loss 0.0981 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0038 Iter 0200 / 0263 | Iter Loss 0.0146 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0038 Iter 0200 / 0263 | Iter Loss 0.0444 | Iter Mean Loss 0.0367\n",
      "CL Training: Epoch 0038 Iter 0200 / 0263 | Iter Loss 0.0980 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0038 Iter 0220 / 0263 | Iter Loss 0.0123 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0038 Iter 0220 / 0263 | Iter Loss 0.0535 | Iter Mean Loss 0.0377\n",
      "CL Training: Epoch 0038 Iter 0220 / 0263 | Iter Loss 0.0981 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0038 Iter 0240 / 0263 | Iter Loss 0.0266 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0038 Iter 0240 / 0263 | Iter Loss 0.0513 | Iter Mean Loss 0.0387\n",
      "CL Training: Epoch 0038 Iter 0240 / 0263 | Iter Loss 0.0983 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0038 Iter 0260 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0038 Iter 0260 / 0263 | Iter Loss 0.0624 | Iter Mean Loss 0.0398\n",
      "CL Training: Epoch 0038 Iter 0260 / 0263 | Iter Loss 0.0984 | Iter Mean Loss 0.0982\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.235580 s\n",
      "Measure time: 0.018634 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 39, Hit Ratio:0.20306  |  Precision:0.12505  |  Recall:0.20532  |  NDCG:0.2116\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0039 Iter 0000 / 0263 | Iter Loss 0.0178 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0039 Iter 0000 / 0263 | Iter Loss 0.0238 | Iter Mean Loss 0.0238\n",
      "CL Training: Epoch 0039 Iter 0000 / 0263 | Iter Loss 0.0988 | Iter Mean Loss 0.0988\n",
      "CF Training: Epoch 0039 Iter 0020 / 0263 | Iter Loss 0.0168 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0039 Iter 0020 / 0263 | Iter Loss 0.0295 | Iter Mean Loss 0.0280\n",
      "CL Training: Epoch 0039 Iter 0020 / 0263 | Iter Loss 0.0984 | Iter Mean Loss 0.0984\n",
      "CF Training: Epoch 0039 Iter 0040 / 0263 | Iter Loss 0.0143 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0039 Iter 0040 / 0263 | Iter Loss 0.0309 | Iter Mean Loss 0.0289\n",
      "CL Training: Epoch 0039 Iter 0040 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0984\n",
      "CF Training: Epoch 0039 Iter 0060 / 0263 | Iter Loss 0.0170 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0039 Iter 0060 / 0263 | Iter Loss 0.0306 | Iter Mean Loss 0.0298\n",
      "CL Training: Epoch 0039 Iter 0060 / 0263 | Iter Loss 0.0978 | Iter Mean Loss 0.0983\n",
      "CF Training: Epoch 0039 Iter 0080 / 0263 | Iter Loss 0.0191 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0039 Iter 0080 / 0263 | Iter Loss 0.0326 | Iter Mean Loss 0.0304\n",
      "CL Training: Epoch 0039 Iter 0080 / 0263 | Iter Loss 0.0978 | Iter Mean Loss 0.0983\n",
      "CF Training: Epoch 0039 Iter 0100 / 0263 | Iter Loss 0.0276 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0039 Iter 0100 / 0263 | Iter Loss 0.0380 | Iter Mean Loss 0.0312\n",
      "CL Training: Epoch 0039 Iter 0100 / 0263 | Iter Loss 0.0984 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0039 Iter 0120 / 0263 | Iter Loss 0.0149 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0039 Iter 0120 / 0263 | Iter Loss 0.0358 | Iter Mean Loss 0.0323\n",
      "CL Training: Epoch 0039 Iter 0120 / 0263 | Iter Loss 0.0977 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0039 Iter 0140 / 0263 | Iter Loss 0.0219 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0039 Iter 0140 / 0263 | Iter Loss 0.0391 | Iter Mean Loss 0.0333\n",
      "CL Training: Epoch 0039 Iter 0140 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0039 Iter 0160 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0197\n",
      "KG Training: Epoch 0039 Iter 0160 / 0263 | Iter Loss 0.0449 | Iter Mean Loss 0.0345\n",
      "CL Training: Epoch 0039 Iter 0160 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0039 Iter 0180 / 0263 | Iter Loss 0.0217 | Iter Mean Loss 0.0197\n",
      "KG Training: Epoch 0039 Iter 0180 / 0263 | Iter Loss 0.0395 | Iter Mean Loss 0.0355\n",
      "CL Training: Epoch 0039 Iter 0180 / 0263 | Iter Loss 0.0981 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0039 Iter 0200 / 0263 | Iter Loss 0.0145 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0039 Iter 0200 / 0263 | Iter Loss 0.0518 | Iter Mean Loss 0.0366\n",
      "CL Training: Epoch 0039 Iter 0200 / 0263 | Iter Loss 0.0981 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0039 Iter 0220 / 0263 | Iter Loss 0.0224 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0039 Iter 0220 / 0263 | Iter Loss 0.0462 | Iter Mean Loss 0.0374\n",
      "CL Training: Epoch 0039 Iter 0220 / 0263 | Iter Loss 0.0984 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0039 Iter 0240 / 0263 | Iter Loss 0.0153 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0039 Iter 0240 / 0263 | Iter Loss 0.0471 | Iter Mean Loss 0.0384\n",
      "CL Training: Epoch 0039 Iter 0240 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0039 Iter 0260 / 0263 | Iter Loss 0.0217 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0039 Iter 0260 / 0263 | Iter Loss 0.0632 | Iter Mean Loss 0.0395\n",
      "CL Training: Epoch 0039 Iter 0260 / 0263 | Iter Loss 0.0983 | Iter Mean Loss 0.0981\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.234533 s\n",
      "Measure time: 0.016827 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 40, Hit Ratio:0.2028  |  Precision:0.12489  |  Recall:0.20438  |  NDCG:0.21653\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0040 Iter 0000 / 0263 | Iter Loss 0.0220 | Iter Mean Loss 0.0220\n",
      "KG Training: Epoch 0040 Iter 0000 / 0263 | Iter Loss 0.0239 | Iter Mean Loss 0.0239\n",
      "CL Training: Epoch 0040 Iter 0000 / 0263 | Iter Loss 0.0984 | Iter Mean Loss 0.0984\n",
      "CF Training: Epoch 0040 Iter 0020 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0040 Iter 0020 / 0263 | Iter Loss 0.0328 | Iter Mean Loss 0.0284\n",
      "CL Training: Epoch 0040 Iter 0020 / 0263 | Iter Loss 0.0985 | Iter Mean Loss 0.0987\n",
      "CF Training: Epoch 0040 Iter 0040 / 0263 | Iter Loss 0.0158 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0040 Iter 0040 / 0263 | Iter Loss 0.0296 | Iter Mean Loss 0.0290\n",
      "CL Training: Epoch 0040 Iter 0040 / 0263 | Iter Loss 0.0984 | Iter Mean Loss 0.0984\n",
      "CF Training: Epoch 0040 Iter 0060 / 0263 | Iter Loss 0.0312 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0040 Iter 0060 / 0263 | Iter Loss 0.0310 | Iter Mean Loss 0.0297\n",
      "CL Training: Epoch 0040 Iter 0060 / 0263 | Iter Loss 0.0982 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0040 Iter 0080 / 0263 | Iter Loss 0.0173 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0040 Iter 0080 / 0263 | Iter Loss 0.0314 | Iter Mean Loss 0.0301\n",
      "CL Training: Epoch 0040 Iter 0080 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0040 Iter 0100 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0040 Iter 0100 / 0263 | Iter Loss 0.0377 | Iter Mean Loss 0.0310\n",
      "CL Training: Epoch 0040 Iter 0100 / 0263 | Iter Loss 0.0980 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0040 Iter 0120 / 0263 | Iter Loss 0.0148 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0040 Iter 0120 / 0263 | Iter Loss 0.0376 | Iter Mean Loss 0.0322\n",
      "CL Training: Epoch 0040 Iter 0120 / 0263 | Iter Loss 0.0983 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0040 Iter 0140 / 0263 | Iter Loss 0.0148 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0040 Iter 0140 / 0263 | Iter Loss 0.0415 | Iter Mean Loss 0.0333\n",
      "CL Training: Epoch 0040 Iter 0140 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0040 Iter 0160 / 0263 | Iter Loss 0.0231 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0040 Iter 0160 / 0263 | Iter Loss 0.0454 | Iter Mean Loss 0.0344\n",
      "CL Training: Epoch 0040 Iter 0160 / 0263 | Iter Loss 0.0977 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0040 Iter 0180 / 0263 | Iter Loss 0.0121 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0040 Iter 0180 / 0263 | Iter Loss 0.0457 | Iter Mean Loss 0.0354\n",
      "CL Training: Epoch 0040 Iter 0180 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0040 Iter 0200 / 0263 | Iter Loss 0.0291 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0040 Iter 0200 / 0263 | Iter Loss 0.0459 | Iter Mean Loss 0.0364\n",
      "CL Training: Epoch 0040 Iter 0200 / 0263 | Iter Loss 0.0978 | Iter Mean Loss 0.0980\n",
      "CF Training: Epoch 0040 Iter 0220 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0040 Iter 0220 / 0263 | Iter Loss 0.0541 | Iter Mean Loss 0.0373\n",
      "CL Training: Epoch 0040 Iter 0220 / 0263 | Iter Loss 0.0982 | Iter Mean Loss 0.0980\n",
      "CF Training: Epoch 0040 Iter 0240 / 0263 | Iter Loss 0.0174 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0040 Iter 0240 / 0263 | Iter Loss 0.0466 | Iter Mean Loss 0.0382\n",
      "CL Training: Epoch 0040 Iter 0240 / 0263 | Iter Loss 0.0980 | Iter Mean Loss 0.0980\n",
      "CF Training: Epoch 0040 Iter 0260 / 0263 | Iter Loss 0.0288 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0040 Iter 0260 / 0263 | Iter Loss 0.0625 | Iter Mean Loss 0.0394\n",
      "CL Training: Epoch 0040 Iter 0260 / 0263 | Iter Loss 0.0984 | Iter Mean Loss 0.0980\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 1.793511 s\n",
      "Measure time: 0.018623 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 41, Hit Ratio:0.21202  |  Precision:0.13057  |  Recall:0.21395  |  NDCG:0.21661\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0041 Iter 0000 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0041 Iter 0000 / 0263 | Iter Loss 0.0237 | Iter Mean Loss 0.0237\n",
      "CL Training: Epoch 0041 Iter 0000 / 0263 | Iter Loss 0.0983 | Iter Mean Loss 0.0983\n",
      "CF Training: Epoch 0041 Iter 0020 / 0263 | Iter Loss 0.0188 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0041 Iter 0020 / 0263 | Iter Loss 0.0269 | Iter Mean Loss 0.0278\n",
      "CL Training: Epoch 0041 Iter 0020 / 0263 | Iter Loss 0.0984 | Iter Mean Loss 0.0984\n",
      "CF Training: Epoch 0041 Iter 0040 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0041 Iter 0040 / 0263 | Iter Loss 0.0310 | Iter Mean Loss 0.0291\n",
      "CL Training: Epoch 0041 Iter 0040 / 0263 | Iter Loss 0.0986 | Iter Mean Loss 0.0985\n",
      "CF Training: Epoch 0041 Iter 0060 / 0263 | Iter Loss 0.0115 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0041 Iter 0060 / 0263 | Iter Loss 0.0286 | Iter Mean Loss 0.0297\n",
      "CL Training: Epoch 0041 Iter 0060 / 0263 | Iter Loss 0.0980 | Iter Mean Loss 0.0985\n",
      "CF Training: Epoch 0041 Iter 0080 / 0263 | Iter Loss 0.0194 | Iter Mean Loss 0.0195\n",
      "KG Training: Epoch 0041 Iter 0080 / 0263 | Iter Loss 0.0337 | Iter Mean Loss 0.0305\n",
      "CL Training: Epoch 0041 Iter 0080 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0983\n",
      "CF Training: Epoch 0041 Iter 0100 / 0263 | Iter Loss 0.0241 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0041 Iter 0100 / 0263 | Iter Loss 0.0337 | Iter Mean Loss 0.0312\n",
      "CL Training: Epoch 0041 Iter 0100 / 0263 | Iter Loss 0.0977 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0041 Iter 0120 / 0263 | Iter Loss 0.0136 | Iter Mean Loss 0.0197\n",
      "KG Training: Epoch 0041 Iter 0120 / 0263 | Iter Loss 0.0387 | Iter Mean Loss 0.0321\n",
      "CL Training: Epoch 0041 Iter 0120 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0041 Iter 0140 / 0263 | Iter Loss 0.0171 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0041 Iter 0140 / 0263 | Iter Loss 0.0390 | Iter Mean Loss 0.0332\n",
      "CL Training: Epoch 0041 Iter 0140 / 0263 | Iter Loss 0.0978 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0041 Iter 0160 / 0263 | Iter Loss 0.0224 | Iter Mean Loss 0.0195\n",
      "KG Training: Epoch 0041 Iter 0160 / 0263 | Iter Loss 0.0391 | Iter Mean Loss 0.0344\n",
      "CL Training: Epoch 0041 Iter 0160 / 0263 | Iter Loss 0.0975 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0041 Iter 0180 / 0263 | Iter Loss 0.0147 | Iter Mean Loss 0.0195\n",
      "KG Training: Epoch 0041 Iter 0180 / 0263 | Iter Loss 0.0439 | Iter Mean Loss 0.0353\n",
      "CL Training: Epoch 0041 Iter 0180 / 0263 | Iter Loss 0.0978 | Iter Mean Loss 0.0980\n",
      "CF Training: Epoch 0041 Iter 0200 / 0263 | Iter Loss 0.0166 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0041 Iter 0200 / 0263 | Iter Loss 0.0443 | Iter Mean Loss 0.0363\n",
      "CL Training: Epoch 0041 Iter 0200 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0980\n",
      "CF Training: Epoch 0041 Iter 0220 / 0263 | Iter Loss 0.0161 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0041 Iter 0220 / 0263 | Iter Loss 0.0433 | Iter Mean Loss 0.0372\n",
      "CL Training: Epoch 0041 Iter 0220 / 0263 | Iter Loss 0.0977 | Iter Mean Loss 0.0980\n",
      "CF Training: Epoch 0041 Iter 0240 / 0263 | Iter Loss 0.0169 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0041 Iter 0240 / 0263 | Iter Loss 0.0510 | Iter Mean Loss 0.0381\n",
      "CL Training: Epoch 0041 Iter 0240 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0979\n",
      "CF Training: Epoch 0041 Iter 0260 / 0263 | Iter Loss 0.0158 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0041 Iter 0260 / 0263 | Iter Loss 0.0608 | Iter Mean Loss 0.0393\n",
      "CL Training: Epoch 0041 Iter 0260 / 0263 | Iter Loss 0.0981 | Iter Mean Loss 0.0979\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.988745 s\n",
      "Measure time: 0.017397 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 42, Hit Ratio:0.20228  |  Precision:0.12458  |  Recall:0.20405  |  NDCG:0.20733\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0042 Iter 0000 / 0263 | Iter Loss 0.0159 | Iter Mean Loss 0.0159\n",
      "KG Training: Epoch 0042 Iter 0000 / 0263 | Iter Loss 0.0209 | Iter Mean Loss 0.0209\n",
      "CL Training: Epoch 0042 Iter 0000 / 0263 | Iter Loss 0.0977 | Iter Mean Loss 0.0977\n",
      "CF Training: Epoch 0042 Iter 0020 / 0263 | Iter Loss 0.0127 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0042 Iter 0020 / 0263 | Iter Loss 0.0283 | Iter Mean Loss 0.0270\n",
      "CL Training: Epoch 0042 Iter 0020 / 0263 | Iter Loss 0.0980 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0042 Iter 0040 / 0263 | Iter Loss 0.0270 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0042 Iter 0040 / 0263 | Iter Loss 0.0324 | Iter Mean Loss 0.0285\n",
      "CL Training: Epoch 0042 Iter 0040 / 0263 | Iter Loss 0.0978 | Iter Mean Loss 0.0980\n",
      "CF Training: Epoch 0042 Iter 0060 / 0263 | Iter Loss 0.0221 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0042 Iter 0060 / 0263 | Iter Loss 0.0301 | Iter Mean Loss 0.0294\n",
      "CL Training: Epoch 0042 Iter 0060 / 0263 | Iter Loss 0.0982 | Iter Mean Loss 0.0980\n",
      "CF Training: Epoch 0042 Iter 0080 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0042 Iter 0080 / 0263 | Iter Loss 0.0316 | Iter Mean Loss 0.0301\n",
      "CL Training: Epoch 0042 Iter 0080 / 0263 | Iter Loss 0.0987 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0042 Iter 0100 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0042 Iter 0100 / 0263 | Iter Loss 0.0395 | Iter Mean Loss 0.0309\n",
      "CL Training: Epoch 0042 Iter 0100 / 0263 | Iter Loss 0.0980 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0042 Iter 0120 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0042 Iter 0120 / 0263 | Iter Loss 0.0401 | Iter Mean Loss 0.0321\n",
      "CL Training: Epoch 0042 Iter 0120 / 0263 | Iter Loss 0.0977 | Iter Mean Loss 0.0982\n",
      "CF Training: Epoch 0042 Iter 0140 / 0263 | Iter Loss 0.0180 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0042 Iter 0140 / 0263 | Iter Loss 0.0436 | Iter Mean Loss 0.0332\n",
      "CL Training: Epoch 0042 Iter 0140 / 0263 | Iter Loss 0.0978 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0042 Iter 0160 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0201\n",
      "KG Training: Epoch 0042 Iter 0160 / 0263 | Iter Loss 0.0424 | Iter Mean Loss 0.0344\n",
      "CL Training: Epoch 0042 Iter 0160 / 0263 | Iter Loss 0.0973 | Iter Mean Loss 0.0981\n",
      "CF Training: Epoch 0042 Iter 0180 / 0263 | Iter Loss 0.0142 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0042 Iter 0180 / 0263 | Iter Loss 0.0439 | Iter Mean Loss 0.0353\n",
      "CL Training: Epoch 0042 Iter 0180 / 0263 | Iter Loss 0.0976 | Iter Mean Loss 0.0980\n",
      "CF Training: Epoch 0042 Iter 0200 / 0263 | Iter Loss 0.0132 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0042 Iter 0200 / 0263 | Iter Loss 0.0423 | Iter Mean Loss 0.0363\n",
      "CL Training: Epoch 0042 Iter 0200 / 0263 | Iter Loss 0.0976 | Iter Mean Loss 0.0980\n",
      "CF Training: Epoch 0042 Iter 0220 / 0263 | Iter Loss 0.0244 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0042 Iter 0220 / 0263 | Iter Loss 0.0449 | Iter Mean Loss 0.0373\n",
      "CL Training: Epoch 0042 Iter 0220 / 0263 | Iter Loss 0.0977 | Iter Mean Loss 0.0980\n",
      "CF Training: Epoch 0042 Iter 0240 / 0263 | Iter Loss 0.0238 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0042 Iter 0240 / 0263 | Iter Loss 0.0496 | Iter Mean Loss 0.0383\n",
      "CL Training: Epoch 0042 Iter 0240 / 0263 | Iter Loss 0.0977 | Iter Mean Loss 0.0979\n",
      "CF Training: Epoch 0042 Iter 0260 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0042 Iter 0260 / 0263 | Iter Loss 0.0631 | Iter Mean Loss 0.0394\n",
      "CL Training: Epoch 0042 Iter 0260 / 0263 | Iter Loss 0.0975 | Iter Mean Loss 0.0979\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.959997 s\n",
      "Measure time: 0.017483 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 43, Hit Ratio:0.19293  |  Precision:0.11882  |  Recall:0.19464  |  NDCG:0.1979\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0043 Iter 0000 / 0263 | Iter Loss 0.0108 | Iter Mean Loss 0.0108\n",
      "KG Training: Epoch 0043 Iter 0000 / 0263 | Iter Loss 0.0217 | Iter Mean Loss 0.0217\n",
      "CL Training: Epoch 0043 Iter 0000 / 0263 | Iter Loss 0.0978 | Iter Mean Loss 0.0978\n",
      "CF Training: Epoch 0043 Iter 0020 / 0263 | Iter Loss 0.0141 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0043 Iter 0020 / 0263 | Iter Loss 0.0274 | Iter Mean Loss 0.0263\n",
      "CL Training: Epoch 0043 Iter 0020 / 0263 | Iter Loss 0.0977 | Iter Mean Loss 0.0979\n",
      "CF Training: Epoch 0043 Iter 0040 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0043 Iter 0040 / 0263 | Iter Loss 0.0322 | Iter Mean Loss 0.0275\n",
      "CL Training: Epoch 0043 Iter 0040 / 0263 | Iter Loss 0.0969 | Iter Mean Loss 0.0977\n",
      "CF Training: Epoch 0043 Iter 0060 / 0263 | Iter Loss 0.0264 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0043 Iter 0060 / 0263 | Iter Loss 0.0328 | Iter Mean Loss 0.0284\n",
      "CL Training: Epoch 0043 Iter 0060 / 0263 | Iter Loss 0.0977 | Iter Mean Loss 0.0977\n",
      "CF Training: Epoch 0043 Iter 0080 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0043 Iter 0080 / 0263 | Iter Loss 0.0327 | Iter Mean Loss 0.0292\n",
      "CL Training: Epoch 0043 Iter 0080 / 0263 | Iter Loss 0.0975 | Iter Mean Loss 0.0977\n",
      "CF Training: Epoch 0043 Iter 0100 / 0263 | Iter Loss 0.0259 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0043 Iter 0100 / 0263 | Iter Loss 0.0319 | Iter Mean Loss 0.0300\n",
      "CL Training: Epoch 0043 Iter 0100 / 0263 | Iter Loss 0.0974 | Iter Mean Loss 0.0977\n",
      "CF Training: Epoch 0043 Iter 0120 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0043 Iter 0120 / 0263 | Iter Loss 0.0379 | Iter Mean Loss 0.0311\n",
      "CL Training: Epoch 0043 Iter 0120 / 0263 | Iter Loss 0.0974 | Iter Mean Loss 0.0976\n",
      "CF Training: Epoch 0043 Iter 0140 / 0263 | Iter Loss 0.0237 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0043 Iter 0140 / 0263 | Iter Loss 0.0368 | Iter Mean Loss 0.0321\n",
      "CL Training: Epoch 0043 Iter 0140 / 0263 | Iter Loss 0.0972 | Iter Mean Loss 0.0976\n",
      "CF Training: Epoch 0043 Iter 0160 / 0263 | Iter Loss 0.0104 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0043 Iter 0160 / 0263 | Iter Loss 0.0427 | Iter Mean Loss 0.0332\n",
      "CL Training: Epoch 0043 Iter 0160 / 0263 | Iter Loss 0.0972 | Iter Mean Loss 0.0976\n",
      "CF Training: Epoch 0043 Iter 0180 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0043 Iter 0180 / 0263 | Iter Loss 0.0411 | Iter Mean Loss 0.0343\n",
      "CL Training: Epoch 0043 Iter 0180 / 0263 | Iter Loss 0.0983 | Iter Mean Loss 0.0976\n",
      "CF Training: Epoch 0043 Iter 0200 / 0263 | Iter Loss 0.0166 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0043 Iter 0200 / 0263 | Iter Loss 0.0481 | Iter Mean Loss 0.0354\n",
      "CL Training: Epoch 0043 Iter 0200 / 0263 | Iter Loss 0.0975 | Iter Mean Loss 0.0976\n",
      "CF Training: Epoch 0043 Iter 0220 / 0263 | Iter Loss 0.0201 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0043 Iter 0220 / 0263 | Iter Loss 0.0514 | Iter Mean Loss 0.0365\n",
      "CL Training: Epoch 0043 Iter 0220 / 0263 | Iter Loss 0.0971 | Iter Mean Loss 0.0976\n",
      "CF Training: Epoch 0043 Iter 0240 / 0263 | Iter Loss 0.0191 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0043 Iter 0240 / 0263 | Iter Loss 0.0571 | Iter Mean Loss 0.0377\n",
      "CL Training: Epoch 0043 Iter 0240 / 0263 | Iter Loss 0.0980 | Iter Mean Loss 0.0976\n",
      "CF Training: Epoch 0043 Iter 0260 / 0263 | Iter Loss 0.0191 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0043 Iter 0260 / 0263 | Iter Loss 0.0632 | Iter Mean Loss 0.0388\n",
      "CL Training: Epoch 0043 Iter 0260 / 0263 | Iter Loss 0.0980 | Iter Mean Loss 0.0976\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.040601 s\n",
      "Measure time: 0.017951 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 44, Hit Ratio:0.18871  |  Precision:0.11622  |  Recall:0.19055  |  NDCG:0.19171\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0044 Iter 0000 / 0263 | Iter Loss 0.0138 | Iter Mean Loss 0.0138\n",
      "KG Training: Epoch 0044 Iter 0000 / 0263 | Iter Loss 0.0229 | Iter Mean Loss 0.0229\n",
      "CL Training: Epoch 0044 Iter 0000 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0979\n",
      "CF Training: Epoch 0044 Iter 0020 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0044 Iter 0020 / 0263 | Iter Loss 0.0278 | Iter Mean Loss 0.0277\n",
      "CL Training: Epoch 0044 Iter 0020 / 0263 | Iter Loss 0.0979 | Iter Mean Loss 0.0980\n",
      "CF Training: Epoch 0044 Iter 0040 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0044 Iter 0040 / 0263 | Iter Loss 0.0323 | Iter Mean Loss 0.0287\n",
      "CL Training: Epoch 0044 Iter 0040 / 0263 | Iter Loss 0.0975 | Iter Mean Loss 0.0979\n",
      "CF Training: Epoch 0044 Iter 0060 / 0263 | Iter Loss 0.0204 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0044 Iter 0060 / 0263 | Iter Loss 0.0342 | Iter Mean Loss 0.0291\n",
      "CL Training: Epoch 0044 Iter 0060 / 0263 | Iter Loss 0.0974 | Iter Mean Loss 0.0977\n",
      "CF Training: Epoch 0044 Iter 0080 / 0263 | Iter Loss 0.0210 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0044 Iter 0080 / 0263 | Iter Loss 0.0302 | Iter Mean Loss 0.0298\n",
      "CL Training: Epoch 0044 Iter 0080 / 0263 | Iter Loss 0.0974 | Iter Mean Loss 0.0977\n",
      "CF Training: Epoch 0044 Iter 0100 / 0263 | Iter Loss 0.0172 | Iter Mean Loss 0.0195\n",
      "KG Training: Epoch 0044 Iter 0100 / 0263 | Iter Loss 0.0339 | Iter Mean Loss 0.0305\n",
      "CL Training: Epoch 0044 Iter 0100 / 0263 | Iter Loss 0.0973 | Iter Mean Loss 0.0976\n",
      "CF Training: Epoch 0044 Iter 0120 / 0263 | Iter Loss 0.0253 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0044 Iter 0120 / 0263 | Iter Loss 0.0402 | Iter Mean Loss 0.0314\n",
      "CL Training: Epoch 0044 Iter 0120 / 0263 | Iter Loss 0.0974 | Iter Mean Loss 0.0975\n",
      "CF Training: Epoch 0044 Iter 0140 / 0263 | Iter Loss 0.0216 | Iter Mean Loss 0.0195\n",
      "KG Training: Epoch 0044 Iter 0140 / 0263 | Iter Loss 0.0379 | Iter Mean Loss 0.0322\n",
      "CL Training: Epoch 0044 Iter 0140 / 0263 | Iter Loss 0.0971 | Iter Mean Loss 0.0975\n",
      "CF Training: Epoch 0044 Iter 0160 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0044 Iter 0160 / 0263 | Iter Loss 0.0421 | Iter Mean Loss 0.0332\n",
      "CL Training: Epoch 0044 Iter 0160 / 0263 | Iter Loss 0.0974 | Iter Mean Loss 0.0974\n",
      "CF Training: Epoch 0044 Iter 0180 / 0263 | Iter Loss 0.0180 | Iter Mean Loss 0.0195\n",
      "KG Training: Epoch 0044 Iter 0180 / 0263 | Iter Loss 0.0396 | Iter Mean Loss 0.0341\n",
      "CL Training: Epoch 0044 Iter 0180 / 0263 | Iter Loss 0.0971 | Iter Mean Loss 0.0974\n",
      "CF Training: Epoch 0044 Iter 0200 / 0263 | Iter Loss 0.0102 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0044 Iter 0200 / 0263 | Iter Loss 0.0475 | Iter Mean Loss 0.0351\n",
      "CL Training: Epoch 0044 Iter 0200 / 0263 | Iter Loss 0.0970 | Iter Mean Loss 0.0973\n",
      "CF Training: Epoch 0044 Iter 0220 / 0263 | Iter Loss 0.0194 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0044 Iter 0220 / 0263 | Iter Loss 0.0417 | Iter Mean Loss 0.0360\n",
      "CL Training: Epoch 0044 Iter 0220 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0973\n",
      "CF Training: Epoch 0044 Iter 0240 / 0263 | Iter Loss 0.0168 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0044 Iter 0240 / 0263 | Iter Loss 0.0452 | Iter Mean Loss 0.0369\n",
      "CL Training: Epoch 0044 Iter 0240 / 0263 | Iter Loss 0.0969 | Iter Mean Loss 0.0973\n",
      "CF Training: Epoch 0044 Iter 0260 / 0263 | Iter Loss 0.0223 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0044 Iter 0260 / 0263 | Iter Loss 0.0604 | Iter Mean Loss 0.0381\n",
      "CL Training: Epoch 0044 Iter 0260 / 0263 | Iter Loss 0.0972 | Iter Mean Loss 0.0973\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.071344 s\n",
      "Measure time: 0.017622 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 45, Hit Ratio:0.19526  |  Precision:0.12025  |  Recall:0.19735  |  NDCG:0.20133\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0045 Iter 0000 / 0263 | Iter Loss 0.0266 | Iter Mean Loss 0.0266\n",
      "KG Training: Epoch 0045 Iter 0000 / 0263 | Iter Loss 0.0209 | Iter Mean Loss 0.0209\n",
      "CL Training: Epoch 0045 Iter 0000 / 0263 | Iter Loss 0.0977 | Iter Mean Loss 0.0977\n",
      "CF Training: Epoch 0045 Iter 0020 / 0263 | Iter Loss 0.0174 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0045 Iter 0020 / 0263 | Iter Loss 0.0248 | Iter Mean Loss 0.0259\n",
      "CL Training: Epoch 0045 Iter 0020 / 0263 | Iter Loss 0.0978 | Iter Mean Loss 0.0976\n",
      "CF Training: Epoch 0045 Iter 0040 / 0263 | Iter Loss 0.0248 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0045 Iter 0040 / 0263 | Iter Loss 0.0268 | Iter Mean Loss 0.0275\n",
      "CL Training: Epoch 0045 Iter 0040 / 0263 | Iter Loss 0.0974 | Iter Mean Loss 0.0975\n",
      "CF Training: Epoch 0045 Iter 0060 / 0263 | Iter Loss 0.0212 | Iter Mean Loss 0.0195\n",
      "KG Training: Epoch 0045 Iter 0060 / 0263 | Iter Loss 0.0308 | Iter Mean Loss 0.0283\n",
      "CL Training: Epoch 0045 Iter 0060 / 0263 | Iter Loss 0.0974 | Iter Mean Loss 0.0973\n",
      "CF Training: Epoch 0045 Iter 0080 / 0263 | Iter Loss 0.0125 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0045 Iter 0080 / 0263 | Iter Loss 0.0276 | Iter Mean Loss 0.0288\n",
      "CL Training: Epoch 0045 Iter 0080 / 0263 | Iter Loss 0.0972 | Iter Mean Loss 0.0973\n",
      "CF Training: Epoch 0045 Iter 0100 / 0263 | Iter Loss 0.0147 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0045 Iter 0100 / 0263 | Iter Loss 0.0324 | Iter Mean Loss 0.0295\n",
      "CL Training: Epoch 0045 Iter 0100 / 0263 | Iter Loss 0.0970 | Iter Mean Loss 0.0972\n",
      "CF Training: Epoch 0045 Iter 0120 / 0263 | Iter Loss 0.0155 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0045 Iter 0120 / 0263 | Iter Loss 0.0358 | Iter Mean Loss 0.0305\n",
      "CL Training: Epoch 0045 Iter 0120 / 0263 | Iter Loss 0.0969 | Iter Mean Loss 0.0972\n",
      "CF Training: Epoch 0045 Iter 0140 / 0263 | Iter Loss 0.0148 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0045 Iter 0140 / 0263 | Iter Loss 0.0379 | Iter Mean Loss 0.0316\n",
      "CL Training: Epoch 0045 Iter 0140 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0971\n",
      "CF Training: Epoch 0045 Iter 0160 / 0263 | Iter Loss 0.0209 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0045 Iter 0160 / 0263 | Iter Loss 0.0388 | Iter Mean Loss 0.0326\n",
      "CL Training: Epoch 0045 Iter 0160 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0971\n",
      "CF Training: Epoch 0045 Iter 0180 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0045 Iter 0180 / 0263 | Iter Loss 0.0437 | Iter Mean Loss 0.0336\n",
      "CL Training: Epoch 0045 Iter 0180 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0970\n",
      "CF Training: Epoch 0045 Iter 0200 / 0263 | Iter Loss 0.0192 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0045 Iter 0200 / 0263 | Iter Loss 0.0484 | Iter Mean Loss 0.0345\n",
      "CL Training: Epoch 0045 Iter 0200 / 0263 | Iter Loss 0.0970 | Iter Mean Loss 0.0970\n",
      "CF Training: Epoch 0045 Iter 0220 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0045 Iter 0220 / 0263 | Iter Loss 0.0423 | Iter Mean Loss 0.0355\n",
      "CL Training: Epoch 0045 Iter 0220 / 0263 | Iter Loss 0.0972 | Iter Mean Loss 0.0970\n",
      "CF Training: Epoch 0045 Iter 0240 / 0263 | Iter Loss 0.0220 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0045 Iter 0240 / 0263 | Iter Loss 0.0483 | Iter Mean Loss 0.0365\n",
      "CL Training: Epoch 0045 Iter 0240 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0970\n",
      "CF Training: Epoch 0045 Iter 0260 / 0263 | Iter Loss 0.0144 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0045 Iter 0260 / 0263 | Iter Loss 0.0592 | Iter Mean Loss 0.0377\n",
      "CL Training: Epoch 0045 Iter 0260 / 0263 | Iter Loss 0.0973 | Iter Mean Loss 0.0970\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.799214 s\n",
      "Measure time: 0.017727 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 46, Hit Ratio:0.20914  |  Precision:0.1288  |  Recall:0.21094  |  NDCG:0.21767\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 14, Hit Ratio:0.21232  |  Precision:0.13076  |  Recall:0.21473  |  NDCG:0.23007\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0046 Iter 0000 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0164\n",
      "KG Training: Epoch 0046 Iter 0000 / 0263 | Iter Loss 0.0209 | Iter Mean Loss 0.0209\n",
      "CL Training: Epoch 0046 Iter 0000 / 0263 | Iter Loss 0.0972 | Iter Mean Loss 0.0972\n",
      "CF Training: Epoch 0046 Iter 0020 / 0263 | Iter Loss 0.0305 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0046 Iter 0020 / 0263 | Iter Loss 0.0292 | Iter Mean Loss 0.0263\n",
      "CL Training: Epoch 0046 Iter 0020 / 0263 | Iter Loss 0.0974 | Iter Mean Loss 0.0975\n",
      "CF Training: Epoch 0046 Iter 0040 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0046 Iter 0040 / 0263 | Iter Loss 0.0306 | Iter Mean Loss 0.0275\n",
      "CL Training: Epoch 0046 Iter 0040 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0973\n",
      "CF Training: Epoch 0046 Iter 0060 / 0263 | Iter Loss 0.0197 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0046 Iter 0060 / 0263 | Iter Loss 0.0314 | Iter Mean Loss 0.0283\n",
      "CL Training: Epoch 0046 Iter 0060 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0972\n",
      "CF Training: Epoch 0046 Iter 0080 / 0263 | Iter Loss 0.0098 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0046 Iter 0080 / 0263 | Iter Loss 0.0298 | Iter Mean Loss 0.0288\n",
      "CL Training: Epoch 0046 Iter 0080 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0971\n",
      "CF Training: Epoch 0046 Iter 0100 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0046 Iter 0100 / 0263 | Iter Loss 0.0366 | Iter Mean Loss 0.0295\n",
      "CL Training: Epoch 0046 Iter 0100 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0970\n",
      "CF Training: Epoch 0046 Iter 0120 / 0263 | Iter Loss 0.0213 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0046 Iter 0120 / 0263 | Iter Loss 0.0385 | Iter Mean Loss 0.0305\n",
      "CL Training: Epoch 0046 Iter 0120 / 0263 | Iter Loss 0.0959 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0046 Iter 0140 / 0263 | Iter Loss 0.0158 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0046 Iter 0140 / 0263 | Iter Loss 0.0415 | Iter Mean Loss 0.0315\n",
      "CL Training: Epoch 0046 Iter 0140 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0046 Iter 0160 / 0263 | Iter Loss 0.0242 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0046 Iter 0160 / 0263 | Iter Loss 0.0386 | Iter Mean Loss 0.0327\n",
      "CL Training: Epoch 0046 Iter 0160 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0046 Iter 0180 / 0263 | Iter Loss 0.0143 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0046 Iter 0180 / 0263 | Iter Loss 0.0460 | Iter Mean Loss 0.0336\n",
      "CL Training: Epoch 0046 Iter 0180 / 0263 | Iter Loss 0.0966 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0046 Iter 0200 / 0263 | Iter Loss 0.0214 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0046 Iter 0200 / 0263 | Iter Loss 0.0401 | Iter Mean Loss 0.0345\n",
      "CL Training: Epoch 0046 Iter 0200 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0046 Iter 0220 / 0263 | Iter Loss 0.0182 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0046 Iter 0220 / 0263 | Iter Loss 0.0493 | Iter Mean Loss 0.0354\n",
      "CL Training: Epoch 0046 Iter 0220 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0046 Iter 0240 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0046 Iter 0240 / 0263 | Iter Loss 0.0477 | Iter Mean Loss 0.0364\n",
      "CL Training: Epoch 0046 Iter 0240 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0046 Iter 0260 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0046 Iter 0260 / 0263 | Iter Loss 0.0581 | Iter Mean Loss 0.0375\n",
      "CL Training: Epoch 0046 Iter 0260 / 0263 | Iter Loss 0.0973 | Iter Mean Loss 0.0968\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.940858 s\n",
      "Measure time: 0.017391 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0047 Iter 0000 / 0263 | Iter Loss 0.0332 | Iter Mean Loss 0.0332\n",
      "KG Training: Epoch 0047 Iter 0000 / 0263 | Iter Loss 0.0219 | Iter Mean Loss 0.0219\n",
      "CL Training: Epoch 0047 Iter 0000 / 0263 | Iter Loss 0.0973 | Iter Mean Loss 0.0973\n",
      "CF Training: Epoch 0047 Iter 0020 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0047 Iter 0020 / 0263 | Iter Loss 0.0283 | Iter Mean Loss 0.0263\n",
      "CL Training: Epoch 0047 Iter 0020 / 0263 | Iter Loss 0.0971 | Iter Mean Loss 0.0973\n",
      "CF Training: Epoch 0047 Iter 0040 / 0263 | Iter Loss 0.0261 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0047 Iter 0040 / 0263 | Iter Loss 0.0273 | Iter Mean Loss 0.0276\n",
      "CL Training: Epoch 0047 Iter 0040 / 0263 | Iter Loss 0.0966 | Iter Mean Loss 0.0971\n",
      "CF Training: Epoch 0047 Iter 0060 / 0263 | Iter Loss 0.0186 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0047 Iter 0060 / 0263 | Iter Loss 0.0277 | Iter Mean Loss 0.0282\n",
      "CL Training: Epoch 0047 Iter 0060 / 0263 | Iter Loss 0.0966 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0047 Iter 0080 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0047 Iter 0080 / 0263 | Iter Loss 0.0284 | Iter Mean Loss 0.0288\n",
      "CL Training: Epoch 0047 Iter 0080 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0047 Iter 0100 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0047 Iter 0100 / 0263 | Iter Loss 0.0328 | Iter Mean Loss 0.0293\n",
      "CL Training: Epoch 0047 Iter 0100 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0047 Iter 0120 / 0263 | Iter Loss 0.0136 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0047 Iter 0120 / 0263 | Iter Loss 0.0347 | Iter Mean Loss 0.0302\n",
      "CL Training: Epoch 0047 Iter 0120 / 0263 | Iter Loss 0.0969 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0047 Iter 0140 / 0263 | Iter Loss 0.0166 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0047 Iter 0140 / 0263 | Iter Loss 0.0425 | Iter Mean Loss 0.0313\n",
      "CL Training: Epoch 0047 Iter 0140 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0047 Iter 0160 / 0263 | Iter Loss 0.0183 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0047 Iter 0160 / 0263 | Iter Loss 0.0377 | Iter Mean Loss 0.0324\n",
      "CL Training: Epoch 0047 Iter 0160 / 0263 | Iter Loss 0.0970 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0047 Iter 0180 / 0263 | Iter Loss 0.0148 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0047 Iter 0180 / 0263 | Iter Loss 0.0452 | Iter Mean Loss 0.0334\n",
      "CL Training: Epoch 0047 Iter 0180 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0047 Iter 0200 / 0263 | Iter Loss 0.0238 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0047 Iter 0200 / 0263 | Iter Loss 0.0480 | Iter Mean Loss 0.0345\n",
      "CL Training: Epoch 0047 Iter 0200 / 0263 | Iter Loss 0.0970 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0047 Iter 0220 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0047 Iter 0220 / 0263 | Iter Loss 0.0422 | Iter Mean Loss 0.0355\n",
      "CL Training: Epoch 0047 Iter 0220 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0047 Iter 0240 / 0263 | Iter Loss 0.0140 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0047 Iter 0240 / 0263 | Iter Loss 0.0468 | Iter Mean Loss 0.0364\n",
      "CL Training: Epoch 0047 Iter 0240 / 0263 | Iter Loss 0.0969 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0047 Iter 0260 / 0263 | Iter Loss 0.0138 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0047 Iter 0260 / 0263 | Iter Loss 0.0600 | Iter Mean Loss 0.0376\n",
      "CL Training: Epoch 0047 Iter 0260 / 0263 | Iter Loss 0.0969 | Iter Mean Loss 0.0968\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.992633 s\n",
      "Measure time: 0.023901 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 48, Hit Ratio:0.2047  |  Precision:0.12606  |  Recall:0.20732  |  NDCG:0.21618\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0048 Iter 0000 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0048 Iter 0000 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0228\n",
      "CL Training: Epoch 0048 Iter 0000 / 0263 | Iter Loss 0.0973 | Iter Mean Loss 0.0973\n",
      "CF Training: Epoch 0048 Iter 0020 / 0263 | Iter Loss 0.0194 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0048 Iter 0020 / 0263 | Iter Loss 0.0283 | Iter Mean Loss 0.0262\n",
      "CL Training: Epoch 0048 Iter 0020 / 0263 | Iter Loss 0.0973 | Iter Mean Loss 0.0975\n",
      "CF Training: Epoch 0048 Iter 0040 / 0263 | Iter Loss 0.0153 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0048 Iter 0040 / 0263 | Iter Loss 0.0276 | Iter Mean Loss 0.0273\n",
      "CL Training: Epoch 0048 Iter 0040 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0973\n",
      "CF Training: Epoch 0048 Iter 0060 / 0263 | Iter Loss 0.0167 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0048 Iter 0060 / 0263 | Iter Loss 0.0258 | Iter Mean Loss 0.0282\n",
      "CL Training: Epoch 0048 Iter 0060 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0971\n",
      "CF Training: Epoch 0048 Iter 0080 / 0263 | Iter Loss 0.0194 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0048 Iter 0080 / 0263 | Iter Loss 0.0301 | Iter Mean Loss 0.0286\n",
      "CL Training: Epoch 0048 Iter 0080 / 0263 | Iter Loss 0.0966 | Iter Mean Loss 0.0970\n",
      "CF Training: Epoch 0048 Iter 0100 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0048 Iter 0100 / 0263 | Iter Loss 0.0349 | Iter Mean Loss 0.0291\n",
      "CL Training: Epoch 0048 Iter 0100 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0048 Iter 0120 / 0263 | Iter Loss 0.0190 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0048 Iter 0120 / 0263 | Iter Loss 0.0321 | Iter Mean Loss 0.0301\n",
      "CL Training: Epoch 0048 Iter 0120 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0048 Iter 0140 / 0263 | Iter Loss 0.0224 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0048 Iter 0140 / 0263 | Iter Loss 0.0397 | Iter Mean Loss 0.0312\n",
      "CL Training: Epoch 0048 Iter 0140 / 0263 | Iter Loss 0.0984 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0048 Iter 0160 / 0263 | Iter Loss 0.0126 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0048 Iter 0160 / 0263 | Iter Loss 0.0436 | Iter Mean Loss 0.0326\n",
      "CL Training: Epoch 0048 Iter 0160 / 0263 | Iter Loss 0.0980 | Iter Mean Loss 0.0971\n",
      "CF Training: Epoch 0048 Iter 0180 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0048 Iter 0180 / 0263 | Iter Loss 0.0384 | Iter Mean Loss 0.0337\n",
      "CL Training: Epoch 0048 Iter 0180 / 0263 | Iter Loss 0.0974 | Iter Mean Loss 0.0972\n",
      "CF Training: Epoch 0048 Iter 0200 / 0263 | Iter Loss 0.0271 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0048 Iter 0200 / 0263 | Iter Loss 0.0423 | Iter Mean Loss 0.0349\n",
      "CL Training: Epoch 0048 Iter 0200 / 0263 | Iter Loss 0.0972 | Iter Mean Loss 0.0972\n",
      "CF Training: Epoch 0048 Iter 0220 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0048 Iter 0220 / 0263 | Iter Loss 0.0519 | Iter Mean Loss 0.0358\n",
      "CL Training: Epoch 0048 Iter 0220 / 0263 | Iter Loss 0.0970 | Iter Mean Loss 0.0972\n",
      "CF Training: Epoch 0048 Iter 0240 / 0263 | Iter Loss 0.0173 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0048 Iter 0240 / 0263 | Iter Loss 0.0464 | Iter Mean Loss 0.0369\n",
      "CL Training: Epoch 0048 Iter 0240 / 0263 | Iter Loss 0.0969 | Iter Mean Loss 0.0972\n",
      "CF Training: Epoch 0048 Iter 0260 / 0263 | Iter Loss 0.0199 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0048 Iter 0260 / 0263 | Iter Loss 0.0527 | Iter Mean Loss 0.0381\n",
      "CL Training: Epoch 0048 Iter 0260 / 0263 | Iter Loss 0.0971 | Iter Mean Loss 0.0972\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.977793 s\n",
      "Measure time: 0.017857 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 49, Hit Ratio:0.19836  |  Precision:0.12216  |  Recall:0.20008  |  NDCG:0.20105\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0049 Iter 0000 / 0263 | Iter Loss 0.0138 | Iter Mean Loss 0.0138\n",
      "KG Training: Epoch 0049 Iter 0000 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0207\n",
      "CL Training: Epoch 0049 Iter 0000 / 0263 | Iter Loss 0.0969 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0049 Iter 0020 / 0263 | Iter Loss 0.0116 | Iter Mean Loss 0.0172\n",
      "KG Training: Epoch 0049 Iter 0020 / 0263 | Iter Loss 0.0310 | Iter Mean Loss 0.0259\n",
      "CL Training: Epoch 0049 Iter 0020 / 0263 | Iter Loss 0.0974 | Iter Mean Loss 0.0971\n",
      "CF Training: Epoch 0049 Iter 0040 / 0263 | Iter Loss 0.0214 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0049 Iter 0040 / 0263 | Iter Loss 0.0291 | Iter Mean Loss 0.0272\n",
      "CL Training: Epoch 0049 Iter 0040 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0970\n",
      "CF Training: Epoch 0049 Iter 0060 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0049 Iter 0060 / 0263 | Iter Loss 0.0317 | Iter Mean Loss 0.0281\n",
      "CL Training: Epoch 0049 Iter 0060 / 0263 | Iter Loss 0.0971 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0049 Iter 0080 / 0263 | Iter Loss 0.0223 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0049 Iter 0080 / 0263 | Iter Loss 0.0294 | Iter Mean Loss 0.0288\n",
      "CL Training: Epoch 0049 Iter 0080 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0049 Iter 0100 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0049 Iter 0100 / 0263 | Iter Loss 0.0314 | Iter Mean Loss 0.0294\n",
      "CL Training: Epoch 0049 Iter 0100 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0049 Iter 0120 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0049 Iter 0120 / 0263 | Iter Loss 0.0361 | Iter Mean Loss 0.0304\n",
      "CL Training: Epoch 0049 Iter 0120 / 0263 | Iter Loss 0.0970 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0049 Iter 0140 / 0263 | Iter Loss 0.0132 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0049 Iter 0140 / 0263 | Iter Loss 0.0362 | Iter Mean Loss 0.0314\n",
      "CL Training: Epoch 0049 Iter 0140 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0049 Iter 0160 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0049 Iter 0160 / 0263 | Iter Loss 0.0369 | Iter Mean Loss 0.0325\n",
      "CL Training: Epoch 0049 Iter 0160 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0049 Iter 0180 / 0263 | Iter Loss 0.0190 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0049 Iter 0180 / 0263 | Iter Loss 0.0439 | Iter Mean Loss 0.0332\n",
      "CL Training: Epoch 0049 Iter 0180 / 0263 | Iter Loss 0.0966 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0049 Iter 0200 / 0263 | Iter Loss 0.0231 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0049 Iter 0200 / 0263 | Iter Loss 0.0388 | Iter Mean Loss 0.0341\n",
      "CL Training: Epoch 0049 Iter 0200 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0049 Iter 0220 / 0263 | Iter Loss 0.0180 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0049 Iter 0220 / 0263 | Iter Loss 0.0410 | Iter Mean Loss 0.0350\n",
      "CL Training: Epoch 0049 Iter 0220 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0967\n",
      "CF Training: Epoch 0049 Iter 0240 / 0263 | Iter Loss 0.0116 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0049 Iter 0240 / 0263 | Iter Loss 0.0470 | Iter Mean Loss 0.0360\n",
      "CL Training: Epoch 0049 Iter 0240 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0967\n",
      "CF Training: Epoch 0049 Iter 0260 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0049 Iter 0260 / 0263 | Iter Loss 0.0601 | Iter Mean Loss 0.0372\n",
      "CL Training: Epoch 0049 Iter 0260 / 0263 | Iter Loss 0.0970 | Iter Mean Loss 0.0968\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.070776 s\n",
      "Measure time: 0.019351 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 50, Hit Ratio:0.20827  |  Precision:0.12826  |  Recall:0.21022  |  NDCG:0.22094\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0050 Iter 0000 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0228\n",
      "KG Training: Epoch 0050 Iter 0000 / 0263 | Iter Loss 0.0221 | Iter Mean Loss 0.0221\n",
      "CL Training: Epoch 0050 Iter 0000 / 0263 | Iter Loss 0.0970 | Iter Mean Loss 0.0970\n",
      "CF Training: Epoch 0050 Iter 0020 / 0263 | Iter Loss 0.0204 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0050 Iter 0020 / 0263 | Iter Loss 0.0254 | Iter Mean Loss 0.0259\n",
      "CL Training: Epoch 0050 Iter 0020 / 0263 | Iter Loss 0.0971 | Iter Mean Loss 0.0971\n",
      "CF Training: Epoch 0050 Iter 0040 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0202\n",
      "KG Training: Epoch 0050 Iter 0040 / 0263 | Iter Loss 0.0328 | Iter Mean Loss 0.0273\n",
      "CL Training: Epoch 0050 Iter 0040 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0050 Iter 0060 / 0263 | Iter Loss 0.0200 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0050 Iter 0060 / 0263 | Iter Loss 0.0304 | Iter Mean Loss 0.0278\n",
      "CL Training: Epoch 0050 Iter 0060 / 0263 | Iter Loss 0.0971 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0050 Iter 0080 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0050 Iter 0080 / 0263 | Iter Loss 0.0303 | Iter Mean Loss 0.0285\n",
      "CL Training: Epoch 0050 Iter 0080 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0050 Iter 0100 / 0263 | Iter Loss 0.0206 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0050 Iter 0100 / 0263 | Iter Loss 0.0334 | Iter Mean Loss 0.0291\n",
      "CL Training: Epoch 0050 Iter 0100 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0050 Iter 0120 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0050 Iter 0120 / 0263 | Iter Loss 0.0366 | Iter Mean Loss 0.0301\n",
      "CL Training: Epoch 0050 Iter 0120 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0050 Iter 0140 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0050 Iter 0140 / 0263 | Iter Loss 0.0385 | Iter Mean Loss 0.0309\n",
      "CL Training: Epoch 0050 Iter 0140 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0050 Iter 0160 / 0263 | Iter Loss 0.0131 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0050 Iter 0160 / 0263 | Iter Loss 0.0412 | Iter Mean Loss 0.0319\n",
      "CL Training: Epoch 0050 Iter 0160 / 0263 | Iter Loss 0.0966 | Iter Mean Loss 0.0967\n",
      "CF Training: Epoch 0050 Iter 0180 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0050 Iter 0180 / 0263 | Iter Loss 0.0367 | Iter Mean Loss 0.0327\n",
      "CL Training: Epoch 0050 Iter 0180 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0967\n",
      "CF Training: Epoch 0050 Iter 0200 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0050 Iter 0200 / 0263 | Iter Loss 0.0432 | Iter Mean Loss 0.0337\n",
      "CL Training: Epoch 0050 Iter 0200 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0967\n",
      "CF Training: Epoch 0050 Iter 0220 / 0263 | Iter Loss 0.0173 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0050 Iter 0220 / 0263 | Iter Loss 0.0392 | Iter Mean Loss 0.0346\n",
      "CL Training: Epoch 0050 Iter 0220 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0967\n",
      "CF Training: Epoch 0050 Iter 0240 / 0263 | Iter Loss 0.0223 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0050 Iter 0240 / 0263 | Iter Loss 0.0447 | Iter Mean Loss 0.0354\n",
      "CL Training: Epoch 0050 Iter 0240 / 0263 | Iter Loss 0.0966 | Iter Mean Loss 0.0966\n",
      "CF Training: Epoch 0050 Iter 0260 / 0263 | Iter Loss 0.0191 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0050 Iter 0260 / 0263 | Iter Loss 0.0527 | Iter Mean Loss 0.0365\n",
      "CL Training: Epoch 0050 Iter 0260 / 0263 | Iter Loss 0.0969 | Iter Mean Loss 0.0966\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.064139 s\n",
      "Measure time: 0.017711 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 51, Hit Ratio:0.20138  |  Precision:0.12402  |  Recall:0.20311  |  NDCG:0.21\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0051 Iter 0000 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0203\n",
      "KG Training: Epoch 0051 Iter 0000 / 0263 | Iter Loss 0.0213 | Iter Mean Loss 0.0213\n",
      "CL Training: Epoch 0051 Iter 0000 / 0263 | Iter Loss 0.0969 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0051 Iter 0020 / 0263 | Iter Loss 0.0146 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0051 Iter 0020 / 0263 | Iter Loss 0.0263 | Iter Mean Loss 0.0256\n",
      "CL Training: Epoch 0051 Iter 0020 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0966\n",
      "CF Training: Epoch 0051 Iter 0040 / 0263 | Iter Loss 0.0146 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0051 Iter 0040 / 0263 | Iter Loss 0.0268 | Iter Mean Loss 0.0267\n",
      "CL Training: Epoch 0051 Iter 0040 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0965\n",
      "CF Training: Epoch 0051 Iter 0060 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0051 Iter 0060 / 0263 | Iter Loss 0.0273 | Iter Mean Loss 0.0276\n",
      "CL Training: Epoch 0051 Iter 0060 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0964\n",
      "CF Training: Epoch 0051 Iter 0080 / 0263 | Iter Loss 0.0138 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0051 Iter 0080 / 0263 | Iter Loss 0.0297 | Iter Mean Loss 0.0282\n",
      "CL Training: Epoch 0051 Iter 0080 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0964\n",
      "CF Training: Epoch 0051 Iter 0100 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0051 Iter 0100 / 0263 | Iter Loss 0.0321 | Iter Mean Loss 0.0288\n",
      "CL Training: Epoch 0051 Iter 0100 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0051 Iter 0120 / 0263 | Iter Loss 0.0206 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0051 Iter 0120 / 0263 | Iter Loss 0.0322 | Iter Mean Loss 0.0297\n",
      "CL Training: Epoch 0051 Iter 0120 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0051 Iter 0140 / 0263 | Iter Loss 0.0174 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0051 Iter 0140 / 0263 | Iter Loss 0.0340 | Iter Mean Loss 0.0306\n",
      "CL Training: Epoch 0051 Iter 0140 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0051 Iter 0160 / 0263 | Iter Loss 0.0180 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0051 Iter 0160 / 0263 | Iter Loss 0.0406 | Iter Mean Loss 0.0318\n",
      "CL Training: Epoch 0051 Iter 0160 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0051 Iter 0180 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0051 Iter 0180 / 0263 | Iter Loss 0.0444 | Iter Mean Loss 0.0327\n",
      "CL Training: Epoch 0051 Iter 0180 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0051 Iter 0200 / 0263 | Iter Loss 0.0250 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0051 Iter 0200 / 0263 | Iter Loss 0.0446 | Iter Mean Loss 0.0337\n",
      "CL Training: Epoch 0051 Iter 0200 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0051 Iter 0220 / 0263 | Iter Loss 0.0231 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0051 Iter 0220 / 0263 | Iter Loss 0.0454 | Iter Mean Loss 0.0346\n",
      "CL Training: Epoch 0051 Iter 0220 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0051 Iter 0240 / 0263 | Iter Loss 0.0190 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0051 Iter 0240 / 0263 | Iter Loss 0.0506 | Iter Mean Loss 0.0357\n",
      "CL Training: Epoch 0051 Iter 0240 / 0263 | Iter Loss 0.0966 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0051 Iter 0260 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0051 Iter 0260 / 0263 | Iter Loss 0.0575 | Iter Mean Loss 0.0369\n",
      "CL Training: Epoch 0051 Iter 0260 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0963\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.941747 s\n",
      "Measure time: 0.019267 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 52, Hit Ratio:0.20612  |  Precision:0.12694  |  Recall:0.20741  |  NDCG:0.21463\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0052 Iter 0000 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0052 Iter 0000 / 0263 | Iter Loss 0.0221 | Iter Mean Loss 0.0221\n",
      "CL Training: Epoch 0052 Iter 0000 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0967\n",
      "CF Training: Epoch 0052 Iter 0020 / 0263 | Iter Loss 0.0199 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0052 Iter 0020 / 0263 | Iter Loss 0.0259 | Iter Mean Loss 0.0256\n",
      "CL Training: Epoch 0052 Iter 0020 / 0263 | Iter Loss 0.0966 | Iter Mean Loss 0.0966\n",
      "CF Training: Epoch 0052 Iter 0040 / 0263 | Iter Loss 0.0110 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0052 Iter 0040 / 0263 | Iter Loss 0.0285 | Iter Mean Loss 0.0269\n",
      "CL Training: Epoch 0052 Iter 0040 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0966\n",
      "CF Training: Epoch 0052 Iter 0060 / 0263 | Iter Loss 0.0102 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0052 Iter 0060 / 0263 | Iter Loss 0.0290 | Iter Mean Loss 0.0273\n",
      "CL Training: Epoch 0052 Iter 0060 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0965\n",
      "CF Training: Epoch 0052 Iter 0080 / 0263 | Iter Loss 0.0219 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0052 Iter 0080 / 0263 | Iter Loss 0.0284 | Iter Mean Loss 0.0278\n",
      "CL Training: Epoch 0052 Iter 0080 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0965\n",
      "CF Training: Epoch 0052 Iter 0100 / 0263 | Iter Loss 0.0163 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0052 Iter 0100 / 0263 | Iter Loss 0.0355 | Iter Mean Loss 0.0283\n",
      "CL Training: Epoch 0052 Iter 0100 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0964\n",
      "CF Training: Epoch 0052 Iter 0120 / 0263 | Iter Loss 0.0219 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0052 Iter 0120 / 0263 | Iter Loss 0.0371 | Iter Mean Loss 0.0296\n",
      "CL Training: Epoch 0052 Iter 0120 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0964\n",
      "CF Training: Epoch 0052 Iter 0140 / 0263 | Iter Loss 0.0141 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0052 Iter 0140 / 0263 | Iter Loss 0.0371 | Iter Mean Loss 0.0306\n",
      "CL Training: Epoch 0052 Iter 0140 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0052 Iter 0160 / 0263 | Iter Loss 0.0181 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0052 Iter 0160 / 0263 | Iter Loss 0.0425 | Iter Mean Loss 0.0317\n",
      "CL Training: Epoch 0052 Iter 0160 / 0263 | Iter Loss 0.0969 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0052 Iter 0180 / 0263 | Iter Loss 0.0138 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0052 Iter 0180 / 0263 | Iter Loss 0.0422 | Iter Mean Loss 0.0329\n",
      "CL Training: Epoch 0052 Iter 0180 / 0263 | Iter Loss 0.0970 | Iter Mean Loss 0.0964\n",
      "CF Training: Epoch 0052 Iter 0200 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0052 Iter 0200 / 0263 | Iter Loss 0.0441 | Iter Mean Loss 0.0339\n",
      "CL Training: Epoch 0052 Iter 0200 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0964\n",
      "CF Training: Epoch 0052 Iter 0220 / 0263 | Iter Loss 0.0214 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0052 Iter 0220 / 0263 | Iter Loss 0.0486 | Iter Mean Loss 0.0350\n",
      "CL Training: Epoch 0052 Iter 0220 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0964\n",
      "CF Training: Epoch 0052 Iter 0240 / 0263 | Iter Loss 0.0181 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0052 Iter 0240 / 0263 | Iter Loss 0.0449 | Iter Mean Loss 0.0360\n",
      "CL Training: Epoch 0052 Iter 0240 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0964\n",
      "CF Training: Epoch 0052 Iter 0260 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0052 Iter 0260 / 0263 | Iter Loss 0.0535 | Iter Mean Loss 0.0372\n",
      "CL Training: Epoch 0052 Iter 0260 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0964\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.048796 s\n",
      "Measure time: 0.017509 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 53, Hit Ratio:0.21349  |  Precision:0.13148  |  Recall:0.21501  |  NDCG:0.22134\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0053 Iter 0000 / 0263 | Iter Loss 0.0220 | Iter Mean Loss 0.0220\n",
      "KG Training: Epoch 0053 Iter 0000 / 0263 | Iter Loss 0.0230 | Iter Mean Loss 0.0230\n",
      "CL Training: Epoch 0053 Iter 0000 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0053 Iter 0020 / 0263 | Iter Loss 0.0240 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0053 Iter 0020 / 0263 | Iter Loss 0.0279 | Iter Mean Loss 0.0261\n",
      "CL Training: Epoch 0053 Iter 0020 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0964\n",
      "CF Training: Epoch 0053 Iter 0040 / 0263 | Iter Loss 0.0162 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0053 Iter 0040 / 0263 | Iter Loss 0.0300 | Iter Mean Loss 0.0273\n",
      "CL Training: Epoch 0053 Iter 0040 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0053 Iter 0060 / 0263 | Iter Loss 0.0169 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0053 Iter 0060 / 0263 | Iter Loss 0.0276 | Iter Mean Loss 0.0277\n",
      "CL Training: Epoch 0053 Iter 0060 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0053 Iter 0080 / 0263 | Iter Loss 0.0150 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0053 Iter 0080 / 0263 | Iter Loss 0.0306 | Iter Mean Loss 0.0283\n",
      "CL Training: Epoch 0053 Iter 0080 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0053 Iter 0100 / 0263 | Iter Loss 0.0188 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0053 Iter 0100 / 0263 | Iter Loss 0.0321 | Iter Mean Loss 0.0289\n",
      "CL Training: Epoch 0053 Iter 0100 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0053 Iter 0120 / 0263 | Iter Loss 0.0241 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0053 Iter 0120 / 0263 | Iter Loss 0.0319 | Iter Mean Loss 0.0299\n",
      "CL Training: Epoch 0053 Iter 0120 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0053 Iter 0140 / 0263 | Iter Loss 0.0155 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0053 Iter 0140 / 0263 | Iter Loss 0.0376 | Iter Mean Loss 0.0309\n",
      "CL Training: Epoch 0053 Iter 0140 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0053 Iter 0160 / 0263 | Iter Loss 0.0125 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0053 Iter 0160 / 0263 | Iter Loss 0.0411 | Iter Mean Loss 0.0320\n",
      "CL Training: Epoch 0053 Iter 0160 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0053 Iter 0180 / 0263 | Iter Loss 0.0263 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0053 Iter 0180 / 0263 | Iter Loss 0.0450 | Iter Mean Loss 0.0331\n",
      "CL Training: Epoch 0053 Iter 0180 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0053 Iter 0200 / 0263 | Iter Loss 0.0219 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0053 Iter 0200 / 0263 | Iter Loss 0.0472 | Iter Mean Loss 0.0341\n",
      "CL Training: Epoch 0053 Iter 0200 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0053 Iter 0220 / 0263 | Iter Loss 0.0141 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0053 Iter 0220 / 0263 | Iter Loss 0.0425 | Iter Mean Loss 0.0349\n",
      "CL Training: Epoch 0053 Iter 0220 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0053 Iter 0240 / 0263 | Iter Loss 0.0139 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0053 Iter 0240 / 0263 | Iter Loss 0.0454 | Iter Mean Loss 0.0358\n",
      "CL Training: Epoch 0053 Iter 0240 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0053 Iter 0260 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0053 Iter 0260 / 0263 | Iter Loss 0.0558 | Iter Mean Loss 0.0369\n",
      "CL Training: Epoch 0053 Iter 0260 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0962\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.013893 s\n",
      "Measure time: 0.017433 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 54, Hit Ratio:0.18375  |  Precision:0.11316  |  Recall:0.18593  |  NDCG:0.18493\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0054 Iter 0000 / 0263 | Iter Loss 0.0162 | Iter Mean Loss 0.0162\n",
      "KG Training: Epoch 0054 Iter 0000 / 0263 | Iter Loss 0.0213 | Iter Mean Loss 0.0213\n",
      "CL Training: Epoch 0054 Iter 0000 / 0263 | Iter Loss 0.0968 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0054 Iter 0020 / 0263 | Iter Loss 0.0155 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0054 Iter 0020 / 0263 | Iter Loss 0.0314 | Iter Mean Loss 0.0261\n",
      "CL Training: Epoch 0054 Iter 0020 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0965\n",
      "CF Training: Epoch 0054 Iter 0040 / 0263 | Iter Loss 0.0190 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0054 Iter 0040 / 0263 | Iter Loss 0.0300 | Iter Mean Loss 0.0270\n",
      "CL Training: Epoch 0054 Iter 0040 / 0263 | Iter Loss 0.0959 | Iter Mean Loss 0.0964\n",
      "CF Training: Epoch 0054 Iter 0060 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0054 Iter 0060 / 0263 | Iter Loss 0.0285 | Iter Mean Loss 0.0274\n",
      "CL Training: Epoch 0054 Iter 0060 / 0263 | Iter Loss 0.0959 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0054 Iter 0080 / 0263 | Iter Loss 0.0180 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0054 Iter 0080 / 0263 | Iter Loss 0.0297 | Iter Mean Loss 0.0279\n",
      "CL Training: Epoch 0054 Iter 0080 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0054 Iter 0100 / 0263 | Iter Loss 0.0159 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0054 Iter 0100 / 0263 | Iter Loss 0.0304 | Iter Mean Loss 0.0286\n",
      "CL Training: Epoch 0054 Iter 0100 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0054 Iter 0120 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0054 Iter 0120 / 0263 | Iter Loss 0.0345 | Iter Mean Loss 0.0297\n",
      "CL Training: Epoch 0054 Iter 0120 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0054 Iter 0140 / 0263 | Iter Loss 0.0247 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0054 Iter 0140 / 0263 | Iter Loss 0.0383 | Iter Mean Loss 0.0306\n",
      "CL Training: Epoch 0054 Iter 0140 / 0263 | Iter Loss 0.0966 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0054 Iter 0160 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0054 Iter 0160 / 0263 | Iter Loss 0.0395 | Iter Mean Loss 0.0317\n",
      "CL Training: Epoch 0054 Iter 0160 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0054 Iter 0180 / 0263 | Iter Loss 0.0185 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0054 Iter 0180 / 0263 | Iter Loss 0.0374 | Iter Mean Loss 0.0326\n",
      "CL Training: Epoch 0054 Iter 0180 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0054 Iter 0200 / 0263 | Iter Loss 0.0231 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0054 Iter 0200 / 0263 | Iter Loss 0.0403 | Iter Mean Loss 0.0335\n",
      "CL Training: Epoch 0054 Iter 0200 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0054 Iter 0220 / 0263 | Iter Loss 0.0132 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0054 Iter 0220 / 0263 | Iter Loss 0.0400 | Iter Mean Loss 0.0344\n",
      "CL Training: Epoch 0054 Iter 0220 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0054 Iter 0240 / 0263 | Iter Loss 0.0194 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0054 Iter 0240 / 0263 | Iter Loss 0.0511 | Iter Mean Loss 0.0353\n",
      "CL Training: Epoch 0054 Iter 0240 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0054 Iter 0260 / 0263 | Iter Loss 0.0192 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0054 Iter 0260 / 0263 | Iter Loss 0.0588 | Iter Mean Loss 0.0364\n",
      "CL Training: Epoch 0054 Iter 0260 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0962\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.045979 s\n",
      "Measure time: 0.017551 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 55, Hit Ratio:0.18716  |  Precision:0.11526  |  Recall:0.18937  |  NDCG:0.19023\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0055 Iter 0000 / 0263 | Iter Loss 0.0155 | Iter Mean Loss 0.0155\n",
      "KG Training: Epoch 0055 Iter 0000 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0208\n",
      "CL Training: Epoch 0055 Iter 0000 / 0263 | Iter Loss 0.0959 | Iter Mean Loss 0.0959\n",
      "CF Training: Epoch 0055 Iter 0020 / 0263 | Iter Loss 0.0229 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0055 Iter 0020 / 0263 | Iter Loss 0.0290 | Iter Mean Loss 0.0251\n",
      "CL Training: Epoch 0055 Iter 0020 / 0263 | Iter Loss 0.0966 | Iter Mean Loss 0.0964\n",
      "CF Training: Epoch 0055 Iter 0040 / 0263 | Iter Loss 0.0134 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0055 Iter 0040 / 0263 | Iter Loss 0.0306 | Iter Mean Loss 0.0266\n",
      "CL Training: Epoch 0055 Iter 0040 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0964\n",
      "CF Training: Epoch 0055 Iter 0060 / 0263 | Iter Loss 0.0243 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0055 Iter 0060 / 0263 | Iter Loss 0.0292 | Iter Mean Loss 0.0275\n",
      "CL Training: Epoch 0055 Iter 0060 / 0263 | Iter Loss 0.0966 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0055 Iter 0080 / 0263 | Iter Loss 0.0190 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0055 Iter 0080 / 0263 | Iter Loss 0.0343 | Iter Mean Loss 0.0281\n",
      "CL Training: Epoch 0055 Iter 0080 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0055 Iter 0100 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0055 Iter 0100 / 0263 | Iter Loss 0.0314 | Iter Mean Loss 0.0287\n",
      "CL Training: Epoch 0055 Iter 0100 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0055 Iter 0120 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0055 Iter 0120 / 0263 | Iter Loss 0.0305 | Iter Mean Loss 0.0296\n",
      "CL Training: Epoch 0055 Iter 0120 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0055 Iter 0140 / 0263 | Iter Loss 0.0216 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0055 Iter 0140 / 0263 | Iter Loss 0.0361 | Iter Mean Loss 0.0306\n",
      "CL Training: Epoch 0055 Iter 0140 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0055 Iter 0160 / 0263 | Iter Loss 0.0216 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0055 Iter 0160 / 0263 | Iter Loss 0.0343 | Iter Mean Loss 0.0316\n",
      "CL Training: Epoch 0055 Iter 0160 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0055 Iter 0180 / 0263 | Iter Loss 0.0140 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0055 Iter 0180 / 0263 | Iter Loss 0.0423 | Iter Mean Loss 0.0326\n",
      "CL Training: Epoch 0055 Iter 0180 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0055 Iter 0200 / 0263 | Iter Loss 0.0195 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0055 Iter 0200 / 0263 | Iter Loss 0.0433 | Iter Mean Loss 0.0334\n",
      "CL Training: Epoch 0055 Iter 0200 / 0263 | Iter Loss 0.0959 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0055 Iter 0220 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0055 Iter 0220 / 0263 | Iter Loss 0.0484 | Iter Mean Loss 0.0342\n",
      "CL Training: Epoch 0055 Iter 0220 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0055 Iter 0240 / 0263 | Iter Loss 0.0214 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0055 Iter 0240 / 0263 | Iter Loss 0.0478 | Iter Mean Loss 0.0353\n",
      "CL Training: Epoch 0055 Iter 0240 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0055 Iter 0260 / 0263 | Iter Loss 0.0266 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0055 Iter 0260 / 0263 | Iter Loss 0.0578 | Iter Mean Loss 0.0364\n",
      "CL Training: Epoch 0055 Iter 0260 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0962\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.991976 s\n",
      "Measure time: 0.017427 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 56, Hit Ratio:0.2025  |  Precision:0.12471  |  Recall:0.20413  |  NDCG:0.21132\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0056 Iter 0000 / 0263 | Iter Loss 0.0213 | Iter Mean Loss 0.0213\n",
      "KG Training: Epoch 0056 Iter 0000 / 0263 | Iter Loss 0.0195 | Iter Mean Loss 0.0195\n",
      "CL Training: Epoch 0056 Iter 0000 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0056 Iter 0020 / 0263 | Iter Loss 0.0192 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0056 Iter 0020 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0247\n",
      "CL Training: Epoch 0056 Iter 0020 / 0263 | Iter Loss 0.0970 | Iter Mean Loss 0.0969\n",
      "CF Training: Epoch 0056 Iter 0040 / 0263 | Iter Loss 0.0278 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0056 Iter 0040 / 0263 | Iter Loss 0.0303 | Iter Mean Loss 0.0262\n",
      "CL Training: Epoch 0056 Iter 0040 / 0263 | Iter Loss 0.0973 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0056 Iter 0060 / 0263 | Iter Loss 0.0265 | Iter Mean Loss 0.0195\n",
      "KG Training: Epoch 0056 Iter 0060 / 0263 | Iter Loss 0.0295 | Iter Mean Loss 0.0270\n",
      "CL Training: Epoch 0056 Iter 0060 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0968\n",
      "CF Training: Epoch 0056 Iter 0080 / 0263 | Iter Loss 0.0233 | Iter Mean Loss 0.0195\n",
      "KG Training: Epoch 0056 Iter 0080 / 0263 | Iter Loss 0.0287 | Iter Mean Loss 0.0275\n",
      "CL Training: Epoch 0056 Iter 0080 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0967\n",
      "CF Training: Epoch 0056 Iter 0100 / 0263 | Iter Loss 0.0337 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0056 Iter 0100 / 0263 | Iter Loss 0.0330 | Iter Mean Loss 0.0284\n",
      "CL Training: Epoch 0056 Iter 0100 / 0263 | Iter Loss 0.0966 | Iter Mean Loss 0.0967\n",
      "CF Training: Epoch 0056 Iter 0120 / 0263 | Iter Loss 0.0238 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0056 Iter 0120 / 0263 | Iter Loss 0.0376 | Iter Mean Loss 0.0292\n",
      "CL Training: Epoch 0056 Iter 0120 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0966\n",
      "CF Training: Epoch 0056 Iter 0140 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0197\n",
      "KG Training: Epoch 0056 Iter 0140 / 0263 | Iter Loss 0.0377 | Iter Mean Loss 0.0302\n",
      "CL Training: Epoch 0056 Iter 0140 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0966\n",
      "CF Training: Epoch 0056 Iter 0160 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0056 Iter 0160 / 0263 | Iter Loss 0.0406 | Iter Mean Loss 0.0314\n",
      "CL Training: Epoch 0056 Iter 0160 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0966\n",
      "CF Training: Epoch 0056 Iter 0180 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0056 Iter 0180 / 0263 | Iter Loss 0.0390 | Iter Mean Loss 0.0324\n",
      "CL Training: Epoch 0056 Iter 0180 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0965\n",
      "CF Training: Epoch 0056 Iter 0200 / 0263 | Iter Loss 0.0134 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0056 Iter 0200 / 0263 | Iter Loss 0.0430 | Iter Mean Loss 0.0333\n",
      "CL Training: Epoch 0056 Iter 0200 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0965\n",
      "CF Training: Epoch 0056 Iter 0220 / 0263 | Iter Loss 0.0162 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0056 Iter 0220 / 0263 | Iter Loss 0.0450 | Iter Mean Loss 0.0341\n",
      "CL Training: Epoch 0056 Iter 0220 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0965\n",
      "CF Training: Epoch 0056 Iter 0240 / 0263 | Iter Loss 0.0250 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0056 Iter 0240 / 0263 | Iter Loss 0.0433 | Iter Mean Loss 0.0349\n",
      "CL Training: Epoch 0056 Iter 0240 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0964\n",
      "CF Training: Epoch 0056 Iter 0260 / 0263 | Iter Loss 0.0120 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0056 Iter 0260 / 0263 | Iter Loss 0.0593 | Iter Mean Loss 0.0361\n",
      "CL Training: Epoch 0056 Iter 0260 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0964\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.023758 s\n",
      "Measure time: 0.019238 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 57, Hit Ratio:0.20858  |  Precision:0.12845  |  Recall:0.21056  |  NDCG:0.21601\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0057 Iter 0000 / 0263 | Iter Loss 0.0135 | Iter Mean Loss 0.0135\n",
      "KG Training: Epoch 0057 Iter 0000 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0207\n",
      "CL Training: Epoch 0057 Iter 0000 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0964\n",
      "CF Training: Epoch 0057 Iter 0020 / 0263 | Iter Loss 0.0193 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0057 Iter 0020 / 0263 | Iter Loss 0.0275 | Iter Mean Loss 0.0251\n",
      "CL Training: Epoch 0057 Iter 0020 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0965\n",
      "CF Training: Epoch 0057 Iter 0040 / 0263 | Iter Loss 0.0269 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0057 Iter 0040 / 0263 | Iter Loss 0.0278 | Iter Mean Loss 0.0262\n",
      "CL Training: Epoch 0057 Iter 0040 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0963\n",
      "CF Training: Epoch 0057 Iter 0060 / 0263 | Iter Loss 0.0155 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0057 Iter 0060 / 0263 | Iter Loss 0.0289 | Iter Mean Loss 0.0270\n",
      "CL Training: Epoch 0057 Iter 0060 / 0263 | Iter Loss 0.0959 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0057 Iter 0080 / 0263 | Iter Loss 0.0210 | Iter Mean Loss 0.0195\n",
      "KG Training: Epoch 0057 Iter 0080 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0275\n",
      "CL Training: Epoch 0057 Iter 0080 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0057 Iter 0100 / 0263 | Iter Loss 0.0210 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0057 Iter 0100 / 0263 | Iter Loss 0.0292 | Iter Mean Loss 0.0280\n",
      "CL Training: Epoch 0057 Iter 0100 / 0263 | Iter Loss 0.0959 | Iter Mean Loss 0.0961\n",
      "CF Training: Epoch 0057 Iter 0120 / 0263 | Iter Loss 0.0152 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0057 Iter 0120 / 0263 | Iter Loss 0.0345 | Iter Mean Loss 0.0289\n",
      "CL Training: Epoch 0057 Iter 0120 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0961\n",
      "CF Training: Epoch 0057 Iter 0140 / 0263 | Iter Loss 0.0188 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0057 Iter 0140 / 0263 | Iter Loss 0.0389 | Iter Mean Loss 0.0299\n",
      "CL Training: Epoch 0057 Iter 0140 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0961\n",
      "CF Training: Epoch 0057 Iter 0160 / 0263 | Iter Loss 0.0194 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0057 Iter 0160 / 0263 | Iter Loss 0.0421 | Iter Mean Loss 0.0309\n",
      "CL Training: Epoch 0057 Iter 0160 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0961\n",
      "CF Training: Epoch 0057 Iter 0180 / 0263 | Iter Loss 0.0247 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0057 Iter 0180 / 0263 | Iter Loss 0.0390 | Iter Mean Loss 0.0319\n",
      "CL Training: Epoch 0057 Iter 0180 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0961\n",
      "CF Training: Epoch 0057 Iter 0200 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0057 Iter 0200 / 0263 | Iter Loss 0.0424 | Iter Mean Loss 0.0328\n",
      "CL Training: Epoch 0057 Iter 0200 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0057 Iter 0220 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0057 Iter 0220 / 0263 | Iter Loss 0.0422 | Iter Mean Loss 0.0337\n",
      "CL Training: Epoch 0057 Iter 0220 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0057 Iter 0240 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0057 Iter 0240 / 0263 | Iter Loss 0.0460 | Iter Mean Loss 0.0347\n",
      "CL Training: Epoch 0057 Iter 0240 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0057 Iter 0260 / 0263 | Iter Loss 0.0138 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0057 Iter 0260 / 0263 | Iter Loss 0.0585 | Iter Mean Loss 0.0358\n",
      "CL Training: Epoch 0057 Iter 0260 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0960\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.978319 s\n",
      "Measure time: 0.021734 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 58, Hit Ratio:0.21021  |  Precision:0.12946  |  Recall:0.2122  |  NDCG:0.2208\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0058 Iter 0000 / 0263 | Iter Loss 0.0167 | Iter Mean Loss 0.0167\n",
      "KG Training: Epoch 0058 Iter 0000 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0205\n",
      "CL Training: Epoch 0058 Iter 0000 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0058 Iter 0020 / 0263 | Iter Loss 0.0182 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0058 Iter 0020 / 0263 | Iter Loss 0.0241 | Iter Mean Loss 0.0248\n",
      "CL Training: Epoch 0058 Iter 0020 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0058 Iter 0040 / 0263 | Iter Loss 0.0200 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0058 Iter 0040 / 0263 | Iter Loss 0.0270 | Iter Mean Loss 0.0262\n",
      "CL Training: Epoch 0058 Iter 0040 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0959\n",
      "CF Training: Epoch 0058 Iter 0060 / 0263 | Iter Loss 0.0136 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0058 Iter 0060 / 0263 | Iter Loss 0.0322 | Iter Mean Loss 0.0268\n",
      "CL Training: Epoch 0058 Iter 0060 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0058 Iter 0080 / 0263 | Iter Loss 0.0148 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0058 Iter 0080 / 0263 | Iter Loss 0.0336 | Iter Mean Loss 0.0275\n",
      "CL Training: Epoch 0058 Iter 0080 / 0263 | Iter Loss 0.0967 | Iter Mean Loss 0.0959\n",
      "CF Training: Epoch 0058 Iter 0100 / 0263 | Iter Loss 0.0140 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0058 Iter 0100 / 0263 | Iter Loss 0.0323 | Iter Mean Loss 0.0281\n",
      "CL Training: Epoch 0058 Iter 0100 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0058 Iter 0120 / 0263 | Iter Loss 0.0146 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0058 Iter 0120 / 0263 | Iter Loss 0.0330 | Iter Mean Loss 0.0289\n",
      "CL Training: Epoch 0058 Iter 0120 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0959\n",
      "CF Training: Epoch 0058 Iter 0140 / 0263 | Iter Loss 0.0146 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0058 Iter 0140 / 0263 | Iter Loss 0.0437 | Iter Mean Loss 0.0299\n",
      "CL Training: Epoch 0058 Iter 0140 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0959\n",
      "CF Training: Epoch 0058 Iter 0160 / 0263 | Iter Loss 0.0136 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0058 Iter 0160 / 0263 | Iter Loss 0.0403 | Iter Mean Loss 0.0309\n",
      "CL Training: Epoch 0058 Iter 0160 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0058 Iter 0180 / 0263 | Iter Loss 0.0150 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0058 Iter 0180 / 0263 | Iter Loss 0.0401 | Iter Mean Loss 0.0317\n",
      "CL Training: Epoch 0058 Iter 0180 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0058 Iter 0200 / 0263 | Iter Loss 0.0136 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0058 Iter 0200 / 0263 | Iter Loss 0.0408 | Iter Mean Loss 0.0326\n",
      "CL Training: Epoch 0058 Iter 0200 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0058 Iter 0220 / 0263 | Iter Loss 0.0144 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0058 Iter 0220 / 0263 | Iter Loss 0.0481 | Iter Mean Loss 0.0335\n",
      "CL Training: Epoch 0058 Iter 0220 / 0263 | Iter Loss 0.0959 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0058 Iter 0240 / 0263 | Iter Loss 0.0144 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0058 Iter 0240 / 0263 | Iter Loss 0.0459 | Iter Mean Loss 0.0345\n",
      "CL Training: Epoch 0058 Iter 0240 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0058 Iter 0260 / 0263 | Iter Loss 0.0231 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0058 Iter 0260 / 0263 | Iter Loss 0.0597 | Iter Mean Loss 0.0358\n",
      "CL Training: Epoch 0058 Iter 0260 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0958\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.991270 s\n",
      "Measure time: 0.017864 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 59, Hit Ratio:0.21508  |  Precision:0.13246  |  Recall:0.21751  |  NDCG:0.22565\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0059 Iter 0000 / 0263 | Iter Loss 0.0157 | Iter Mean Loss 0.0157\n",
      "KG Training: Epoch 0059 Iter 0000 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0189\n",
      "CL Training: Epoch 0059 Iter 0000 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0965\n",
      "CF Training: Epoch 0059 Iter 0020 / 0263 | Iter Loss 0.0226 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0059 Iter 0020 / 0263 | Iter Loss 0.0310 | Iter Mean Loss 0.0257\n",
      "CL Training: Epoch 0059 Iter 0020 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0059 Iter 0040 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0059 Iter 0040 / 0263 | Iter Loss 0.0306 | Iter Mean Loss 0.0268\n",
      "CL Training: Epoch 0059 Iter 0040 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0962\n",
      "CF Training: Epoch 0059 Iter 0060 / 0263 | Iter Loss 0.0154 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0059 Iter 0060 / 0263 | Iter Loss 0.0282 | Iter Mean Loss 0.0275\n",
      "CL Training: Epoch 0059 Iter 0060 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0961\n",
      "CF Training: Epoch 0059 Iter 0080 / 0263 | Iter Loss 0.0219 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0059 Iter 0080 / 0263 | Iter Loss 0.0320 | Iter Mean Loss 0.0279\n",
      "CL Training: Epoch 0059 Iter 0080 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0961\n",
      "CF Training: Epoch 0059 Iter 0100 / 0263 | Iter Loss 0.0145 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0059 Iter 0100 / 0263 | Iter Loss 0.0340 | Iter Mean Loss 0.0284\n",
      "CL Training: Epoch 0059 Iter 0100 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0961\n",
      "CF Training: Epoch 0059 Iter 0120 / 0263 | Iter Loss 0.0103 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0059 Iter 0120 / 0263 | Iter Loss 0.0344 | Iter Mean Loss 0.0294\n",
      "CL Training: Epoch 0059 Iter 0120 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0961\n",
      "CF Training: Epoch 0059 Iter 0140 / 0263 | Iter Loss 0.0158 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0059 Iter 0140 / 0263 | Iter Loss 0.0365 | Iter Mean Loss 0.0304\n",
      "CL Training: Epoch 0059 Iter 0140 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0961\n",
      "CF Training: Epoch 0059 Iter 0160 / 0263 | Iter Loss 0.0150 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0059 Iter 0160 / 0263 | Iter Loss 0.0361 | Iter Mean Loss 0.0314\n",
      "CL Training: Epoch 0059 Iter 0160 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0961\n",
      "CF Training: Epoch 0059 Iter 0180 / 0263 | Iter Loss 0.0130 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0059 Iter 0180 / 0263 | Iter Loss 0.0390 | Iter Mean Loss 0.0322\n",
      "CL Training: Epoch 0059 Iter 0180 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0961\n",
      "CF Training: Epoch 0059 Iter 0200 / 0263 | Iter Loss 0.0194 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0059 Iter 0200 / 0263 | Iter Loss 0.0409 | Iter Mean Loss 0.0331\n",
      "CL Training: Epoch 0059 Iter 0200 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0059 Iter 0220 / 0263 | Iter Loss 0.0126 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0059 Iter 0220 / 0263 | Iter Loss 0.0454 | Iter Mean Loss 0.0339\n",
      "CL Training: Epoch 0059 Iter 0220 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0059 Iter 0240 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0059 Iter 0240 / 0263 | Iter Loss 0.0478 | Iter Mean Loss 0.0349\n",
      "CL Training: Epoch 0059 Iter 0240 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0059 Iter 0260 / 0263 | Iter Loss 0.0119 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0059 Iter 0260 / 0263 | Iter Loss 0.0624 | Iter Mean Loss 0.0360\n",
      "CL Training: Epoch 0059 Iter 0260 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0960\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.056757 s\n",
      "Measure time: 0.017432 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 60, Hit Ratio:0.20461  |  Precision:0.12601  |  Recall:0.20552  |  NDCG:0.20735\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0060 Iter 0000 / 0263 | Iter Loss 0.0192 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0060 Iter 0000 / 0263 | Iter Loss 0.0199 | Iter Mean Loss 0.0199\n",
      "CL Training: Epoch 0060 Iter 0000 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0961\n",
      "CF Training: Epoch 0060 Iter 0020 / 0263 | Iter Loss 0.0154 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0060 Iter 0020 / 0263 | Iter Loss 0.0243 | Iter Mean Loss 0.0245\n",
      "CL Training: Epoch 0060 Iter 0020 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0961\n",
      "CF Training: Epoch 0060 Iter 0040 / 0263 | Iter Loss 0.0236 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0060 Iter 0040 / 0263 | Iter Loss 0.0276 | Iter Mean Loss 0.0261\n",
      "CL Training: Epoch 0060 Iter 0040 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0959\n",
      "CF Training: Epoch 0060 Iter 0060 / 0263 | Iter Loss 0.0185 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0060 Iter 0060 / 0263 | Iter Loss 0.0288 | Iter Mean Loss 0.0266\n",
      "CL Training: Epoch 0060 Iter 0060 / 0263 | Iter Loss 0.0964 | Iter Mean Loss 0.0959\n",
      "CF Training: Epoch 0060 Iter 0080 / 0263 | Iter Loss 0.0199 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0060 Iter 0080 / 0263 | Iter Loss 0.0283 | Iter Mean Loss 0.0270\n",
      "CL Training: Epoch 0060 Iter 0080 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0060 Iter 0100 / 0263 | Iter Loss 0.0192 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0060 Iter 0100 / 0263 | Iter Loss 0.0298 | Iter Mean Loss 0.0276\n",
      "CL Training: Epoch 0060 Iter 0100 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0060 Iter 0120 / 0263 | Iter Loss 0.0113 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0060 Iter 0120 / 0263 | Iter Loss 0.0336 | Iter Mean Loss 0.0286\n",
      "CL Training: Epoch 0060 Iter 0120 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0060 Iter 0140 / 0263 | Iter Loss 0.0225 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0060 Iter 0140 / 0263 | Iter Loss 0.0345 | Iter Mean Loss 0.0295\n",
      "CL Training: Epoch 0060 Iter 0140 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0060 Iter 0160 / 0263 | Iter Loss 0.0220 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0060 Iter 0160 / 0263 | Iter Loss 0.0381 | Iter Mean Loss 0.0304\n",
      "CL Training: Epoch 0060 Iter 0160 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0060 Iter 0180 / 0263 | Iter Loss 0.0136 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0060 Iter 0180 / 0263 | Iter Loss 0.0406 | Iter Mean Loss 0.0312\n",
      "CL Training: Epoch 0060 Iter 0180 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0060 Iter 0200 / 0263 | Iter Loss 0.0153 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0060 Iter 0200 / 0263 | Iter Loss 0.0457 | Iter Mean Loss 0.0321\n",
      "CL Training: Epoch 0060 Iter 0200 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0060 Iter 0220 / 0263 | Iter Loss 0.0216 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0060 Iter 0220 / 0263 | Iter Loss 0.0453 | Iter Mean Loss 0.0329\n",
      "CL Training: Epoch 0060 Iter 0220 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0060 Iter 0240 / 0263 | Iter Loss 0.0181 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0060 Iter 0240 / 0263 | Iter Loss 0.0514 | Iter Mean Loss 0.0339\n",
      "CL Training: Epoch 0060 Iter 0240 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0060 Iter 0260 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0060 Iter 0260 / 0263 | Iter Loss 0.0683 | Iter Mean Loss 0.0352\n",
      "CL Training: Epoch 0060 Iter 0260 / 0263 | Iter Loss 0.0959 | Iter Mean Loss 0.0957\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.083076 s\n",
      "Measure time: 0.017882 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 61, Hit Ratio:0.21  |  Precision:0.12933  |  Recall:0.21185  |  NDCG:0.22097\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0061 Iter 0000 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0160\n",
      "KG Training: Epoch 0061 Iter 0000 / 0263 | Iter Loss 0.0201 | Iter Mean Loss 0.0201\n",
      "CL Training: Epoch 0061 Iter 0000 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0061 Iter 0020 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0170\n",
      "KG Training: Epoch 0061 Iter 0020 / 0263 | Iter Loss 0.0266 | Iter Mean Loss 0.0248\n",
      "CL Training: Epoch 0061 Iter 0020 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0959\n",
      "CF Training: Epoch 0061 Iter 0040 / 0263 | Iter Loss 0.0178 | Iter Mean Loss 0.0168\n",
      "KG Training: Epoch 0061 Iter 0040 / 0263 | Iter Loss 0.0254 | Iter Mean Loss 0.0260\n",
      "CL Training: Epoch 0061 Iter 0040 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0061 Iter 0060 / 0263 | Iter Loss 0.0174 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0061 Iter 0060 / 0263 | Iter Loss 0.0279 | Iter Mean Loss 0.0263\n",
      "CL Training: Epoch 0061 Iter 0060 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0061 Iter 0080 / 0263 | Iter Loss 0.0163 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0061 Iter 0080 / 0263 | Iter Loss 0.0267 | Iter Mean Loss 0.0268\n",
      "CL Training: Epoch 0061 Iter 0080 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0061 Iter 0100 / 0263 | Iter Loss 0.0157 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0061 Iter 0100 / 0263 | Iter Loss 0.0308 | Iter Mean Loss 0.0274\n",
      "CL Training: Epoch 0061 Iter 0100 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0061 Iter 0120 / 0263 | Iter Loss 0.0237 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0061 Iter 0120 / 0263 | Iter Loss 0.0317 | Iter Mean Loss 0.0282\n",
      "CL Training: Epoch 0061 Iter 0120 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0061 Iter 0140 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0061 Iter 0140 / 0263 | Iter Loss 0.0361 | Iter Mean Loss 0.0291\n",
      "CL Training: Epoch 0061 Iter 0140 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0061 Iter 0160 / 0263 | Iter Loss 0.0265 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0061 Iter 0160 / 0263 | Iter Loss 0.0401 | Iter Mean Loss 0.0301\n",
      "CL Training: Epoch 0061 Iter 0160 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0061 Iter 0180 / 0263 | Iter Loss 0.0159 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0061 Iter 0180 / 0263 | Iter Loss 0.0353 | Iter Mean Loss 0.0309\n",
      "CL Training: Epoch 0061 Iter 0180 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0061 Iter 0200 / 0263 | Iter Loss 0.0201 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0061 Iter 0200 / 0263 | Iter Loss 0.0434 | Iter Mean Loss 0.0318\n",
      "CL Training: Epoch 0061 Iter 0200 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0061 Iter 0220 / 0263 | Iter Loss 0.0232 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0061 Iter 0220 / 0263 | Iter Loss 0.0440 | Iter Mean Loss 0.0326\n",
      "CL Training: Epoch 0061 Iter 0220 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0061 Iter 0240 / 0263 | Iter Loss 0.0169 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0061 Iter 0240 / 0263 | Iter Loss 0.0428 | Iter Mean Loss 0.0335\n",
      "CL Training: Epoch 0061 Iter 0240 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0061 Iter 0260 / 0263 | Iter Loss 0.0139 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0061 Iter 0260 / 0263 | Iter Loss 0.0601 | Iter Mean Loss 0.0348\n",
      "CL Training: Epoch 0061 Iter 0260 / 0263 | Iter Loss 0.0959 | Iter Mean Loss 0.0957\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.015223 s\n",
      "Measure time: 0.017461 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 62, Hit Ratio:0.19957  |  Precision:0.1229  |  Recall:0.20246  |  NDCG:0.20541\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 47, Hit Ratio:0.21422  |  Precision:0.13193  |  Recall:0.21785  |  NDCG:0.22943\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0062 Iter 0000 / 0263 | Iter Loss 0.0172 | Iter Mean Loss 0.0172\n",
      "KG Training: Epoch 0062 Iter 0000 / 0263 | Iter Loss 0.0186 | Iter Mean Loss 0.0186\n",
      "CL Training: Epoch 0062 Iter 0000 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0062 Iter 0020 / 0263 | Iter Loss 0.0132 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0062 Iter 0020 / 0263 | Iter Loss 0.0255 | Iter Mean Loss 0.0240\n",
      "CL Training: Epoch 0062 Iter 0020 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0062 Iter 0040 / 0263 | Iter Loss 0.0200 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0062 Iter 0040 / 0263 | Iter Loss 0.0314 | Iter Mean Loss 0.0256\n",
      "CL Training: Epoch 0062 Iter 0040 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0062 Iter 0060 / 0263 | Iter Loss 0.0254 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0062 Iter 0060 / 0263 | Iter Loss 0.0233 | Iter Mean Loss 0.0261\n",
      "CL Training: Epoch 0062 Iter 0060 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0062 Iter 0080 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0062 Iter 0080 / 0263 | Iter Loss 0.0272 | Iter Mean Loss 0.0266\n",
      "CL Training: Epoch 0062 Iter 0080 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0062 Iter 0100 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0062 Iter 0100 / 0263 | Iter Loss 0.0321 | Iter Mean Loss 0.0272\n",
      "CL Training: Epoch 0062 Iter 0100 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0062 Iter 0120 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0062 Iter 0120 / 0263 | Iter Loss 0.0323 | Iter Mean Loss 0.0280\n",
      "CL Training: Epoch 0062 Iter 0120 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0062 Iter 0140 / 0263 | Iter Loss 0.0127 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0062 Iter 0140 / 0263 | Iter Loss 0.0337 | Iter Mean Loss 0.0288\n",
      "CL Training: Epoch 0062 Iter 0140 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0062 Iter 0160 / 0263 | Iter Loss 0.0247 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0062 Iter 0160 / 0263 | Iter Loss 0.0312 | Iter Mean Loss 0.0298\n",
      "CL Training: Epoch 0062 Iter 0160 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0062 Iter 0180 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0062 Iter 0180 / 0263 | Iter Loss 0.0421 | Iter Mean Loss 0.0307\n",
      "CL Training: Epoch 0062 Iter 0180 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0062 Iter 0200 / 0263 | Iter Loss 0.0290 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0062 Iter 0200 / 0263 | Iter Loss 0.0363 | Iter Mean Loss 0.0316\n",
      "CL Training: Epoch 0062 Iter 0200 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0062 Iter 0220 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0062 Iter 0220 / 0263 | Iter Loss 0.0433 | Iter Mean Loss 0.0326\n",
      "CL Training: Epoch 0062 Iter 0220 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0062 Iter 0240 / 0263 | Iter Loss 0.0149 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0062 Iter 0240 / 0263 | Iter Loss 0.0452 | Iter Mean Loss 0.0335\n",
      "CL Training: Epoch 0062 Iter 0240 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0062 Iter 0260 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0062 Iter 0260 / 0263 | Iter Loss 0.0585 | Iter Mean Loss 0.0346\n",
      "CL Training: Epoch 0062 Iter 0260 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0956\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.995427 s\n",
      "Measure time: 0.017494 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0063 Iter 0000 / 0263 | Iter Loss 0.0218 | Iter Mean Loss 0.0218\n",
      "KG Training: Epoch 0063 Iter 0000 / 0263 | Iter Loss 0.0195 | Iter Mean Loss 0.0195\n",
      "CL Training: Epoch 0063 Iter 0000 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0063 Iter 0020 / 0263 | Iter Loss 0.0140 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0063 Iter 0020 / 0263 | Iter Loss 0.0274 | Iter Mean Loss 0.0246\n",
      "CL Training: Epoch 0063 Iter 0020 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0959\n",
      "CF Training: Epoch 0063 Iter 0040 / 0263 | Iter Loss 0.0194 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0063 Iter 0040 / 0263 | Iter Loss 0.0257 | Iter Mean Loss 0.0257\n",
      "CL Training: Epoch 0063 Iter 0040 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0063 Iter 0060 / 0263 | Iter Loss 0.0155 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0063 Iter 0060 / 0263 | Iter Loss 0.0298 | Iter Mean Loss 0.0259\n",
      "CL Training: Epoch 0063 Iter 0060 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0063 Iter 0080 / 0263 | Iter Loss 0.0220 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0063 Iter 0080 / 0263 | Iter Loss 0.0276 | Iter Mean Loss 0.0265\n",
      "CL Training: Epoch 0063 Iter 0080 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0063 Iter 0100 / 0263 | Iter Loss 0.0167 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0063 Iter 0100 / 0263 | Iter Loss 0.0321 | Iter Mean Loss 0.0272\n",
      "CL Training: Epoch 0063 Iter 0100 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0063 Iter 0120 / 0263 | Iter Loss 0.0147 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0063 Iter 0120 / 0263 | Iter Loss 0.0341 | Iter Mean Loss 0.0281\n",
      "CL Training: Epoch 0063 Iter 0120 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0063 Iter 0140 / 0263 | Iter Loss 0.0158 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0063 Iter 0140 / 0263 | Iter Loss 0.0354 | Iter Mean Loss 0.0291\n",
      "CL Training: Epoch 0063 Iter 0140 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0063 Iter 0160 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0063 Iter 0160 / 0263 | Iter Loss 0.0358 | Iter Mean Loss 0.0300\n",
      "CL Training: Epoch 0063 Iter 0160 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0063 Iter 0180 / 0263 | Iter Loss 0.0186 | Iter Mean Loss 0.0195\n",
      "KG Training: Epoch 0063 Iter 0180 / 0263 | Iter Loss 0.0369 | Iter Mean Loss 0.0308\n",
      "CL Training: Epoch 0063 Iter 0180 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0063 Iter 0200 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0063 Iter 0200 / 0263 | Iter Loss 0.0387 | Iter Mean Loss 0.0317\n",
      "CL Training: Epoch 0063 Iter 0200 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0063 Iter 0220 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0063 Iter 0220 / 0263 | Iter Loss 0.0396 | Iter Mean Loss 0.0325\n",
      "CL Training: Epoch 0063 Iter 0220 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0063 Iter 0240 / 0263 | Iter Loss 0.0159 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0063 Iter 0240 / 0263 | Iter Loss 0.0409 | Iter Mean Loss 0.0334\n",
      "CL Training: Epoch 0063 Iter 0240 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0063 Iter 0260 / 0263 | Iter Loss 0.0169 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0063 Iter 0260 / 0263 | Iter Loss 0.0506 | Iter Mean Loss 0.0346\n",
      "CL Training: Epoch 0063 Iter 0260 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0957\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.982733 s\n",
      "Measure time: 0.022080 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 64, Hit Ratio:0.20211  |  Precision:0.12447  |  Recall:0.20469  |  NDCG:0.21065\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0064 Iter 0000 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0064 Iter 0000 / 0263 | Iter Loss 0.0197 | Iter Mean Loss 0.0197\n",
      "CL Training: Epoch 0064 Iter 0000 / 0263 | Iter Loss 0.0960 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0064 Iter 0020 / 0263 | Iter Loss 0.0193 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0064 Iter 0020 / 0263 | Iter Loss 0.0243 | Iter Mean Loss 0.0236\n",
      "CL Training: Epoch 0064 Iter 0020 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0064 Iter 0040 / 0263 | Iter Loss 0.0194 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0064 Iter 0040 / 0263 | Iter Loss 0.0252 | Iter Mean Loss 0.0252\n",
      "CL Training: Epoch 0064 Iter 0040 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0064 Iter 0060 / 0263 | Iter Loss 0.0149 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0064 Iter 0060 / 0263 | Iter Loss 0.0269 | Iter Mean Loss 0.0257\n",
      "CL Training: Epoch 0064 Iter 0060 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0064 Iter 0080 / 0263 | Iter Loss 0.0159 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0064 Iter 0080 / 0263 | Iter Loss 0.0329 | Iter Mean Loss 0.0263\n",
      "CL Training: Epoch 0064 Iter 0080 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0064 Iter 0100 / 0263 | Iter Loss 0.0183 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0064 Iter 0100 / 0263 | Iter Loss 0.0316 | Iter Mean Loss 0.0270\n",
      "CL Training: Epoch 0064 Iter 0100 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0064 Iter 0120 / 0263 | Iter Loss 0.0225 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0064 Iter 0120 / 0263 | Iter Loss 0.0345 | Iter Mean Loss 0.0279\n",
      "CL Training: Epoch 0064 Iter 0120 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0064 Iter 0140 / 0263 | Iter Loss 0.0260 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0064 Iter 0140 / 0263 | Iter Loss 0.0351 | Iter Mean Loss 0.0288\n",
      "CL Training: Epoch 0064 Iter 0140 / 0263 | Iter Loss 0.0961 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0064 Iter 0160 / 0263 | Iter Loss 0.0186 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0064 Iter 0160 / 0263 | Iter Loss 0.0366 | Iter Mean Loss 0.0299\n",
      "CL Training: Epoch 0064 Iter 0160 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0064 Iter 0180 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0064 Iter 0180 / 0263 | Iter Loss 0.0364 | Iter Mean Loss 0.0309\n",
      "CL Training: Epoch 0064 Iter 0180 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0064 Iter 0200 / 0263 | Iter Loss 0.0197 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0064 Iter 0200 / 0263 | Iter Loss 0.0410 | Iter Mean Loss 0.0318\n",
      "CL Training: Epoch 0064 Iter 0200 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0064 Iter 0220 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0064 Iter 0220 / 0263 | Iter Loss 0.0421 | Iter Mean Loss 0.0326\n",
      "CL Training: Epoch 0064 Iter 0220 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0064 Iter 0240 / 0263 | Iter Loss 0.0263 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0064 Iter 0240 / 0263 | Iter Loss 0.0417 | Iter Mean Loss 0.0335\n",
      "CL Training: Epoch 0064 Iter 0240 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0064 Iter 0260 / 0263 | Iter Loss 0.0190 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0064 Iter 0260 / 0263 | Iter Loss 0.0488 | Iter Mean Loss 0.0347\n",
      "CL Training: Epoch 0064 Iter 0260 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0957\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.086091 s\n",
      "Measure time: 0.019072 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 65, Hit Ratio:0.20448  |  Precision:0.12593  |  Recall:0.20696  |  NDCG:0.21257\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0065 Iter 0000 / 0263 | Iter Loss 0.0234 | Iter Mean Loss 0.0234\n",
      "KG Training: Epoch 0065 Iter 0000 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0207\n",
      "CL Training: Epoch 0065 Iter 0000 / 0263 | Iter Loss 0.0966 | Iter Mean Loss 0.0966\n",
      "CF Training: Epoch 0065 Iter 0020 / 0263 | Iter Loss 0.0141 | Iter Mean Loss 0.0171\n",
      "KG Training: Epoch 0065 Iter 0020 / 0263 | Iter Loss 0.0247 | Iter Mean Loss 0.0239\n",
      "CL Training: Epoch 0065 Iter 0020 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0065 Iter 0040 / 0263 | Iter Loss 0.0099 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0065 Iter 0040 / 0263 | Iter Loss 0.0263 | Iter Mean Loss 0.0251\n",
      "CL Training: Epoch 0065 Iter 0040 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0065 Iter 0060 / 0263 | Iter Loss 0.0183 | Iter Mean Loss 0.0171\n",
      "KG Training: Epoch 0065 Iter 0060 / 0263 | Iter Loss 0.0260 | Iter Mean Loss 0.0257\n",
      "CL Training: Epoch 0065 Iter 0060 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0065 Iter 0080 / 0263 | Iter Loss 0.0178 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0065 Iter 0080 / 0263 | Iter Loss 0.0284 | Iter Mean Loss 0.0260\n",
      "CL Training: Epoch 0065 Iter 0080 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0065 Iter 0100 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0065 Iter 0100 / 0263 | Iter Loss 0.0302 | Iter Mean Loss 0.0265\n",
      "CL Training: Epoch 0065 Iter 0100 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0065 Iter 0120 / 0263 | Iter Loss 0.0135 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0065 Iter 0120 / 0263 | Iter Loss 0.0308 | Iter Mean Loss 0.0273\n",
      "CL Training: Epoch 0065 Iter 0120 / 0263 | Iter Loss 0.0962 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0065 Iter 0140 / 0263 | Iter Loss 0.0257 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0065 Iter 0140 / 0263 | Iter Loss 0.0356 | Iter Mean Loss 0.0281\n",
      "CL Training: Epoch 0065 Iter 0140 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0065 Iter 0160 / 0263 | Iter Loss 0.0233 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0065 Iter 0160 / 0263 | Iter Loss 0.0381 | Iter Mean Loss 0.0292\n",
      "CL Training: Epoch 0065 Iter 0160 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0065 Iter 0180 / 0263 | Iter Loss 0.0139 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0065 Iter 0180 / 0263 | Iter Loss 0.0357 | Iter Mean Loss 0.0301\n",
      "CL Training: Epoch 0065 Iter 0180 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0065 Iter 0200 / 0263 | Iter Loss 0.0149 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0065 Iter 0200 / 0263 | Iter Loss 0.0429 | Iter Mean Loss 0.0312\n",
      "CL Training: Epoch 0065 Iter 0200 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0065 Iter 0220 / 0263 | Iter Loss 0.0230 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0065 Iter 0220 / 0263 | Iter Loss 0.0427 | Iter Mean Loss 0.0320\n",
      "CL Training: Epoch 0065 Iter 0220 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0065 Iter 0240 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0065 Iter 0240 / 0263 | Iter Loss 0.0404 | Iter Mean Loss 0.0329\n",
      "CL Training: Epoch 0065 Iter 0240 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0065 Iter 0260 / 0263 | Iter Loss 0.0149 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0065 Iter 0260 / 0263 | Iter Loss 0.0551 | Iter Mean Loss 0.0341\n",
      "CL Training: Epoch 0065 Iter 0260 / 0263 | Iter Loss 0.0959 | Iter Mean Loss 0.0956\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.963054 s\n",
      "Measure time: 0.017387 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 66, Hit Ratio:0.20935  |  Precision:0.12893  |  Recall:0.21166  |  NDCG:0.22311\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0066 Iter 0000 / 0263 | Iter Loss 0.0172 | Iter Mean Loss 0.0172\n",
      "KG Training: Epoch 0066 Iter 0000 / 0263 | Iter Loss 0.0206 | Iter Mean Loss 0.0206\n",
      "CL Training: Epoch 0066 Iter 0000 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0066 Iter 0020 / 0263 | Iter Loss 0.0169 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0066 Iter 0020 / 0263 | Iter Loss 0.0255 | Iter Mean Loss 0.0240\n",
      "CL Training: Epoch 0066 Iter 0020 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0066 Iter 0040 / 0263 | Iter Loss 0.0302 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0066 Iter 0040 / 0263 | Iter Loss 0.0266 | Iter Mean Loss 0.0253\n",
      "CL Training: Epoch 0066 Iter 0040 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0066 Iter 0060 / 0263 | Iter Loss 0.0126 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0066 Iter 0060 / 0263 | Iter Loss 0.0278 | Iter Mean Loss 0.0258\n",
      "CL Training: Epoch 0066 Iter 0060 / 0263 | Iter Loss 0.0959 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0066 Iter 0080 / 0263 | Iter Loss 0.0218 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0066 Iter 0080 / 0263 | Iter Loss 0.0268 | Iter Mean Loss 0.0262\n",
      "CL Training: Epoch 0066 Iter 0080 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0066 Iter 0100 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0066 Iter 0100 / 0263 | Iter Loss 0.0299 | Iter Mean Loss 0.0268\n",
      "CL Training: Epoch 0066 Iter 0100 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0066 Iter 0120 / 0263 | Iter Loss 0.0153 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0066 Iter 0120 / 0263 | Iter Loss 0.0333 | Iter Mean Loss 0.0277\n",
      "CL Training: Epoch 0066 Iter 0120 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0066 Iter 0140 / 0263 | Iter Loss 0.0217 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0066 Iter 0140 / 0263 | Iter Loss 0.0388 | Iter Mean Loss 0.0286\n",
      "CL Training: Epoch 0066 Iter 0140 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0066 Iter 0160 / 0263 | Iter Loss 0.0144 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0066 Iter 0160 / 0263 | Iter Loss 0.0378 | Iter Mean Loss 0.0296\n",
      "CL Training: Epoch 0066 Iter 0160 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0066 Iter 0180 / 0263 | Iter Loss 0.0112 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0066 Iter 0180 / 0263 | Iter Loss 0.0391 | Iter Mean Loss 0.0304\n",
      "CL Training: Epoch 0066 Iter 0180 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0066 Iter 0200 / 0263 | Iter Loss 0.0257 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0066 Iter 0200 / 0263 | Iter Loss 0.0385 | Iter Mean Loss 0.0313\n",
      "CL Training: Epoch 0066 Iter 0200 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0066 Iter 0220 / 0263 | Iter Loss 0.0144 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0066 Iter 0220 / 0263 | Iter Loss 0.0404 | Iter Mean Loss 0.0322\n",
      "CL Training: Epoch 0066 Iter 0220 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0066 Iter 0240 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0066 Iter 0240 / 0263 | Iter Loss 0.0478 | Iter Mean Loss 0.0331\n",
      "CL Training: Epoch 0066 Iter 0240 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0066 Iter 0260 / 0263 | Iter Loss 0.0125 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0066 Iter 0260 / 0263 | Iter Loss 0.0578 | Iter Mean Loss 0.0343\n",
      "CL Training: Epoch 0066 Iter 0260 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0954\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.031007 s\n",
      "Measure time: 0.020328 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 67, Hit Ratio:0.20026  |  Precision:0.12333  |  Recall:0.20214  |  NDCG:0.20689\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0067 Iter 0000 / 0263 | Iter Loss 0.0185 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0067 Iter 0000 / 0263 | Iter Loss 0.0200 | Iter Mean Loss 0.0200\n",
      "CL Training: Epoch 0067 Iter 0000 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0067 Iter 0020 / 0263 | Iter Loss 0.0193 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0067 Iter 0020 / 0263 | Iter Loss 0.0242 | Iter Mean Loss 0.0235\n",
      "CL Training: Epoch 0067 Iter 0020 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0067 Iter 0040 / 0263 | Iter Loss 0.0181 | Iter Mean Loss 0.0167\n",
      "KG Training: Epoch 0067 Iter 0040 / 0263 | Iter Loss 0.0266 | Iter Mean Loss 0.0246\n",
      "CL Training: Epoch 0067 Iter 0040 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0067 Iter 0060 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0067 Iter 0060 / 0263 | Iter Loss 0.0280 | Iter Mean Loss 0.0253\n",
      "CL Training: Epoch 0067 Iter 0060 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0067 Iter 0080 / 0263 | Iter Loss 0.0254 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0067 Iter 0080 / 0263 | Iter Loss 0.0256 | Iter Mean Loss 0.0258\n",
      "CL Training: Epoch 0067 Iter 0080 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0067 Iter 0100 / 0263 | Iter Loss 0.0235 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0067 Iter 0100 / 0263 | Iter Loss 0.0283 | Iter Mean Loss 0.0262\n",
      "CL Training: Epoch 0067 Iter 0100 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0067 Iter 0120 / 0263 | Iter Loss 0.0223 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0067 Iter 0120 / 0263 | Iter Loss 0.0349 | Iter Mean Loss 0.0272\n",
      "CL Training: Epoch 0067 Iter 0120 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0067 Iter 0140 / 0263 | Iter Loss 0.0132 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0067 Iter 0140 / 0263 | Iter Loss 0.0341 | Iter Mean Loss 0.0282\n",
      "CL Training: Epoch 0067 Iter 0140 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0067 Iter 0160 / 0263 | Iter Loss 0.0286 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0067 Iter 0160 / 0263 | Iter Loss 0.0370 | Iter Mean Loss 0.0292\n",
      "CL Training: Epoch 0067 Iter 0160 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0067 Iter 0180 / 0263 | Iter Loss 0.0169 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0067 Iter 0180 / 0263 | Iter Loss 0.0400 | Iter Mean Loss 0.0301\n",
      "CL Training: Epoch 0067 Iter 0180 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0067 Iter 0200 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0067 Iter 0200 / 0263 | Iter Loss 0.0390 | Iter Mean Loss 0.0309\n",
      "CL Training: Epoch 0067 Iter 0200 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0067 Iter 0220 / 0263 | Iter Loss 0.0185 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0067 Iter 0220 / 0263 | Iter Loss 0.0418 | Iter Mean Loss 0.0318\n",
      "CL Training: Epoch 0067 Iter 0220 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0067 Iter 0240 / 0263 | Iter Loss 0.0240 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0067 Iter 0240 / 0263 | Iter Loss 0.0469 | Iter Mean Loss 0.0327\n",
      "CL Training: Epoch 0067 Iter 0240 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0067 Iter 0260 / 0263 | Iter Loss 0.0172 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0067 Iter 0260 / 0263 | Iter Loss 0.0601 | Iter Mean Loss 0.0339\n",
      "CL Training: Epoch 0067 Iter 0260 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0952\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.091254 s\n",
      "Measure time: 0.017614 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 68, Hit Ratio:0.21021  |  Precision:0.12946  |  Recall:0.21205  |  NDCG:0.22125\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0068 Iter 0000 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0211\n",
      "KG Training: Epoch 0068 Iter 0000 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0189\n",
      "CL Training: Epoch 0068 Iter 0000 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0068 Iter 0020 / 0263 | Iter Loss 0.0235 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0068 Iter 0020 / 0263 | Iter Loss 0.0259 | Iter Mean Loss 0.0229\n",
      "CL Training: Epoch 0068 Iter 0020 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0068 Iter 0040 / 0263 | Iter Loss 0.0169 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0068 Iter 0040 / 0263 | Iter Loss 0.0274 | Iter Mean Loss 0.0244\n",
      "CL Training: Epoch 0068 Iter 0040 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0068 Iter 0060 / 0263 | Iter Loss 0.0213 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0068 Iter 0060 / 0263 | Iter Loss 0.0280 | Iter Mean Loss 0.0254\n",
      "CL Training: Epoch 0068 Iter 0060 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0068 Iter 0080 / 0263 | Iter Loss 0.0138 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0068 Iter 0080 / 0263 | Iter Loss 0.0298 | Iter Mean Loss 0.0261\n",
      "CL Training: Epoch 0068 Iter 0080 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0068 Iter 0100 / 0263 | Iter Loss 0.0206 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0068 Iter 0100 / 0263 | Iter Loss 0.0301 | Iter Mean Loss 0.0267\n",
      "CL Training: Epoch 0068 Iter 0100 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0068 Iter 0120 / 0263 | Iter Loss 0.0220 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0068 Iter 0120 / 0263 | Iter Loss 0.0369 | Iter Mean Loss 0.0278\n",
      "CL Training: Epoch 0068 Iter 0120 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0068 Iter 0140 / 0263 | Iter Loss 0.0167 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0068 Iter 0140 / 0263 | Iter Loss 0.0372 | Iter Mean Loss 0.0288\n",
      "CL Training: Epoch 0068 Iter 0140 / 0263 | Iter Loss 0.0958 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0068 Iter 0160 / 0263 | Iter Loss 0.0139 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0068 Iter 0160 / 0263 | Iter Loss 0.0370 | Iter Mean Loss 0.0299\n",
      "CL Training: Epoch 0068 Iter 0160 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0068 Iter 0180 / 0263 | Iter Loss 0.0141 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0068 Iter 0180 / 0263 | Iter Loss 0.0418 | Iter Mean Loss 0.0306\n",
      "CL Training: Epoch 0068 Iter 0180 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0068 Iter 0200 / 0263 | Iter Loss 0.0191 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0068 Iter 0200 / 0263 | Iter Loss 0.0405 | Iter Mean Loss 0.0315\n",
      "CL Training: Epoch 0068 Iter 0200 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0068 Iter 0220 / 0263 | Iter Loss 0.0146 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0068 Iter 0220 / 0263 | Iter Loss 0.0346 | Iter Mean Loss 0.0323\n",
      "CL Training: Epoch 0068 Iter 0220 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0068 Iter 0240 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0068 Iter 0240 / 0263 | Iter Loss 0.0430 | Iter Mean Loss 0.0332\n",
      "CL Training: Epoch 0068 Iter 0240 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0068 Iter 0260 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0068 Iter 0260 / 0263 | Iter Loss 0.0520 | Iter Mean Loss 0.0343\n",
      "CL Training: Epoch 0068 Iter 0260 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0952\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.969893 s\n",
      "Measure time: 0.017579 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 69, Hit Ratio:0.19974  |  Precision:0.12301  |  Recall:0.20225  |  NDCG:0.20057\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0069 Iter 0000 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0165\n",
      "KG Training: Epoch 0069 Iter 0000 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0184\n",
      "CL Training: Epoch 0069 Iter 0000 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0069 Iter 0020 / 0263 | Iter Loss 0.0234 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0069 Iter 0020 / 0263 | Iter Loss 0.0247 | Iter Mean Loss 0.0239\n",
      "CL Training: Epoch 0069 Iter 0020 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0069 Iter 0040 / 0263 | Iter Loss 0.0141 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0069 Iter 0040 / 0263 | Iter Loss 0.0282 | Iter Mean Loss 0.0254\n",
      "CL Training: Epoch 0069 Iter 0040 / 0263 | Iter Loss 0.0975 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0069 Iter 0060 / 0263 | Iter Loss 0.0212 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0069 Iter 0060 / 0263 | Iter Loss 0.0264 | Iter Mean Loss 0.0265\n",
      "CL Training: Epoch 0069 Iter 0060 / 0263 | Iter Loss 0.0959 | Iter Mean Loss 0.0960\n",
      "CF Training: Epoch 0069 Iter 0080 / 0263 | Iter Loss 0.0151 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0069 Iter 0080 / 0263 | Iter Loss 0.0306 | Iter Mean Loss 0.0272\n",
      "CL Training: Epoch 0069 Iter 0080 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0959\n",
      "CF Training: Epoch 0069 Iter 0100 / 0263 | Iter Loss 0.0140 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0069 Iter 0100 / 0263 | Iter Loss 0.0326 | Iter Mean Loss 0.0278\n",
      "CL Training: Epoch 0069 Iter 0100 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0958\n",
      "CF Training: Epoch 0069 Iter 0120 / 0263 | Iter Loss 0.0147 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0069 Iter 0120 / 0263 | Iter Loss 0.0334 | Iter Mean Loss 0.0288\n",
      "CL Training: Epoch 0069 Iter 0120 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0069 Iter 0140 / 0263 | Iter Loss 0.0268 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0069 Iter 0140 / 0263 | Iter Loss 0.0302 | Iter Mean Loss 0.0299\n",
      "CL Training: Epoch 0069 Iter 0140 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0069 Iter 0160 / 0263 | Iter Loss 0.0197 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0069 Iter 0160 / 0263 | Iter Loss 0.0350 | Iter Mean Loss 0.0309\n",
      "CL Training: Epoch 0069 Iter 0160 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0069 Iter 0180 / 0263 | Iter Loss 0.0214 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0069 Iter 0180 / 0263 | Iter Loss 0.0364 | Iter Mean Loss 0.0318\n",
      "CL Training: Epoch 0069 Iter 0180 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0069 Iter 0200 / 0263 | Iter Loss 0.0172 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0069 Iter 0200 / 0263 | Iter Loss 0.0395 | Iter Mean Loss 0.0326\n",
      "CL Training: Epoch 0069 Iter 0200 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0069 Iter 0220 / 0263 | Iter Loss 0.0174 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0069 Iter 0220 / 0263 | Iter Loss 0.0395 | Iter Mean Loss 0.0335\n",
      "CL Training: Epoch 0069 Iter 0220 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0069 Iter 0240 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0069 Iter 0240 / 0263 | Iter Loss 0.0412 | Iter Mean Loss 0.0342\n",
      "CL Training: Epoch 0069 Iter 0240 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0069 Iter 0260 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0069 Iter 0260 / 0263 | Iter Loss 0.0524 | Iter Mean Loss 0.0352\n",
      "CL Training: Epoch 0069 Iter 0260 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0954\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.003685 s\n",
      "Measure time: 0.017699 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 70, Hit Ratio:0.20233  |  Precision:0.1246  |  Recall:0.20555  |  NDCG:0.2055\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0070 Iter 0000 / 0263 | Iter Loss 0.0193 | Iter Mean Loss 0.0193\n",
      "KG Training: Epoch 0070 Iter 0000 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0187\n",
      "CL Training: Epoch 0070 Iter 0000 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0957\n",
      "CF Training: Epoch 0070 Iter 0020 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0070 Iter 0020 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0233\n",
      "CL Training: Epoch 0070 Iter 0020 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0070 Iter 0040 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0070 Iter 0040 / 0263 | Iter Loss 0.0260 | Iter Mean Loss 0.0246\n",
      "CL Training: Epoch 0070 Iter 0040 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0070 Iter 0060 / 0263 | Iter Loss 0.0325 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0070 Iter 0060 / 0263 | Iter Loss 0.0260 | Iter Mean Loss 0.0253\n",
      "CL Training: Epoch 0070 Iter 0060 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0070 Iter 0080 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0070 Iter 0080 / 0263 | Iter Loss 0.0264 | Iter Mean Loss 0.0259\n",
      "CL Training: Epoch 0070 Iter 0080 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0070 Iter 0100 / 0263 | Iter Loss 0.0148 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0070 Iter 0100 / 0263 | Iter Loss 0.0287 | Iter Mean Loss 0.0264\n",
      "CL Training: Epoch 0070 Iter 0100 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0070 Iter 0120 / 0263 | Iter Loss 0.0155 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0070 Iter 0120 / 0263 | Iter Loss 0.0295 | Iter Mean Loss 0.0271\n",
      "CL Training: Epoch 0070 Iter 0120 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0070 Iter 0140 / 0263 | Iter Loss 0.0219 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0070 Iter 0140 / 0263 | Iter Loss 0.0344 | Iter Mean Loss 0.0281\n",
      "CL Training: Epoch 0070 Iter 0140 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0070 Iter 0160 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0070 Iter 0160 / 0263 | Iter Loss 0.0320 | Iter Mean Loss 0.0291\n",
      "CL Training: Epoch 0070 Iter 0160 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0070 Iter 0180 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0070 Iter 0180 / 0263 | Iter Loss 0.0451 | Iter Mean Loss 0.0300\n",
      "CL Training: Epoch 0070 Iter 0180 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0070 Iter 0200 / 0263 | Iter Loss 0.0192 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0070 Iter 0200 / 0263 | Iter Loss 0.0449 | Iter Mean Loss 0.0309\n",
      "CL Training: Epoch 0070 Iter 0200 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0070 Iter 0220 / 0263 | Iter Loss 0.0127 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0070 Iter 0220 / 0263 | Iter Loss 0.0412 | Iter Mean Loss 0.0318\n",
      "CL Training: Epoch 0070 Iter 0220 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0070 Iter 0240 / 0263 | Iter Loss 0.0126 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0070 Iter 0240 / 0263 | Iter Loss 0.0437 | Iter Mean Loss 0.0327\n",
      "CL Training: Epoch 0070 Iter 0240 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0070 Iter 0260 / 0263 | Iter Loss 0.0224 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0070 Iter 0260 / 0263 | Iter Loss 0.0542 | Iter Mean Loss 0.0338\n",
      "CL Training: Epoch 0070 Iter 0260 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0952\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.069438 s\n",
      "Measure time: 0.017562 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 71, Hit Ratio:0.19823  |  Precision:0.12208  |  Recall:0.2014  |  NDCG:0.20401\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0071 Iter 0000 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0208\n",
      "KG Training: Epoch 0071 Iter 0000 / 0263 | Iter Loss 0.0183 | Iter Mean Loss 0.0183\n",
      "CL Training: Epoch 0071 Iter 0000 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0071 Iter 0020 / 0263 | Iter Loss 0.0266 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0071 Iter 0020 / 0263 | Iter Loss 0.0249 | Iter Mean Loss 0.0235\n",
      "CL Training: Epoch 0071 Iter 0020 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0071 Iter 0040 / 0263 | Iter Loss 0.0182 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0071 Iter 0040 / 0263 | Iter Loss 0.0252 | Iter Mean Loss 0.0246\n",
      "CL Training: Epoch 0071 Iter 0040 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0071 Iter 0060 / 0263 | Iter Loss 0.0163 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0071 Iter 0060 / 0263 | Iter Loss 0.0284 | Iter Mean Loss 0.0252\n",
      "CL Training: Epoch 0071 Iter 0060 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0071 Iter 0080 / 0263 | Iter Loss 0.0149 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0071 Iter 0080 / 0263 | Iter Loss 0.0280 | Iter Mean Loss 0.0259\n",
      "CL Training: Epoch 0071 Iter 0080 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0071 Iter 0100 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0071 Iter 0100 / 0263 | Iter Loss 0.0298 | Iter Mean Loss 0.0264\n",
      "CL Training: Epoch 0071 Iter 0100 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0071 Iter 0120 / 0263 | Iter Loss 0.0172 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0071 Iter 0120 / 0263 | Iter Loss 0.0287 | Iter Mean Loss 0.0274\n",
      "CL Training: Epoch 0071 Iter 0120 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0071 Iter 0140 / 0263 | Iter Loss 0.0158 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0071 Iter 0140 / 0263 | Iter Loss 0.0389 | Iter Mean Loss 0.0284\n",
      "CL Training: Epoch 0071 Iter 0140 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0071 Iter 0160 / 0263 | Iter Loss 0.0159 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0071 Iter 0160 / 0263 | Iter Loss 0.0384 | Iter Mean Loss 0.0293\n",
      "CL Training: Epoch 0071 Iter 0160 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0071 Iter 0180 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0071 Iter 0180 / 0263 | Iter Loss 0.0381 | Iter Mean Loss 0.0303\n",
      "CL Training: Epoch 0071 Iter 0180 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0071 Iter 0200 / 0263 | Iter Loss 0.0245 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0071 Iter 0200 / 0263 | Iter Loss 0.0466 | Iter Mean Loss 0.0311\n",
      "CL Training: Epoch 0071 Iter 0200 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0071 Iter 0220 / 0263 | Iter Loss 0.0240 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0071 Iter 0220 / 0263 | Iter Loss 0.0384 | Iter Mean Loss 0.0319\n",
      "CL Training: Epoch 0071 Iter 0220 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0071 Iter 0240 / 0263 | Iter Loss 0.0237 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0071 Iter 0240 / 0263 | Iter Loss 0.0427 | Iter Mean Loss 0.0328\n",
      "CL Training: Epoch 0071 Iter 0240 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0071 Iter 0260 / 0263 | Iter Loss 0.0168 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0071 Iter 0260 / 0263 | Iter Loss 0.0509 | Iter Mean Loss 0.0339\n",
      "CL Training: Epoch 0071 Iter 0260 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0951\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.977497 s\n",
      "Measure time: 0.018070 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 72, Hit Ratio:0.20565  |  Precision:0.12665  |  Recall:0.2072  |  NDCG:0.21291\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0072 Iter 0000 / 0263 | Iter Loss 0.0180 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0072 Iter 0000 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0184\n",
      "CL Training: Epoch 0072 Iter 0000 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0072 Iter 0020 / 0263 | Iter Loss 0.0145 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0072 Iter 0020 / 0263 | Iter Loss 0.0250 | Iter Mean Loss 0.0231\n",
      "CL Training: Epoch 0072 Iter 0020 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0072 Iter 0040 / 0263 | Iter Loss 0.0157 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0072 Iter 0040 / 0263 | Iter Loss 0.0263 | Iter Mean Loss 0.0247\n",
      "CL Training: Epoch 0072 Iter 0040 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0072 Iter 0060 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0072 Iter 0060 / 0263 | Iter Loss 0.0269 | Iter Mean Loss 0.0256\n",
      "CL Training: Epoch 0072 Iter 0060 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0072 Iter 0080 / 0263 | Iter Loss 0.0223 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0072 Iter 0080 / 0263 | Iter Loss 0.0262 | Iter Mean Loss 0.0262\n",
      "CL Training: Epoch 0072 Iter 0080 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0072 Iter 0100 / 0263 | Iter Loss 0.0210 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0072 Iter 0100 / 0263 | Iter Loss 0.0317 | Iter Mean Loss 0.0269\n",
      "CL Training: Epoch 0072 Iter 0100 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0072 Iter 0120 / 0263 | Iter Loss 0.0183 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0072 Iter 0120 / 0263 | Iter Loss 0.0360 | Iter Mean Loss 0.0279\n",
      "CL Training: Epoch 0072 Iter 0120 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0072 Iter 0140 / 0263 | Iter Loss 0.0221 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0072 Iter 0140 / 0263 | Iter Loss 0.0336 | Iter Mean Loss 0.0289\n",
      "CL Training: Epoch 0072 Iter 0140 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0072 Iter 0160 / 0263 | Iter Loss 0.0230 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0072 Iter 0160 / 0263 | Iter Loss 0.0343 | Iter Mean Loss 0.0298\n",
      "CL Training: Epoch 0072 Iter 0160 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0072 Iter 0180 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0072 Iter 0180 / 0263 | Iter Loss 0.0426 | Iter Mean Loss 0.0307\n",
      "CL Training: Epoch 0072 Iter 0180 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0072 Iter 0200 / 0263 | Iter Loss 0.0199 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0072 Iter 0200 / 0263 | Iter Loss 0.0383 | Iter Mean Loss 0.0315\n",
      "CL Training: Epoch 0072 Iter 0200 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0072 Iter 0220 / 0263 | Iter Loss 0.0167 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0072 Iter 0220 / 0263 | Iter Loss 0.0458 | Iter Mean Loss 0.0323\n",
      "CL Training: Epoch 0072 Iter 0220 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0072 Iter 0240 / 0263 | Iter Loss 0.0143 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0072 Iter 0240 / 0263 | Iter Loss 0.0417 | Iter Mean Loss 0.0332\n",
      "CL Training: Epoch 0072 Iter 0240 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0072 Iter 0260 / 0263 | Iter Loss 0.0183 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0072 Iter 0260 / 0263 | Iter Loss 0.0539 | Iter Mean Loss 0.0343\n",
      "CL Training: Epoch 0072 Iter 0260 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0953\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.992485 s\n",
      "Measure time: 0.017854 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 73, Hit Ratio:0.20491  |  Precision:0.12619  |  Recall:0.20719  |  NDCG:0.21032\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0073 Iter 0000 / 0263 | Iter Loss 0.0168 | Iter Mean Loss 0.0168\n",
      "KG Training: Epoch 0073 Iter 0000 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0208\n",
      "CL Training: Epoch 0073 Iter 0000 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0073 Iter 0020 / 0263 | Iter Loss 0.0181 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0073 Iter 0020 / 0263 | Iter Loss 0.0252 | Iter Mean Loss 0.0235\n",
      "CL Training: Epoch 0073 Iter 0020 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0073 Iter 0040 / 0263 | Iter Loss 0.0154 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0073 Iter 0040 / 0263 | Iter Loss 0.0284 | Iter Mean Loss 0.0249\n",
      "CL Training: Epoch 0073 Iter 0040 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0073 Iter 0060 / 0263 | Iter Loss 0.0241 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0073 Iter 0060 / 0263 | Iter Loss 0.0279 | Iter Mean Loss 0.0255\n",
      "CL Training: Epoch 0073 Iter 0060 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0073 Iter 0080 / 0263 | Iter Loss 0.0182 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0073 Iter 0080 / 0263 | Iter Loss 0.0260 | Iter Mean Loss 0.0259\n",
      "CL Training: Epoch 0073 Iter 0080 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0073 Iter 0100 / 0263 | Iter Loss 0.0217 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0073 Iter 0100 / 0263 | Iter Loss 0.0295 | Iter Mean Loss 0.0264\n",
      "CL Training: Epoch 0073 Iter 0100 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0073 Iter 0120 / 0263 | Iter Loss 0.0220 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0073 Iter 0120 / 0263 | Iter Loss 0.0346 | Iter Mean Loss 0.0273\n",
      "CL Training: Epoch 0073 Iter 0120 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0073 Iter 0140 / 0263 | Iter Loss 0.0158 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0073 Iter 0140 / 0263 | Iter Loss 0.0343 | Iter Mean Loss 0.0281\n",
      "CL Training: Epoch 0073 Iter 0140 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0073 Iter 0160 / 0263 | Iter Loss 0.0190 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0073 Iter 0160 / 0263 | Iter Loss 0.0348 | Iter Mean Loss 0.0290\n",
      "CL Training: Epoch 0073 Iter 0160 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0073 Iter 0180 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0073 Iter 0180 / 0263 | Iter Loss 0.0380 | Iter Mean Loss 0.0298\n",
      "CL Training: Epoch 0073 Iter 0180 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0073 Iter 0200 / 0263 | Iter Loss 0.0172 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0073 Iter 0200 / 0263 | Iter Loss 0.0360 | Iter Mean Loss 0.0306\n",
      "CL Training: Epoch 0073 Iter 0200 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0073 Iter 0220 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0073 Iter 0220 / 0263 | Iter Loss 0.0362 | Iter Mean Loss 0.0315\n",
      "CL Training: Epoch 0073 Iter 0220 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0073 Iter 0240 / 0263 | Iter Loss 0.0098 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0073 Iter 0240 / 0263 | Iter Loss 0.0389 | Iter Mean Loss 0.0324\n",
      "CL Training: Epoch 0073 Iter 0240 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0073 Iter 0260 / 0263 | Iter Loss 0.0170 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0073 Iter 0260 / 0263 | Iter Loss 0.0568 | Iter Mean Loss 0.0335\n",
      "CL Training: Epoch 0073 Iter 0260 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.241170 s\n",
      "Measure time: 0.018089 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 74, Hit Ratio:0.21129  |  Precision:0.13012  |  Recall:0.21286  |  NDCG:0.21862\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0074 Iter 0000 / 0263 | Iter Loss 0.0168 | Iter Mean Loss 0.0168\n",
      "KG Training: Epoch 0074 Iter 0000 / 0263 | Iter Loss 0.0186 | Iter Mean Loss 0.0186\n",
      "CL Training: Epoch 0074 Iter 0000 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0074 Iter 0020 / 0263 | Iter Loss 0.0245 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0074 Iter 0020 / 0263 | Iter Loss 0.0238 | Iter Mean Loss 0.0228\n",
      "CL Training: Epoch 0074 Iter 0020 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0074 Iter 0040 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0074 Iter 0040 / 0263 | Iter Loss 0.0251 | Iter Mean Loss 0.0240\n",
      "CL Training: Epoch 0074 Iter 0040 / 0263 | Iter Loss 0.0942 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0074 Iter 0060 / 0263 | Iter Loss 0.0162 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0074 Iter 0060 / 0263 | Iter Loss 0.0254 | Iter Mean Loss 0.0248\n",
      "CL Training: Epoch 0074 Iter 0060 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0074 Iter 0080 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0074 Iter 0080 / 0263 | Iter Loss 0.0276 | Iter Mean Loss 0.0253\n",
      "CL Training: Epoch 0074 Iter 0080 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0074 Iter 0100 / 0263 | Iter Loss 0.0149 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0074 Iter 0100 / 0263 | Iter Loss 0.0334 | Iter Mean Loss 0.0259\n",
      "CL Training: Epoch 0074 Iter 0100 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0074 Iter 0120 / 0263 | Iter Loss 0.0173 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0074 Iter 0120 / 0263 | Iter Loss 0.0314 | Iter Mean Loss 0.0267\n",
      "CL Training: Epoch 0074 Iter 0120 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0074 Iter 0140 / 0263 | Iter Loss 0.0220 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0074 Iter 0140 / 0263 | Iter Loss 0.0384 | Iter Mean Loss 0.0278\n",
      "CL Training: Epoch 0074 Iter 0140 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0074 Iter 0160 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0074 Iter 0160 / 0263 | Iter Loss 0.0406 | Iter Mean Loss 0.0288\n",
      "CL Training: Epoch 0074 Iter 0160 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0074 Iter 0180 / 0263 | Iter Loss 0.0121 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0074 Iter 0180 / 0263 | Iter Loss 0.0377 | Iter Mean Loss 0.0297\n",
      "CL Training: Epoch 0074 Iter 0180 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0074 Iter 0200 / 0263 | Iter Loss 0.0107 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0074 Iter 0200 / 0263 | Iter Loss 0.0405 | Iter Mean Loss 0.0305\n",
      "CL Training: Epoch 0074 Iter 0200 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0074 Iter 0220 / 0263 | Iter Loss 0.0131 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0074 Iter 0220 / 0263 | Iter Loss 0.0433 | Iter Mean Loss 0.0314\n",
      "CL Training: Epoch 0074 Iter 0220 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0074 Iter 0240 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0074 Iter 0240 / 0263 | Iter Loss 0.0460 | Iter Mean Loss 0.0323\n",
      "CL Training: Epoch 0074 Iter 0240 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0074 Iter 0260 / 0263 | Iter Loss 0.0159 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0074 Iter 0260 / 0263 | Iter Loss 0.0540 | Iter Mean Loss 0.0335\n",
      "CL Training: Epoch 0074 Iter 0260 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0949\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.949270 s\n",
      "Measure time: 0.017569 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 75, Hit Ratio:0.20728  |  Precision:0.12765  |  Recall:0.20971  |  NDCG:0.21693\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0075 Iter 0000 / 0263 | Iter Loss 0.0119 | Iter Mean Loss 0.0119\n",
      "KG Training: Epoch 0075 Iter 0000 / 0263 | Iter Loss 0.0196 | Iter Mean Loss 0.0196\n",
      "CL Training: Epoch 0075 Iter 0000 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0075 Iter 0020 / 0263 | Iter Loss 0.0220 | Iter Mean Loss 0.0169\n",
      "KG Training: Epoch 0075 Iter 0020 / 0263 | Iter Loss 0.0230 | Iter Mean Loss 0.0234\n",
      "CL Training: Epoch 0075 Iter 0020 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0075 Iter 0040 / 0263 | Iter Loss 0.0202 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0075 Iter 0040 / 0263 | Iter Loss 0.0274 | Iter Mean Loss 0.0247\n",
      "CL Training: Epoch 0075 Iter 0040 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0075 Iter 0060 / 0263 | Iter Loss 0.0183 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0075 Iter 0060 / 0263 | Iter Loss 0.0245 | Iter Mean Loss 0.0250\n",
      "CL Training: Epoch 0075 Iter 0060 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0075 Iter 0080 / 0263 | Iter Loss 0.0186 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0075 Iter 0080 / 0263 | Iter Loss 0.0260 | Iter Mean Loss 0.0254\n",
      "CL Training: Epoch 0075 Iter 0080 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0075 Iter 0100 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0075 Iter 0100 / 0263 | Iter Loss 0.0291 | Iter Mean Loss 0.0259\n",
      "CL Training: Epoch 0075 Iter 0100 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0075 Iter 0120 / 0263 | Iter Loss 0.0182 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0075 Iter 0120 / 0263 | Iter Loss 0.0331 | Iter Mean Loss 0.0267\n",
      "CL Training: Epoch 0075 Iter 0120 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0075 Iter 0140 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0075 Iter 0140 / 0263 | Iter Loss 0.0335 | Iter Mean Loss 0.0276\n",
      "CL Training: Epoch 0075 Iter 0140 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0075 Iter 0160 / 0263 | Iter Loss 0.0172 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0075 Iter 0160 / 0263 | Iter Loss 0.0356 | Iter Mean Loss 0.0287\n",
      "CL Training: Epoch 0075 Iter 0160 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0075 Iter 0180 / 0263 | Iter Loss 0.0120 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0075 Iter 0180 / 0263 | Iter Loss 0.0368 | Iter Mean Loss 0.0296\n",
      "CL Training: Epoch 0075 Iter 0180 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0075 Iter 0200 / 0263 | Iter Loss 0.0265 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0075 Iter 0200 / 0263 | Iter Loss 0.0374 | Iter Mean Loss 0.0303\n",
      "CL Training: Epoch 0075 Iter 0200 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0075 Iter 0220 / 0263 | Iter Loss 0.0159 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0075 Iter 0220 / 0263 | Iter Loss 0.0458 | Iter Mean Loss 0.0313\n",
      "CL Training: Epoch 0075 Iter 0220 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0075 Iter 0240 / 0263 | Iter Loss 0.0153 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0075 Iter 0240 / 0263 | Iter Loss 0.0473 | Iter Mean Loss 0.0321\n",
      "CL Training: Epoch 0075 Iter 0240 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0075 Iter 0260 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0075 Iter 0260 / 0263 | Iter Loss 0.0528 | Iter Mean Loss 0.0333\n",
      "CL Training: Epoch 0075 Iter 0260 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0950\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.082666 s\n",
      "Measure time: 0.017596 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 76, Hit Ratio:0.20349  |  Precision:0.12532  |  Recall:0.20589  |  NDCG:0.21112\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0076 Iter 0000 / 0263 | Iter Loss 0.0239 | Iter Mean Loss 0.0239\n",
      "KG Training: Epoch 0076 Iter 0000 / 0263 | Iter Loss 0.0173 | Iter Mean Loss 0.0173\n",
      "CL Training: Epoch 0076 Iter 0000 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0076 Iter 0020 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0076 Iter 0020 / 0263 | Iter Loss 0.0241 | Iter Mean Loss 0.0231\n",
      "CL Training: Epoch 0076 Iter 0020 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0076 Iter 0040 / 0263 | Iter Loss 0.0173 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0076 Iter 0040 / 0263 | Iter Loss 0.0255 | Iter Mean Loss 0.0242\n",
      "CL Training: Epoch 0076 Iter 0040 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0076 Iter 0060 / 0263 | Iter Loss 0.0214 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0076 Iter 0060 / 0263 | Iter Loss 0.0241 | Iter Mean Loss 0.0245\n",
      "CL Training: Epoch 0076 Iter 0060 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0076 Iter 0080 / 0263 | Iter Loss 0.0240 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0076 Iter 0080 / 0263 | Iter Loss 0.0271 | Iter Mean Loss 0.0250\n",
      "CL Training: Epoch 0076 Iter 0080 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0076 Iter 0100 / 0263 | Iter Loss 0.0167 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0076 Iter 0100 / 0263 | Iter Loss 0.0305 | Iter Mean Loss 0.0256\n",
      "CL Training: Epoch 0076 Iter 0100 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0076 Iter 0120 / 0263 | Iter Loss 0.0131 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0076 Iter 0120 / 0263 | Iter Loss 0.0336 | Iter Mean Loss 0.0266\n",
      "CL Training: Epoch 0076 Iter 0120 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0076 Iter 0140 / 0263 | Iter Loss 0.0126 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0076 Iter 0140 / 0263 | Iter Loss 0.0348 | Iter Mean Loss 0.0275\n",
      "CL Training: Epoch 0076 Iter 0140 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0076 Iter 0160 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0076 Iter 0160 / 0263 | Iter Loss 0.0366 | Iter Mean Loss 0.0284\n",
      "CL Training: Epoch 0076 Iter 0160 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0076 Iter 0180 / 0263 | Iter Loss 0.0186 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0076 Iter 0180 / 0263 | Iter Loss 0.0405 | Iter Mean Loss 0.0293\n",
      "CL Training: Epoch 0076 Iter 0180 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0076 Iter 0200 / 0263 | Iter Loss 0.0186 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0076 Iter 0200 / 0263 | Iter Loss 0.0437 | Iter Mean Loss 0.0302\n",
      "CL Training: Epoch 0076 Iter 0200 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0076 Iter 0220 / 0263 | Iter Loss 0.0229 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0076 Iter 0220 / 0263 | Iter Loss 0.0440 | Iter Mean Loss 0.0311\n",
      "CL Training: Epoch 0076 Iter 0220 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0076 Iter 0240 / 0263 | Iter Loss 0.0153 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0076 Iter 0240 / 0263 | Iter Loss 0.0440 | Iter Mean Loss 0.0320\n",
      "CL Training: Epoch 0076 Iter 0240 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0076 Iter 0260 / 0263 | Iter Loss 0.0245 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0076 Iter 0260 / 0263 | Iter Loss 0.0611 | Iter Mean Loss 0.0331\n",
      "CL Training: Epoch 0076 Iter 0260 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.888205 s\n",
      "Measure time: 0.017593 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 77, Hit Ratio:0.19435  |  Precision:0.11969  |  Recall:0.1963  |  NDCG:0.2009\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0077 Iter 0000 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0077 Iter 0000 / 0263 | Iter Loss 0.0181 | Iter Mean Loss 0.0181\n",
      "CL Training: Epoch 0077 Iter 0000 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0077 Iter 0020 / 0263 | Iter Loss 0.0173 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0077 Iter 0020 / 0263 | Iter Loss 0.0240 | Iter Mean Loss 0.0232\n",
      "CL Training: Epoch 0077 Iter 0020 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0077 Iter 0040 / 0263 | Iter Loss 0.0142 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0077 Iter 0040 / 0263 | Iter Loss 0.0256 | Iter Mean Loss 0.0244\n",
      "CL Training: Epoch 0077 Iter 0040 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0077 Iter 0060 / 0263 | Iter Loss 0.0110 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0077 Iter 0060 / 0263 | Iter Loss 0.0263 | Iter Mean Loss 0.0250\n",
      "CL Training: Epoch 0077 Iter 0060 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0077 Iter 0080 / 0263 | Iter Loss 0.0227 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0077 Iter 0080 / 0263 | Iter Loss 0.0268 | Iter Mean Loss 0.0254\n",
      "CL Training: Epoch 0077 Iter 0080 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0077 Iter 0100 / 0263 | Iter Loss 0.0128 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0077 Iter 0100 / 0263 | Iter Loss 0.0247 | Iter Mean Loss 0.0259\n",
      "CL Training: Epoch 0077 Iter 0100 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0077 Iter 0120 / 0263 | Iter Loss 0.0180 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0077 Iter 0120 / 0263 | Iter Loss 0.0312 | Iter Mean Loss 0.0266\n",
      "CL Training: Epoch 0077 Iter 0120 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0077 Iter 0140 / 0263 | Iter Loss 0.0168 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0077 Iter 0140 / 0263 | Iter Loss 0.0299 | Iter Mean Loss 0.0275\n",
      "CL Training: Epoch 0077 Iter 0140 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0077 Iter 0160 / 0263 | Iter Loss 0.0183 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0077 Iter 0160 / 0263 | Iter Loss 0.0340 | Iter Mean Loss 0.0286\n",
      "CL Training: Epoch 0077 Iter 0160 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0077 Iter 0180 / 0263 | Iter Loss 0.0122 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0077 Iter 0180 / 0263 | Iter Loss 0.0363 | Iter Mean Loss 0.0294\n",
      "CL Training: Epoch 0077 Iter 0180 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0077 Iter 0200 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0077 Iter 0200 / 0263 | Iter Loss 0.0376 | Iter Mean Loss 0.0303\n",
      "CL Training: Epoch 0077 Iter 0200 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0077 Iter 0220 / 0263 | Iter Loss 0.0133 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0077 Iter 0220 / 0263 | Iter Loss 0.0400 | Iter Mean Loss 0.0313\n",
      "CL Training: Epoch 0077 Iter 0220 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0077 Iter 0240 / 0263 | Iter Loss 0.0170 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0077 Iter 0240 / 0263 | Iter Loss 0.0450 | Iter Mean Loss 0.0321\n",
      "CL Training: Epoch 0077 Iter 0240 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0077 Iter 0260 / 0263 | Iter Loss 0.0213 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0077 Iter 0260 / 0263 | Iter Loss 0.0549 | Iter Mean Loss 0.0333\n",
      "CL Training: Epoch 0077 Iter 0260 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0951\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.991875 s\n",
      "Measure time: 0.019001 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 78, Hit Ratio:0.2122  |  Precision:0.13068  |  Recall:0.21417  |  NDCG:0.22141\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0078 Iter 0000 / 0263 | Iter Loss 0.0162 | Iter Mean Loss 0.0162\n",
      "KG Training: Epoch 0078 Iter 0000 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0179\n",
      "CL Training: Epoch 0078 Iter 0000 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0078 Iter 0020 / 0263 | Iter Loss 0.0144 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0078 Iter 0020 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0229\n",
      "CL Training: Epoch 0078 Iter 0020 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0078 Iter 0040 / 0263 | Iter Loss 0.0153 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0078 Iter 0040 / 0263 | Iter Loss 0.0270 | Iter Mean Loss 0.0238\n",
      "CL Training: Epoch 0078 Iter 0040 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0078 Iter 0060 / 0263 | Iter Loss 0.0171 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0078 Iter 0060 / 0263 | Iter Loss 0.0256 | Iter Mean Loss 0.0243\n",
      "CL Training: Epoch 0078 Iter 0060 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0078 Iter 0080 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0078 Iter 0080 / 0263 | Iter Loss 0.0248 | Iter Mean Loss 0.0247\n",
      "CL Training: Epoch 0078 Iter 0080 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0078 Iter 0100 / 0263 | Iter Loss 0.0152 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0078 Iter 0100 / 0263 | Iter Loss 0.0347 | Iter Mean Loss 0.0253\n",
      "CL Training: Epoch 0078 Iter 0100 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0078 Iter 0120 / 0263 | Iter Loss 0.0146 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0078 Iter 0120 / 0263 | Iter Loss 0.0299 | Iter Mean Loss 0.0261\n",
      "CL Training: Epoch 0078 Iter 0120 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0078 Iter 0140 / 0263 | Iter Loss 0.0170 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0078 Iter 0140 / 0263 | Iter Loss 0.0323 | Iter Mean Loss 0.0270\n",
      "CL Training: Epoch 0078 Iter 0140 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0078 Iter 0160 / 0263 | Iter Loss 0.0141 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0078 Iter 0160 / 0263 | Iter Loss 0.0397 | Iter Mean Loss 0.0282\n",
      "CL Training: Epoch 0078 Iter 0160 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0078 Iter 0180 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0078 Iter 0180 / 0263 | Iter Loss 0.0345 | Iter Mean Loss 0.0290\n",
      "CL Training: Epoch 0078 Iter 0180 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0078 Iter 0200 / 0263 | Iter Loss 0.0196 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0078 Iter 0200 / 0263 | Iter Loss 0.0370 | Iter Mean Loss 0.0299\n",
      "CL Training: Epoch 0078 Iter 0200 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0078 Iter 0220 / 0263 | Iter Loss 0.0152 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0078 Iter 0220 / 0263 | Iter Loss 0.0411 | Iter Mean Loss 0.0307\n",
      "CL Training: Epoch 0078 Iter 0220 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0078 Iter 0240 / 0263 | Iter Loss 0.0161 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0078 Iter 0240 / 0263 | Iter Loss 0.0404 | Iter Mean Loss 0.0317\n",
      "CL Training: Epoch 0078 Iter 0240 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0078 Iter 0260 / 0263 | Iter Loss 0.0150 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0078 Iter 0260 / 0263 | Iter Loss 0.0548 | Iter Mean Loss 0.0328\n",
      "CL Training: Epoch 0078 Iter 0260 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.925219 s\n",
      "Measure time: 0.017687 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 79, Hit Ratio:0.19457  |  Precision:0.11982  |  Recall:0.197  |  NDCG:0.19821\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0079 Iter 0000 / 0263 | Iter Loss 0.0134 | Iter Mean Loss 0.0134\n",
      "KG Training: Epoch 0079 Iter 0000 / 0263 | Iter Loss 0.0188 | Iter Mean Loss 0.0188\n",
      "CL Training: Epoch 0079 Iter 0000 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0079 Iter 0020 / 0263 | Iter Loss 0.0120 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0079 Iter 0020 / 0263 | Iter Loss 0.0251 | Iter Mean Loss 0.0227\n",
      "CL Training: Epoch 0079 Iter 0020 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0079 Iter 0040 / 0263 | Iter Loss 0.0161 | Iter Mean Loss 0.0167\n",
      "KG Training: Epoch 0079 Iter 0040 / 0263 | Iter Loss 0.0232 | Iter Mean Loss 0.0236\n",
      "CL Training: Epoch 0079 Iter 0040 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0079 Iter 0060 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0079 Iter 0060 / 0263 | Iter Loss 0.0276 | Iter Mean Loss 0.0244\n",
      "CL Training: Epoch 0079 Iter 0060 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0079 Iter 0080 / 0263 | Iter Loss 0.0106 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0079 Iter 0080 / 0263 | Iter Loss 0.0256 | Iter Mean Loss 0.0248\n",
      "CL Training: Epoch 0079 Iter 0080 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0079 Iter 0100 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0079 Iter 0100 / 0263 | Iter Loss 0.0265 | Iter Mean Loss 0.0251\n",
      "CL Training: Epoch 0079 Iter 0100 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0079 Iter 0120 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0079 Iter 0120 / 0263 | Iter Loss 0.0339 | Iter Mean Loss 0.0261\n",
      "CL Training: Epoch 0079 Iter 0120 / 0263 | Iter Loss 0.0963 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0079 Iter 0140 / 0263 | Iter Loss 0.0161 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0079 Iter 0140 / 0263 | Iter Loss 0.0372 | Iter Mean Loss 0.0272\n",
      "CL Training: Epoch 0079 Iter 0140 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0079 Iter 0160 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0079 Iter 0160 / 0263 | Iter Loss 0.0382 | Iter Mean Loss 0.0283\n",
      "CL Training: Epoch 0079 Iter 0160 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0079 Iter 0180 / 0263 | Iter Loss 0.0167 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0079 Iter 0180 / 0263 | Iter Loss 0.0397 | Iter Mean Loss 0.0292\n",
      "CL Training: Epoch 0079 Iter 0180 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0079 Iter 0200 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0079 Iter 0200 / 0263 | Iter Loss 0.0498 | Iter Mean Loss 0.0304\n",
      "CL Training: Epoch 0079 Iter 0200 / 0263 | Iter Loss 0.0957 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0079 Iter 0220 / 0263 | Iter Loss 0.0167 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0079 Iter 0220 / 0263 | Iter Loss 0.0443 | Iter Mean Loss 0.0313\n",
      "CL Training: Epoch 0079 Iter 0220 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0079 Iter 0240 / 0263 | Iter Loss 0.0202 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0079 Iter 0240 / 0263 | Iter Loss 0.0456 | Iter Mean Loss 0.0323\n",
      "CL Training: Epoch 0079 Iter 0240 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0079 Iter 0260 / 0263 | Iter Loss 0.0148 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0079 Iter 0260 / 0263 | Iter Loss 0.0534 | Iter Mean Loss 0.0335\n",
      "CL Training: Epoch 0079 Iter 0260 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0952\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.679756 s\n",
      "Measure time: 0.017201 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 80, Hit Ratio:0.20797  |  Precision:0.12808  |  Recall:0.21036  |  NDCG:0.21744\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0080 Iter 0000 / 0263 | Iter Loss 0.0199 | Iter Mean Loss 0.0199\n",
      "KG Training: Epoch 0080 Iter 0000 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0177\n",
      "CL Training: Epoch 0080 Iter 0000 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0955\n",
      "CF Training: Epoch 0080 Iter 0020 / 0263 | Iter Loss 0.0152 | Iter Mean Loss 0.0166\n",
      "KG Training: Epoch 0080 Iter 0020 / 0263 | Iter Loss 0.0243 | Iter Mean Loss 0.0228\n",
      "CL Training: Epoch 0080 Iter 0020 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0080 Iter 0040 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0169\n",
      "KG Training: Epoch 0080 Iter 0040 / 0263 | Iter Loss 0.0271 | Iter Mean Loss 0.0239\n",
      "CL Training: Epoch 0080 Iter 0040 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0080 Iter 0060 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0170\n",
      "KG Training: Epoch 0080 Iter 0060 / 0263 | Iter Loss 0.0253 | Iter Mean Loss 0.0246\n",
      "CL Training: Epoch 0080 Iter 0060 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0080 Iter 0080 / 0263 | Iter Loss 0.0232 | Iter Mean Loss 0.0170\n",
      "KG Training: Epoch 0080 Iter 0080 / 0263 | Iter Loss 0.0274 | Iter Mean Loss 0.0252\n",
      "CL Training: Epoch 0080 Iter 0080 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0080 Iter 0100 / 0263 | Iter Loss 0.0146 | Iter Mean Loss 0.0170\n",
      "KG Training: Epoch 0080 Iter 0100 / 0263 | Iter Loss 0.0313 | Iter Mean Loss 0.0258\n",
      "CL Training: Epoch 0080 Iter 0100 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0080 Iter 0120 / 0263 | Iter Loss 0.0171 | Iter Mean Loss 0.0168\n",
      "KG Training: Epoch 0080 Iter 0120 / 0263 | Iter Loss 0.0309 | Iter Mean Loss 0.0267\n",
      "CL Training: Epoch 0080 Iter 0120 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0080 Iter 0140 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0168\n",
      "KG Training: Epoch 0080 Iter 0140 / 0263 | Iter Loss 0.0418 | Iter Mean Loss 0.0277\n",
      "CL Training: Epoch 0080 Iter 0140 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0080 Iter 0160 / 0263 | Iter Loss 0.0237 | Iter Mean Loss 0.0171\n",
      "KG Training: Epoch 0080 Iter 0160 / 0263 | Iter Loss 0.0328 | Iter Mean Loss 0.0288\n",
      "CL Training: Epoch 0080 Iter 0160 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0080 Iter 0180 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0171\n",
      "KG Training: Epoch 0080 Iter 0180 / 0263 | Iter Loss 0.0355 | Iter Mean Loss 0.0298\n",
      "CL Training: Epoch 0080 Iter 0180 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0080 Iter 0200 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0171\n",
      "KG Training: Epoch 0080 Iter 0200 / 0263 | Iter Loss 0.0454 | Iter Mean Loss 0.0306\n",
      "CL Training: Epoch 0080 Iter 0200 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0080 Iter 0220 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0171\n",
      "KG Training: Epoch 0080 Iter 0220 / 0263 | Iter Loss 0.0391 | Iter Mean Loss 0.0314\n",
      "CL Training: Epoch 0080 Iter 0220 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0080 Iter 0240 / 0263 | Iter Loss 0.0248 | Iter Mean Loss 0.0172\n",
      "KG Training: Epoch 0080 Iter 0240 / 0263 | Iter Loss 0.0435 | Iter Mean Loss 0.0324\n",
      "CL Training: Epoch 0080 Iter 0240 / 0263 | Iter Loss 0.0965 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0080 Iter 0260 / 0263 | Iter Loss 0.0221 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0080 Iter 0260 / 0263 | Iter Loss 0.0543 | Iter Mean Loss 0.0338\n",
      "CL Training: Epoch 0080 Iter 0260 / 0263 | Iter Loss 0.0959 | Iter Mean Loss 0.0952\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.967357 s\n",
      "Measure time: 0.019583 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 81, Hit Ratio:0.19405  |  Precision:0.11951  |  Recall:0.19621  |  NDCG:0.1991\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0081 Iter 0000 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0205\n",
      "KG Training: Epoch 0081 Iter 0000 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0211\n",
      "CL Training: Epoch 0081 Iter 0000 / 0263 | Iter Loss 0.0956 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0081 Iter 0020 / 0263 | Iter Loss 0.0202 | Iter Mean Loss 0.0171\n",
      "KG Training: Epoch 0081 Iter 0020 / 0263 | Iter Loss 0.0238 | Iter Mean Loss 0.0235\n",
      "CL Training: Epoch 0081 Iter 0020 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0956\n",
      "CF Training: Epoch 0081 Iter 0040 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0081 Iter 0040 / 0263 | Iter Loss 0.0236 | Iter Mean Loss 0.0249\n",
      "CL Training: Epoch 0081 Iter 0040 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0081 Iter 0060 / 0263 | Iter Loss 0.0153 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0081 Iter 0060 / 0263 | Iter Loss 0.0287 | Iter Mean Loss 0.0254\n",
      "CL Training: Epoch 0081 Iter 0060 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0081 Iter 0080 / 0263 | Iter Loss 0.0150 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0081 Iter 0080 / 0263 | Iter Loss 0.0297 | Iter Mean Loss 0.0256\n",
      "CL Training: Epoch 0081 Iter 0080 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0081 Iter 0100 / 0263 | Iter Loss 0.0192 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0081 Iter 0100 / 0263 | Iter Loss 0.0283 | Iter Mean Loss 0.0262\n",
      "CL Training: Epoch 0081 Iter 0100 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0081 Iter 0120 / 0263 | Iter Loss 0.0138 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0081 Iter 0120 / 0263 | Iter Loss 0.0342 | Iter Mean Loss 0.0271\n",
      "CL Training: Epoch 0081 Iter 0120 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0081 Iter 0140 / 0263 | Iter Loss 0.0094 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0081 Iter 0140 / 0263 | Iter Loss 0.0324 | Iter Mean Loss 0.0281\n",
      "CL Training: Epoch 0081 Iter 0140 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0081 Iter 0160 / 0263 | Iter Loss 0.0249 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0081 Iter 0160 / 0263 | Iter Loss 0.0372 | Iter Mean Loss 0.0292\n",
      "CL Training: Epoch 0081 Iter 0160 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0081 Iter 0180 / 0263 | Iter Loss 0.0243 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0081 Iter 0180 / 0263 | Iter Loss 0.0384 | Iter Mean Loss 0.0301\n",
      "CL Training: Epoch 0081 Iter 0180 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0081 Iter 0200 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0081 Iter 0200 / 0263 | Iter Loss 0.0382 | Iter Mean Loss 0.0309\n",
      "CL Training: Epoch 0081 Iter 0200 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0081 Iter 0220 / 0263 | Iter Loss 0.0148 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0081 Iter 0220 / 0263 | Iter Loss 0.0362 | Iter Mean Loss 0.0316\n",
      "CL Training: Epoch 0081 Iter 0220 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0081 Iter 0240 / 0263 | Iter Loss 0.0163 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0081 Iter 0240 / 0263 | Iter Loss 0.0433 | Iter Mean Loss 0.0325\n",
      "CL Training: Epoch 0081 Iter 0240 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0081 Iter 0260 / 0263 | Iter Loss 0.0097 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0081 Iter 0260 / 0263 | Iter Loss 0.0521 | Iter Mean Loss 0.0336\n",
      "CL Training: Epoch 0081 Iter 0260 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0950\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.858732 s\n",
      "Measure time: 0.017429 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 82, Hit Ratio:0.2075  |  Precision:0.12779  |  Recall:0.2096  |  NDCG:0.21561\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0082 Iter 0000 / 0263 | Iter Loss 0.0120 | Iter Mean Loss 0.0120\n",
      "KG Training: Epoch 0082 Iter 0000 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0177\n",
      "CL Training: Epoch 0082 Iter 0000 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0082 Iter 0020 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0164\n",
      "KG Training: Epoch 0082 Iter 0020 / 0263 | Iter Loss 0.0233 | Iter Mean Loss 0.0227\n",
      "CL Training: Epoch 0082 Iter 0020 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0082 Iter 0040 / 0263 | Iter Loss 0.0100 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0082 Iter 0040 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0239\n",
      "CL Training: Epoch 0082 Iter 0040 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0082 Iter 0060 / 0263 | Iter Loss 0.0285 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0082 Iter 0060 / 0263 | Iter Loss 0.0239 | Iter Mean Loss 0.0244\n",
      "CL Training: Epoch 0082 Iter 0060 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0082 Iter 0080 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0082 Iter 0080 / 0263 | Iter Loss 0.0252 | Iter Mean Loss 0.0249\n",
      "CL Training: Epoch 0082 Iter 0080 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0082 Iter 0100 / 0263 | Iter Loss 0.0139 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0082 Iter 0100 / 0263 | Iter Loss 0.0314 | Iter Mean Loss 0.0254\n",
      "CL Training: Epoch 0082 Iter 0100 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0082 Iter 0120 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0082 Iter 0120 / 0263 | Iter Loss 0.0311 | Iter Mean Loss 0.0261\n",
      "CL Training: Epoch 0082 Iter 0120 / 0263 | Iter Loss 0.0943 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0082 Iter 0140 / 0263 | Iter Loss 0.0145 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0082 Iter 0140 / 0263 | Iter Loss 0.0351 | Iter Mean Loss 0.0272\n",
      "CL Training: Epoch 0082 Iter 0140 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0082 Iter 0160 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0082 Iter 0160 / 0263 | Iter Loss 0.0347 | Iter Mean Loss 0.0281\n",
      "CL Training: Epoch 0082 Iter 0160 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0082 Iter 0180 / 0263 | Iter Loss 0.0200 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0082 Iter 0180 / 0263 | Iter Loss 0.0359 | Iter Mean Loss 0.0290\n",
      "CL Training: Epoch 0082 Iter 0180 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0082 Iter 0200 / 0263 | Iter Loss 0.0240 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0082 Iter 0200 / 0263 | Iter Loss 0.0368 | Iter Mean Loss 0.0299\n",
      "CL Training: Epoch 0082 Iter 0200 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0082 Iter 0220 / 0263 | Iter Loss 0.0206 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0082 Iter 0220 / 0263 | Iter Loss 0.0421 | Iter Mean Loss 0.0308\n",
      "CL Training: Epoch 0082 Iter 0220 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0082 Iter 0240 / 0263 | Iter Loss 0.0137 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0082 Iter 0240 / 0263 | Iter Loss 0.0420 | Iter Mean Loss 0.0316\n",
      "CL Training: Epoch 0082 Iter 0240 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0082 Iter 0260 / 0263 | Iter Loss 0.0204 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0082 Iter 0260 / 0263 | Iter Loss 0.0573 | Iter Mean Loss 0.0328\n",
      "CL Training: Epoch 0082 Iter 0260 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0947\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.971888 s\n",
      "Measure time: 0.017680 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 83, Hit Ratio:0.20509  |  Precision:0.1263  |  Recall:0.20677  |  NDCG:0.21268\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0083 Iter 0000 / 0263 | Iter Loss 0.0130 | Iter Mean Loss 0.0130\n",
      "KG Training: Epoch 0083 Iter 0000 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0184\n",
      "CL Training: Epoch 0083 Iter 0000 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0083 Iter 0020 / 0263 | Iter Loss 0.0174 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0083 Iter 0020 / 0263 | Iter Loss 0.0224 | Iter Mean Loss 0.0221\n",
      "CL Training: Epoch 0083 Iter 0020 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0083 Iter 0040 / 0263 | Iter Loss 0.0174 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0083 Iter 0040 / 0263 | Iter Loss 0.0233 | Iter Mean Loss 0.0231\n",
      "CL Training: Epoch 0083 Iter 0040 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0083 Iter 0060 / 0263 | Iter Loss 0.0149 | Iter Mean Loss 0.0173\n",
      "KG Training: Epoch 0083 Iter 0060 / 0263 | Iter Loss 0.0256 | Iter Mean Loss 0.0237\n",
      "CL Training: Epoch 0083 Iter 0060 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0083 Iter 0080 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0170\n",
      "KG Training: Epoch 0083 Iter 0080 / 0263 | Iter Loss 0.0261 | Iter Mean Loss 0.0241\n",
      "CL Training: Epoch 0083 Iter 0080 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0083 Iter 0100 / 0263 | Iter Loss 0.0183 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0083 Iter 0100 / 0263 | Iter Loss 0.0275 | Iter Mean Loss 0.0248\n",
      "CL Training: Epoch 0083 Iter 0100 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0083 Iter 0120 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0083 Iter 0120 / 0263 | Iter Loss 0.0331 | Iter Mean Loss 0.0258\n",
      "CL Training: Epoch 0083 Iter 0120 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0083 Iter 0140 / 0263 | Iter Loss 0.0206 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0083 Iter 0140 / 0263 | Iter Loss 0.0293 | Iter Mean Loss 0.0268\n",
      "CL Training: Epoch 0083 Iter 0140 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0083 Iter 0160 / 0263 | Iter Loss 0.0174 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0083 Iter 0160 / 0263 | Iter Loss 0.0349 | Iter Mean Loss 0.0278\n",
      "CL Training: Epoch 0083 Iter 0160 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0083 Iter 0180 / 0263 | Iter Loss 0.0144 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0083 Iter 0180 / 0263 | Iter Loss 0.0352 | Iter Mean Loss 0.0286\n",
      "CL Training: Epoch 0083 Iter 0180 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0083 Iter 0200 / 0263 | Iter Loss 0.0142 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0083 Iter 0200 / 0263 | Iter Loss 0.0359 | Iter Mean Loss 0.0294\n",
      "CL Training: Epoch 0083 Iter 0200 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0083 Iter 0220 / 0263 | Iter Loss 0.0268 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0083 Iter 0220 / 0263 | Iter Loss 0.0343 | Iter Mean Loss 0.0303\n",
      "CL Training: Epoch 0083 Iter 0220 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0083 Iter 0240 / 0263 | Iter Loss 0.0148 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0083 Iter 0240 / 0263 | Iter Loss 0.0392 | Iter Mean Loss 0.0312\n",
      "CL Training: Epoch 0083 Iter 0240 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0083 Iter 0260 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0083 Iter 0260 / 0263 | Iter Loss 0.0578 | Iter Mean Loss 0.0323\n",
      "CL Training: Epoch 0083 Iter 0260 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0949\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.035479 s\n",
      "Measure time: 0.017423 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 84, Hit Ratio:0.20543  |  Precision:0.12651  |  Recall:0.20744  |  NDCG:0.21473\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0084 Iter 0000 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0198\n",
      "KG Training: Epoch 0084 Iter 0000 / 0263 | Iter Loss 0.0172 | Iter Mean Loss 0.0172\n",
      "CL Training: Epoch 0084 Iter 0000 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0084 Iter 0020 / 0263 | Iter Loss 0.0152 | Iter Mean Loss 0.0170\n",
      "KG Training: Epoch 0084 Iter 0020 / 0263 | Iter Loss 0.0256 | Iter Mean Loss 0.0222\n",
      "CL Training: Epoch 0084 Iter 0020 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0084 Iter 0040 / 0263 | Iter Loss 0.0185 | Iter Mean Loss 0.0172\n",
      "KG Training: Epoch 0084 Iter 0040 / 0263 | Iter Loss 0.0238 | Iter Mean Loss 0.0234\n",
      "CL Training: Epoch 0084 Iter 0040 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0084 Iter 0060 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0084 Iter 0060 / 0263 | Iter Loss 0.0289 | Iter Mean Loss 0.0240\n",
      "CL Training: Epoch 0084 Iter 0060 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0084 Iter 0080 / 0263 | Iter Loss 0.0255 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0084 Iter 0080 / 0263 | Iter Loss 0.0243 | Iter Mean Loss 0.0243\n",
      "CL Training: Epoch 0084 Iter 0080 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0084 Iter 0100 / 0263 | Iter Loss 0.0161 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0084 Iter 0100 / 0263 | Iter Loss 0.0305 | Iter Mean Loss 0.0249\n",
      "CL Training: Epoch 0084 Iter 0100 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0084 Iter 0120 / 0263 | Iter Loss 0.0180 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0084 Iter 0120 / 0263 | Iter Loss 0.0278 | Iter Mean Loss 0.0258\n",
      "CL Training: Epoch 0084 Iter 0120 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0084 Iter 0140 / 0263 | Iter Loss 0.0155 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0084 Iter 0140 / 0263 | Iter Loss 0.0322 | Iter Mean Loss 0.0267\n",
      "CL Training: Epoch 0084 Iter 0140 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0084 Iter 0160 / 0263 | Iter Loss 0.0263 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0084 Iter 0160 / 0263 | Iter Loss 0.0349 | Iter Mean Loss 0.0276\n",
      "CL Training: Epoch 0084 Iter 0160 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0084 Iter 0180 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0084 Iter 0180 / 0263 | Iter Loss 0.0394 | Iter Mean Loss 0.0286\n",
      "CL Training: Epoch 0084 Iter 0180 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0084 Iter 0200 / 0263 | Iter Loss 0.0182 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0084 Iter 0200 / 0263 | Iter Loss 0.0349 | Iter Mean Loss 0.0293\n",
      "CL Training: Epoch 0084 Iter 0200 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0084 Iter 0220 / 0263 | Iter Loss 0.0267 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0084 Iter 0220 / 0263 | Iter Loss 0.0443 | Iter Mean Loss 0.0301\n",
      "CL Training: Epoch 0084 Iter 0220 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0084 Iter 0240 / 0263 | Iter Loss 0.0194 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0084 Iter 0240 / 0263 | Iter Loss 0.0394 | Iter Mean Loss 0.0310\n",
      "CL Training: Epoch 0084 Iter 0240 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0084 Iter 0260 / 0263 | Iter Loss 0.0155 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0084 Iter 0260 / 0263 | Iter Loss 0.0537 | Iter Mean Loss 0.0321\n",
      "CL Training: Epoch 0084 Iter 0260 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0949\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.036150 s\n",
      "Measure time: 0.017522 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 85, Hit Ratio:0.21116  |  Precision:0.13004  |  Recall:0.21436  |  NDCG:0.21996\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0085 Iter 0000 / 0263 | Iter Loss 0.0235 | Iter Mean Loss 0.0235\n",
      "KG Training: Epoch 0085 Iter 0000 / 0263 | Iter Loss 0.0178 | Iter Mean Loss 0.0178\n",
      "CL Training: Epoch 0085 Iter 0000 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0085 Iter 0020 / 0263 | Iter Loss 0.0140 | Iter Mean Loss 0.0171\n",
      "KG Training: Epoch 0085 Iter 0020 / 0263 | Iter Loss 0.0238 | Iter Mean Loss 0.0219\n",
      "CL Training: Epoch 0085 Iter 0020 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0085 Iter 0040 / 0263 | Iter Loss 0.0230 | Iter Mean Loss 0.0169\n",
      "KG Training: Epoch 0085 Iter 0040 / 0263 | Iter Loss 0.0257 | Iter Mean Loss 0.0234\n",
      "CL Training: Epoch 0085 Iter 0040 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0085 Iter 0060 / 0263 | Iter Loss 0.0237 | Iter Mean Loss 0.0173\n",
      "KG Training: Epoch 0085 Iter 0060 / 0263 | Iter Loss 0.0240 | Iter Mean Loss 0.0238\n",
      "CL Training: Epoch 0085 Iter 0060 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0085 Iter 0080 / 0263 | Iter Loss 0.0191 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0085 Iter 0080 / 0263 | Iter Loss 0.0255 | Iter Mean Loss 0.0242\n",
      "CL Training: Epoch 0085 Iter 0080 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0085 Iter 0100 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0085 Iter 0100 / 0263 | Iter Loss 0.0311 | Iter Mean Loss 0.0248\n",
      "CL Training: Epoch 0085 Iter 0100 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0085 Iter 0120 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0085 Iter 0120 / 0263 | Iter Loss 0.0326 | Iter Mean Loss 0.0258\n",
      "CL Training: Epoch 0085 Iter 0120 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0085 Iter 0140 / 0263 | Iter Loss 0.0166 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0085 Iter 0140 / 0263 | Iter Loss 0.0341 | Iter Mean Loss 0.0268\n",
      "CL Training: Epoch 0085 Iter 0140 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0085 Iter 0160 / 0263 | Iter Loss 0.0193 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0085 Iter 0160 / 0263 | Iter Loss 0.0323 | Iter Mean Loss 0.0278\n",
      "CL Training: Epoch 0085 Iter 0160 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0085 Iter 0180 / 0263 | Iter Loss 0.0153 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0085 Iter 0180 / 0263 | Iter Loss 0.0375 | Iter Mean Loss 0.0287\n",
      "CL Training: Epoch 0085 Iter 0180 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0085 Iter 0200 / 0263 | Iter Loss 0.0147 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0085 Iter 0200 / 0263 | Iter Loss 0.0394 | Iter Mean Loss 0.0295\n",
      "CL Training: Epoch 0085 Iter 0200 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0085 Iter 0220 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0085 Iter 0220 / 0263 | Iter Loss 0.0396 | Iter Mean Loss 0.0303\n",
      "CL Training: Epoch 0085 Iter 0220 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0085 Iter 0240 / 0263 | Iter Loss 0.0147 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0085 Iter 0240 / 0263 | Iter Loss 0.0443 | Iter Mean Loss 0.0314\n",
      "CL Training: Epoch 0085 Iter 0240 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0085 Iter 0260 / 0263 | Iter Loss 0.0128 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0085 Iter 0260 / 0263 | Iter Loss 0.0610 | Iter Mean Loss 0.0327\n",
      "CL Training: Epoch 0085 Iter 0260 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0948\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.916592 s\n",
      "Measure time: 0.023090 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 86, Hit Ratio:0.20164  |  Precision:0.12418  |  Recall:0.20279  |  NDCG:0.20657\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0086 Iter 0000 / 0263 | Iter Loss 0.0209 | Iter Mean Loss 0.0209\n",
      "KG Training: Epoch 0086 Iter 0000 / 0263 | Iter Loss 0.0197 | Iter Mean Loss 0.0197\n",
      "CL Training: Epoch 0086 Iter 0000 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0086 Iter 0020 / 0263 | Iter Loss 0.0144 | Iter Mean Loss 0.0192\n",
      "KG Training: Epoch 0086 Iter 0020 / 0263 | Iter Loss 0.0258 | Iter Mean Loss 0.0229\n",
      "CL Training: Epoch 0086 Iter 0020 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0086 Iter 0040 / 0263 | Iter Loss 0.0161 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0086 Iter 0040 / 0263 | Iter Loss 0.0262 | Iter Mean Loss 0.0240\n",
      "CL Training: Epoch 0086 Iter 0040 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0954\n",
      "CF Training: Epoch 0086 Iter 0060 / 0263 | Iter Loss 0.0219 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0086 Iter 0060 / 0263 | Iter Loss 0.0274 | Iter Mean Loss 0.0247\n",
      "CL Training: Epoch 0086 Iter 0060 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0086 Iter 0080 / 0263 | Iter Loss 0.0168 | Iter Mean Loss 0.0196\n",
      "KG Training: Epoch 0086 Iter 0080 / 0263 | Iter Loss 0.0260 | Iter Mean Loss 0.0252\n",
      "CL Training: Epoch 0086 Iter 0080 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0086 Iter 0100 / 0263 | Iter Loss 0.0136 | Iter Mean Loss 0.0195\n",
      "KG Training: Epoch 0086 Iter 0100 / 0263 | Iter Loss 0.0326 | Iter Mean Loss 0.0256\n",
      "CL Training: Epoch 0086 Iter 0100 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0086 Iter 0120 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0194\n",
      "KG Training: Epoch 0086 Iter 0120 / 0263 | Iter Loss 0.0337 | Iter Mean Loss 0.0267\n",
      "CL Training: Epoch 0086 Iter 0120 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0086 Iter 0140 / 0263 | Iter Loss 0.0124 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0086 Iter 0140 / 0263 | Iter Loss 0.0344 | Iter Mean Loss 0.0278\n",
      "CL Training: Epoch 0086 Iter 0140 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0086 Iter 0160 / 0263 | Iter Loss 0.0150 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0086 Iter 0160 / 0263 | Iter Loss 0.0366 | Iter Mean Loss 0.0287\n",
      "CL Training: Epoch 0086 Iter 0160 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0086 Iter 0180 / 0263 | Iter Loss 0.0122 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0086 Iter 0180 / 0263 | Iter Loss 0.0340 | Iter Mean Loss 0.0294\n",
      "CL Training: Epoch 0086 Iter 0180 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0086 Iter 0200 / 0263 | Iter Loss 0.0159 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0086 Iter 0200 / 0263 | Iter Loss 0.0376 | Iter Mean Loss 0.0302\n",
      "CL Training: Epoch 0086 Iter 0200 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0086 Iter 0220 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0086 Iter 0220 / 0263 | Iter Loss 0.0447 | Iter Mean Loss 0.0311\n",
      "CL Training: Epoch 0086 Iter 0220 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0086 Iter 0240 / 0263 | Iter Loss 0.0226 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0086 Iter 0240 / 0263 | Iter Loss 0.0405 | Iter Mean Loss 0.0320\n",
      "CL Training: Epoch 0086 Iter 0240 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0086 Iter 0260 / 0263 | Iter Loss 0.0195 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0086 Iter 0260 / 0263 | Iter Loss 0.0607 | Iter Mean Loss 0.0331\n",
      "CL Training: Epoch 0086 Iter 0260 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0951\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.933264 s\n",
      "Measure time: 0.020804 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 87, Hit Ratio:0.20664  |  Precision:0.12726  |  Recall:0.20898  |  NDCG:0.21543\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0087 Iter 0000 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0215\n",
      "KG Training: Epoch 0087 Iter 0000 / 0263 | Iter Loss 0.0180 | Iter Mean Loss 0.0180\n",
      "CL Training: Epoch 0087 Iter 0000 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0087 Iter 0020 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0087 Iter 0020 / 0263 | Iter Loss 0.0270 | Iter Mean Loss 0.0229\n",
      "CL Training: Epoch 0087 Iter 0020 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0087 Iter 0040 / 0263 | Iter Loss 0.0185 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0087 Iter 0040 / 0263 | Iter Loss 0.0268 | Iter Mean Loss 0.0240\n",
      "CL Training: Epoch 0087 Iter 0040 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0087 Iter 0060 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0087 Iter 0060 / 0263 | Iter Loss 0.0269 | Iter Mean Loss 0.0243\n",
      "CL Training: Epoch 0087 Iter 0060 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0087 Iter 0080 / 0263 | Iter Loss 0.0195 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0087 Iter 0080 / 0263 | Iter Loss 0.0257 | Iter Mean Loss 0.0247\n",
      "CL Training: Epoch 0087 Iter 0080 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0087 Iter 0100 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0087 Iter 0100 / 0263 | Iter Loss 0.0308 | Iter Mean Loss 0.0253\n",
      "CL Training: Epoch 0087 Iter 0100 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0087 Iter 0120 / 0263 | Iter Loss 0.0224 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0087 Iter 0120 / 0263 | Iter Loss 0.0281 | Iter Mean Loss 0.0261\n",
      "CL Training: Epoch 0087 Iter 0120 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0087 Iter 0140 / 0263 | Iter Loss 0.0213 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0087 Iter 0140 / 0263 | Iter Loss 0.0339 | Iter Mean Loss 0.0272\n",
      "CL Training: Epoch 0087 Iter 0140 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0087 Iter 0160 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0087 Iter 0160 / 0263 | Iter Loss 0.0393 | Iter Mean Loss 0.0284\n",
      "CL Training: Epoch 0087 Iter 0160 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0087 Iter 0180 / 0263 | Iter Loss 0.0161 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0087 Iter 0180 / 0263 | Iter Loss 0.0375 | Iter Mean Loss 0.0294\n",
      "CL Training: Epoch 0087 Iter 0180 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0087 Iter 0200 / 0263 | Iter Loss 0.0142 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0087 Iter 0200 / 0263 | Iter Loss 0.0383 | Iter Mean Loss 0.0302\n",
      "CL Training: Epoch 0087 Iter 0200 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0087 Iter 0220 / 0263 | Iter Loss 0.0116 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0087 Iter 0220 / 0263 | Iter Loss 0.0380 | Iter Mean Loss 0.0311\n",
      "CL Training: Epoch 0087 Iter 0220 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0087 Iter 0240 / 0263 | Iter Loss 0.0162 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0087 Iter 0240 / 0263 | Iter Loss 0.0460 | Iter Mean Loss 0.0320\n",
      "CL Training: Epoch 0087 Iter 0240 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0087 Iter 0260 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0087 Iter 0260 / 0263 | Iter Loss 0.0512 | Iter Mean Loss 0.0331\n",
      "CL Training: Epoch 0087 Iter 0260 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0950\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.033140 s\n",
      "Measure time: 0.019603 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 88, Hit Ratio:0.1991  |  Precision:0.12261  |  Recall:0.20199  |  NDCG:0.20527\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0088 Iter 0000 / 0263 | Iter Loss 0.0139 | Iter Mean Loss 0.0139\n",
      "KG Training: Epoch 0088 Iter 0000 / 0263 | Iter Loss 0.0186 | Iter Mean Loss 0.0186\n",
      "CL Training: Epoch 0088 Iter 0000 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0088 Iter 0020 / 0263 | Iter Loss 0.0125 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0088 Iter 0020 / 0263 | Iter Loss 0.0244 | Iter Mean Loss 0.0229\n",
      "CL Training: Epoch 0088 Iter 0020 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0088 Iter 0040 / 0263 | Iter Loss 0.0219 | Iter Mean Loss 0.0173\n",
      "KG Training: Epoch 0088 Iter 0040 / 0263 | Iter Loss 0.0234 | Iter Mean Loss 0.0240\n",
      "CL Training: Epoch 0088 Iter 0040 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0088 Iter 0060 / 0263 | Iter Loss 0.0139 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0088 Iter 0060 / 0263 | Iter Loss 0.0278 | Iter Mean Loss 0.0249\n",
      "CL Training: Epoch 0088 Iter 0060 / 0263 | Iter Loss 0.0954 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0088 Iter 0080 / 0263 | Iter Loss 0.0144 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0088 Iter 0080 / 0263 | Iter Loss 0.0250 | Iter Mean Loss 0.0251\n",
      "CL Training: Epoch 0088 Iter 0080 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0088 Iter 0100 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0088 Iter 0100 / 0263 | Iter Loss 0.0338 | Iter Mean Loss 0.0258\n",
      "CL Training: Epoch 0088 Iter 0100 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0088 Iter 0120 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0088 Iter 0120 / 0263 | Iter Loss 0.0326 | Iter Mean Loss 0.0265\n",
      "CL Training: Epoch 0088 Iter 0120 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0088 Iter 0140 / 0263 | Iter Loss 0.0203 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0088 Iter 0140 / 0263 | Iter Loss 0.0361 | Iter Mean Loss 0.0274\n",
      "CL Training: Epoch 0088 Iter 0140 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0088 Iter 0160 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0088 Iter 0160 / 0263 | Iter Loss 0.0362 | Iter Mean Loss 0.0284\n",
      "CL Training: Epoch 0088 Iter 0160 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0088 Iter 0180 / 0263 | Iter Loss 0.0175 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0088 Iter 0180 / 0263 | Iter Loss 0.0447 | Iter Mean Loss 0.0291\n",
      "CL Training: Epoch 0088 Iter 0180 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0088 Iter 0200 / 0263 | Iter Loss 0.0236 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0088 Iter 0200 / 0263 | Iter Loss 0.0422 | Iter Mean Loss 0.0299\n",
      "CL Training: Epoch 0088 Iter 0200 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0088 Iter 0220 / 0263 | Iter Loss 0.0113 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0088 Iter 0220 / 0263 | Iter Loss 0.0404 | Iter Mean Loss 0.0307\n",
      "CL Training: Epoch 0088 Iter 0220 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0088 Iter 0240 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0088 Iter 0240 / 0263 | Iter Loss 0.0404 | Iter Mean Loss 0.0315\n",
      "CL Training: Epoch 0088 Iter 0240 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0088 Iter 0260 / 0263 | Iter Loss 0.0148 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0088 Iter 0260 / 0263 | Iter Loss 0.0555 | Iter Mean Loss 0.0326\n",
      "CL Training: Epoch 0088 Iter 0260 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0949\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.795192 s\n",
      "Measure time: 0.017542 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 89, Hit Ratio:0.19888  |  Precision:0.12248  |  Recall:0.20157  |  NDCG:0.19993\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0089 Iter 0000 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0089 Iter 0000 / 0263 | Iter Loss 0.0181 | Iter Mean Loss 0.0181\n",
      "CL Training: Epoch 0089 Iter 0000 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0089 Iter 0020 / 0263 | Iter Loss 0.0161 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0089 Iter 0020 / 0263 | Iter Loss 0.0242 | Iter Mean Loss 0.0221\n",
      "CL Training: Epoch 0089 Iter 0020 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0089 Iter 0040 / 0263 | Iter Loss 0.0234 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0089 Iter 0040 / 0263 | Iter Loss 0.0293 | Iter Mean Loss 0.0233\n",
      "CL Training: Epoch 0089 Iter 0040 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0089 Iter 0060 / 0263 | Iter Loss 0.0150 | Iter Mean Loss 0.0191\n",
      "KG Training: Epoch 0089 Iter 0060 / 0263 | Iter Loss 0.0255 | Iter Mean Loss 0.0240\n",
      "CL Training: Epoch 0089 Iter 0060 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0089 Iter 0080 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0089 Iter 0080 / 0263 | Iter Loss 0.0275 | Iter Mean Loss 0.0245\n",
      "CL Training: Epoch 0089 Iter 0080 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0089 Iter 0100 / 0263 | Iter Loss 0.0238 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0089 Iter 0100 / 0263 | Iter Loss 0.0283 | Iter Mean Loss 0.0251\n",
      "CL Training: Epoch 0089 Iter 0100 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0089 Iter 0120 / 0263 | Iter Loss 0.0114 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0089 Iter 0120 / 0263 | Iter Loss 0.0295 | Iter Mean Loss 0.0260\n",
      "CL Training: Epoch 0089 Iter 0120 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0089 Iter 0140 / 0263 | Iter Loss 0.0212 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0089 Iter 0140 / 0263 | Iter Loss 0.0354 | Iter Mean Loss 0.0269\n",
      "CL Training: Epoch 0089 Iter 0140 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0089 Iter 0160 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0089 Iter 0160 / 0263 | Iter Loss 0.0319 | Iter Mean Loss 0.0278\n",
      "CL Training: Epoch 0089 Iter 0160 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0089 Iter 0180 / 0263 | Iter Loss 0.0224 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0089 Iter 0180 / 0263 | Iter Loss 0.0338 | Iter Mean Loss 0.0286\n",
      "CL Training: Epoch 0089 Iter 0180 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0089 Iter 0200 / 0263 | Iter Loss 0.0154 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0089 Iter 0200 / 0263 | Iter Loss 0.0380 | Iter Mean Loss 0.0294\n",
      "CL Training: Epoch 0089 Iter 0200 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0089 Iter 0220 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0089 Iter 0220 / 0263 | Iter Loss 0.0348 | Iter Mean Loss 0.0303\n",
      "CL Training: Epoch 0089 Iter 0220 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0089 Iter 0240 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0089 Iter 0240 / 0263 | Iter Loss 0.0422 | Iter Mean Loss 0.0312\n",
      "CL Training: Epoch 0089 Iter 0240 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0089 Iter 0260 / 0263 | Iter Loss 0.0215 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0089 Iter 0260 / 0263 | Iter Loss 0.0536 | Iter Mean Loss 0.0323\n",
      "CL Training: Epoch 0089 Iter 0260 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0948\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.948450 s\n",
      "Measure time: 0.021872 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 90, Hit Ratio:0.19806  |  Precision:0.12197  |  Recall:0.20019  |  NDCG:0.20246\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0090 Iter 0000 / 0263 | Iter Loss 0.0200 | Iter Mean Loss 0.0200\n",
      "KG Training: Epoch 0090 Iter 0000 / 0263 | Iter Loss 0.0192 | Iter Mean Loss 0.0192\n",
      "CL Training: Epoch 0090 Iter 0000 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0090 Iter 0020 / 0263 | Iter Loss 0.0193 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0090 Iter 0020 / 0263 | Iter Loss 0.0235 | Iter Mean Loss 0.0224\n",
      "CL Training: Epoch 0090 Iter 0020 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0090 Iter 0040 / 0263 | Iter Loss 0.0166 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0090 Iter 0040 / 0263 | Iter Loss 0.0276 | Iter Mean Loss 0.0238\n",
      "CL Training: Epoch 0090 Iter 0040 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0090 Iter 0060 / 0263 | Iter Loss 0.0174 | Iter Mean Loss 0.0187\n",
      "KG Training: Epoch 0090 Iter 0060 / 0263 | Iter Loss 0.0278 | Iter Mean Loss 0.0245\n",
      "CL Training: Epoch 0090 Iter 0060 / 0263 | Iter Loss 0.0955 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0090 Iter 0080 / 0263 | Iter Loss 0.0205 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0090 Iter 0080 / 0263 | Iter Loss 0.0244 | Iter Mean Loss 0.0250\n",
      "CL Training: Epoch 0090 Iter 0080 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0090 Iter 0100 / 0263 | Iter Loss 0.0184 | Iter Mean Loss 0.0189\n",
      "KG Training: Epoch 0090 Iter 0100 / 0263 | Iter Loss 0.0288 | Iter Mean Loss 0.0255\n",
      "CL Training: Epoch 0090 Iter 0100 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0090 Iter 0120 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0090 Iter 0120 / 0263 | Iter Loss 0.0327 | Iter Mean Loss 0.0264\n",
      "CL Training: Epoch 0090 Iter 0120 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0090 Iter 0140 / 0263 | Iter Loss 0.0150 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0090 Iter 0140 / 0263 | Iter Loss 0.0347 | Iter Mean Loss 0.0274\n",
      "CL Training: Epoch 0090 Iter 0140 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0090 Iter 0160 / 0263 | Iter Loss 0.0135 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0090 Iter 0160 / 0263 | Iter Loss 0.0323 | Iter Mean Loss 0.0283\n",
      "CL Training: Epoch 0090 Iter 0160 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0090 Iter 0180 / 0263 | Iter Loss 0.0157 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0090 Iter 0180 / 0263 | Iter Loss 0.0348 | Iter Mean Loss 0.0292\n",
      "CL Training: Epoch 0090 Iter 0180 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0090 Iter 0200 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0090 Iter 0200 / 0263 | Iter Loss 0.0365 | Iter Mean Loss 0.0299\n",
      "CL Training: Epoch 0090 Iter 0200 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0090 Iter 0220 / 0263 | Iter Loss 0.0244 | Iter Mean Loss 0.0184\n",
      "KG Training: Epoch 0090 Iter 0220 / 0263 | Iter Loss 0.0399 | Iter Mean Loss 0.0307\n",
      "CL Training: Epoch 0090 Iter 0220 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0090 Iter 0240 / 0263 | Iter Loss 0.0172 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0090 Iter 0240 / 0263 | Iter Loss 0.0381 | Iter Mean Loss 0.0316\n",
      "CL Training: Epoch 0090 Iter 0240 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0090 Iter 0260 / 0263 | Iter Loss 0.0151 | Iter Mean Loss 0.0186\n",
      "KG Training: Epoch 0090 Iter 0260 / 0263 | Iter Loss 0.0524 | Iter Mean Loss 0.0328\n",
      "CL Training: Epoch 0090 Iter 0260 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.972576 s\n",
      "Measure time: 0.017645 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 91, Hit Ratio:0.21039  |  Precision:0.12956  |  Recall:0.21253  |  NDCG:0.22199\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0091 Iter 0000 / 0263 | Iter Loss 0.0143 | Iter Mean Loss 0.0143\n",
      "KG Training: Epoch 0091 Iter 0000 / 0263 | Iter Loss 0.0174 | Iter Mean Loss 0.0174\n",
      "CL Training: Epoch 0091 Iter 0000 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0091 Iter 0020 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0185\n",
      "KG Training: Epoch 0091 Iter 0020 / 0263 | Iter Loss 0.0243 | Iter Mean Loss 0.0220\n",
      "CL Training: Epoch 0091 Iter 0020 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0953\n",
      "CF Training: Epoch 0091 Iter 0040 / 0263 | Iter Loss 0.0153 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0091 Iter 0040 / 0263 | Iter Loss 0.0238 | Iter Mean Loss 0.0232\n",
      "CL Training: Epoch 0091 Iter 0040 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0091 Iter 0060 / 0263 | Iter Loss 0.0131 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0091 Iter 0060 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0239\n",
      "CL Training: Epoch 0091 Iter 0060 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0091 Iter 0080 / 0263 | Iter Loss 0.0268 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0091 Iter 0080 / 0263 | Iter Loss 0.0230 | Iter Mean Loss 0.0243\n",
      "CL Training: Epoch 0091 Iter 0080 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0091 Iter 0100 / 0263 | Iter Loss 0.0277 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0091 Iter 0100 / 0263 | Iter Loss 0.0298 | Iter Mean Loss 0.0248\n",
      "CL Training: Epoch 0091 Iter 0100 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0091 Iter 0120 / 0263 | Iter Loss 0.0131 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0091 Iter 0120 / 0263 | Iter Loss 0.0262 | Iter Mean Loss 0.0256\n",
      "CL Training: Epoch 0091 Iter 0120 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0091 Iter 0140 / 0263 | Iter Loss 0.0187 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0091 Iter 0140 / 0263 | Iter Loss 0.0318 | Iter Mean Loss 0.0265\n",
      "CL Training: Epoch 0091 Iter 0140 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0091 Iter 0160 / 0263 | Iter Loss 0.0190 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0091 Iter 0160 / 0263 | Iter Loss 0.0343 | Iter Mean Loss 0.0274\n",
      "CL Training: Epoch 0091 Iter 0160 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0091 Iter 0180 / 0263 | Iter Loss 0.0152 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0091 Iter 0180 / 0263 | Iter Loss 0.0352 | Iter Mean Loss 0.0281\n",
      "CL Training: Epoch 0091 Iter 0180 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0091 Iter 0200 / 0263 | Iter Loss 0.0177 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0091 Iter 0200 / 0263 | Iter Loss 0.0340 | Iter Mean Loss 0.0289\n",
      "CL Training: Epoch 0091 Iter 0200 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0091 Iter 0220 / 0263 | Iter Loss 0.0163 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0091 Iter 0220 / 0263 | Iter Loss 0.0361 | Iter Mean Loss 0.0297\n",
      "CL Training: Epoch 0091 Iter 0220 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0091 Iter 0240 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0091 Iter 0240 / 0263 | Iter Loss 0.0376 | Iter Mean Loss 0.0305\n",
      "CL Training: Epoch 0091 Iter 0240 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0091 Iter 0260 / 0263 | Iter Loss 0.0217 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0091 Iter 0260 / 0263 | Iter Loss 0.0540 | Iter Mean Loss 0.0316\n",
      "CL Training: Epoch 0091 Iter 0260 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0948\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.923925 s\n",
      "Measure time: 0.017624 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 92, Hit Ratio:0.18612  |  Precision:0.11462  |  Recall:0.18785  |  NDCG:0.18777\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0092 Iter 0000 / 0263 | Iter Loss 0.0167 | Iter Mean Loss 0.0167\n",
      "KG Training: Epoch 0092 Iter 0000 / 0263 | Iter Loss 0.0157 | Iter Mean Loss 0.0157\n",
      "CL Training: Epoch 0092 Iter 0000 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0092 Iter 0020 / 0263 | Iter Loss 0.0153 | Iter Mean Loss 0.0168\n",
      "KG Training: Epoch 0092 Iter 0020 / 0263 | Iter Loss 0.0226 | Iter Mean Loss 0.0217\n",
      "CL Training: Epoch 0092 Iter 0020 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0092 Iter 0040 / 0263 | Iter Loss 0.0143 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0092 Iter 0040 / 0263 | Iter Loss 0.0241 | Iter Mean Loss 0.0226\n",
      "CL Training: Epoch 0092 Iter 0040 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0092 Iter 0060 / 0263 | Iter Loss 0.0200 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0092 Iter 0060 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0233\n",
      "CL Training: Epoch 0092 Iter 0060 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0092 Iter 0080 / 0263 | Iter Loss 0.0182 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0092 Iter 0080 / 0263 | Iter Loss 0.0254 | Iter Mean Loss 0.0239\n",
      "CL Training: Epoch 0092 Iter 0080 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0092 Iter 0100 / 0263 | Iter Loss 0.0201 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0092 Iter 0100 / 0263 | Iter Loss 0.0288 | Iter Mean Loss 0.0248\n",
      "CL Training: Epoch 0092 Iter 0100 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0092 Iter 0120 / 0263 | Iter Loss 0.0128 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0092 Iter 0120 / 0263 | Iter Loss 0.0290 | Iter Mean Loss 0.0258\n",
      "CL Training: Epoch 0092 Iter 0120 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0092 Iter 0140 / 0263 | Iter Loss 0.0171 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0092 Iter 0140 / 0263 | Iter Loss 0.0355 | Iter Mean Loss 0.0269\n",
      "CL Training: Epoch 0092 Iter 0140 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0092 Iter 0160 / 0263 | Iter Loss 0.0214 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0092 Iter 0160 / 0263 | Iter Loss 0.0364 | Iter Mean Loss 0.0279\n",
      "CL Training: Epoch 0092 Iter 0160 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0092 Iter 0180 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0092 Iter 0180 / 0263 | Iter Loss 0.0368 | Iter Mean Loss 0.0288\n",
      "CL Training: Epoch 0092 Iter 0180 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0092 Iter 0200 / 0263 | Iter Loss 0.0201 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0092 Iter 0200 / 0263 | Iter Loss 0.0416 | Iter Mean Loss 0.0298\n",
      "CL Training: Epoch 0092 Iter 0200 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0092 Iter 0220 / 0263 | Iter Loss 0.0157 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0092 Iter 0220 / 0263 | Iter Loss 0.0374 | Iter Mean Loss 0.0306\n",
      "CL Training: Epoch 0092 Iter 0220 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0092 Iter 0240 / 0263 | Iter Loss 0.0167 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0092 Iter 0240 / 0263 | Iter Loss 0.0421 | Iter Mean Loss 0.0315\n",
      "CL Training: Epoch 0092 Iter 0240 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0092 Iter 0260 / 0263 | Iter Loss 0.0105 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0092 Iter 0260 / 0263 | Iter Loss 0.0492 | Iter Mean Loss 0.0326\n",
      "CL Training: Epoch 0092 Iter 0260 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0948\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.013696 s\n",
      "Measure time: 0.017527 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 93, Hit Ratio:0.20823  |  Precision:0.12824  |  Recall:0.21057  |  NDCG:0.22125\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0093 Iter 0000 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0211\n",
      "KG Training: Epoch 0093 Iter 0000 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0189\n",
      "CL Training: Epoch 0093 Iter 0000 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0093 Iter 0020 / 0263 | Iter Loss 0.0182 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0093 Iter 0020 / 0263 | Iter Loss 0.0246 | Iter Mean Loss 0.0225\n",
      "CL Training: Epoch 0093 Iter 0020 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0093 Iter 0040 / 0263 | Iter Loss 0.0218 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0093 Iter 0040 / 0263 | Iter Loss 0.0230 | Iter Mean Loss 0.0236\n",
      "CL Training: Epoch 0093 Iter 0040 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0950\n",
      "CF Training: Epoch 0093 Iter 0060 / 0263 | Iter Loss 0.0155 | Iter Mean Loss 0.0173\n",
      "KG Training: Epoch 0093 Iter 0060 / 0263 | Iter Loss 0.0242 | Iter Mean Loss 0.0239\n",
      "CL Training: Epoch 0093 Iter 0060 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0093 Iter 0080 / 0263 | Iter Loss 0.0161 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0093 Iter 0080 / 0263 | Iter Loss 0.0259 | Iter Mean Loss 0.0245\n",
      "CL Training: Epoch 0093 Iter 0080 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0093 Iter 0100 / 0263 | Iter Loss 0.0148 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0093 Iter 0100 / 0263 | Iter Loss 0.0297 | Iter Mean Loss 0.0249\n",
      "CL Training: Epoch 0093 Iter 0100 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0093 Iter 0120 / 0263 | Iter Loss 0.0142 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0093 Iter 0120 / 0263 | Iter Loss 0.0313 | Iter Mean Loss 0.0258\n",
      "CL Training: Epoch 0093 Iter 0120 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0093 Iter 0140 / 0263 | Iter Loss 0.0129 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0093 Iter 0140 / 0263 | Iter Loss 0.0360 | Iter Mean Loss 0.0267\n",
      "CL Training: Epoch 0093 Iter 0140 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0093 Iter 0160 / 0263 | Iter Loss 0.0153 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0093 Iter 0160 / 0263 | Iter Loss 0.0369 | Iter Mean Loss 0.0275\n",
      "CL Training: Epoch 0093 Iter 0160 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0093 Iter 0180 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0093 Iter 0180 / 0263 | Iter Loss 0.0381 | Iter Mean Loss 0.0283\n",
      "CL Training: Epoch 0093 Iter 0180 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0093 Iter 0200 / 0263 | Iter Loss 0.0190 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0093 Iter 0200 / 0263 | Iter Loss 0.0407 | Iter Mean Loss 0.0290\n",
      "CL Training: Epoch 0093 Iter 0200 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0093 Iter 0220 / 0263 | Iter Loss 0.0172 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0093 Iter 0220 / 0263 | Iter Loss 0.0379 | Iter Mean Loss 0.0298\n",
      "CL Training: Epoch 0093 Iter 0220 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0093 Iter 0240 / 0263 | Iter Loss 0.0111 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0093 Iter 0240 / 0263 | Iter Loss 0.0411 | Iter Mean Loss 0.0307\n",
      "CL Training: Epoch 0093 Iter 0240 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0093 Iter 0260 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0093 Iter 0260 / 0263 | Iter Loss 0.0597 | Iter Mean Loss 0.0318\n",
      "CL Training: Epoch 0093 Iter 0260 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0947\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.977388 s\n",
      "Measure time: 0.017773 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 94, Hit Ratio:0.20405  |  Precision:0.12566  |  Recall:0.20526  |  NDCG:0.21339\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0094 Iter 0000 / 0263 | Iter Loss 0.0220 | Iter Mean Loss 0.0220\n",
      "KG Training: Epoch 0094 Iter 0000 / 0263 | Iter Loss 0.0179 | Iter Mean Loss 0.0179\n",
      "CL Training: Epoch 0094 Iter 0000 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0094 Iter 0020 / 0263 | Iter Loss 0.0158 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0094 Iter 0020 / 0263 | Iter Loss 0.0228 | Iter Mean Loss 0.0221\n",
      "CL Training: Epoch 0094 Iter 0020 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0094 Iter 0040 / 0263 | Iter Loss 0.0169 | Iter Mean Loss 0.0190\n",
      "KG Training: Epoch 0094 Iter 0040 / 0263 | Iter Loss 0.0249 | Iter Mean Loss 0.0232\n",
      "CL Training: Epoch 0094 Iter 0040 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0094 Iter 0060 / 0263 | Iter Loss 0.0166 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0094 Iter 0060 / 0263 | Iter Loss 0.0242 | Iter Mean Loss 0.0235\n",
      "CL Training: Epoch 0094 Iter 0060 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0094 Iter 0080 / 0263 | Iter Loss 0.0126 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0094 Iter 0080 / 0263 | Iter Loss 0.0263 | Iter Mean Loss 0.0240\n",
      "CL Training: Epoch 0094 Iter 0080 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0094 Iter 0100 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0178\n",
      "KG Training: Epoch 0094 Iter 0100 / 0263 | Iter Loss 0.0293 | Iter Mean Loss 0.0245\n",
      "CL Training: Epoch 0094 Iter 0100 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0094 Iter 0120 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0094 Iter 0120 / 0263 | Iter Loss 0.0343 | Iter Mean Loss 0.0253\n",
      "CL Training: Epoch 0094 Iter 0120 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0094 Iter 0140 / 0263 | Iter Loss 0.0225 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0094 Iter 0140 / 0263 | Iter Loss 0.0317 | Iter Mean Loss 0.0261\n",
      "CL Training: Epoch 0094 Iter 0140 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0094 Iter 0160 / 0263 | Iter Loss 0.0198 | Iter Mean Loss 0.0183\n",
      "KG Training: Epoch 0094 Iter 0160 / 0263 | Iter Loss 0.0351 | Iter Mean Loss 0.0271\n",
      "CL Training: Epoch 0094 Iter 0160 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0094 Iter 0180 / 0263 | Iter Loss 0.0209 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0094 Iter 0180 / 0263 | Iter Loss 0.0366 | Iter Mean Loss 0.0279\n",
      "CL Training: Epoch 0094 Iter 0180 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0094 Iter 0200 / 0263 | Iter Loss 0.0167 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0094 Iter 0200 / 0263 | Iter Loss 0.0393 | Iter Mean Loss 0.0288\n",
      "CL Training: Epoch 0094 Iter 0200 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0094 Iter 0220 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0094 Iter 0220 / 0263 | Iter Loss 0.0400 | Iter Mean Loss 0.0296\n",
      "CL Training: Epoch 0094 Iter 0220 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0094 Iter 0240 / 0263 | Iter Loss 0.0208 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0094 Iter 0240 / 0263 | Iter Loss 0.0380 | Iter Mean Loss 0.0304\n",
      "CL Training: Epoch 0094 Iter 0240 / 0263 | Iter Loss 0.0942 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0094 Iter 0260 / 0263 | Iter Loss 0.0207 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0094 Iter 0260 / 0263 | Iter Loss 0.0578 | Iter Mean Loss 0.0315\n",
      "CL Training: Epoch 0094 Iter 0260 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0946\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.972397 s\n",
      "Measure time: 0.019761 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 95, Hit Ratio:0.20534  |  Precision:0.12646  |  Recall:0.20781  |  NDCG:0.22141\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0095 Iter 0000 / 0263 | Iter Loss 0.0152 | Iter Mean Loss 0.0152\n",
      "KG Training: Epoch 0095 Iter 0000 / 0263 | Iter Loss 0.0182 | Iter Mean Loss 0.0182\n",
      "CL Training: Epoch 0095 Iter 0000 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0095 Iter 0020 / 0263 | Iter Loss 0.0190 | Iter Mean Loss 0.0163\n",
      "KG Training: Epoch 0095 Iter 0020 / 0263 | Iter Loss 0.0238 | Iter Mean Loss 0.0216\n",
      "CL Training: Epoch 0095 Iter 0020 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0095 Iter 0040 / 0263 | Iter Loss 0.0192 | Iter Mean Loss 0.0171\n",
      "KG Training: Epoch 0095 Iter 0040 / 0263 | Iter Loss 0.0244 | Iter Mean Loss 0.0228\n",
      "CL Training: Epoch 0095 Iter 0040 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0095 Iter 0060 / 0263 | Iter Loss 0.0168 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0095 Iter 0060 / 0263 | Iter Loss 0.0242 | Iter Mean Loss 0.0234\n",
      "CL Training: Epoch 0095 Iter 0060 / 0263 | Iter Loss 0.0946 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0095 Iter 0080 / 0263 | Iter Loss 0.0221 | Iter Mean Loss 0.0176\n",
      "KG Training: Epoch 0095 Iter 0080 / 0263 | Iter Loss 0.0217 | Iter Mean Loss 0.0236\n",
      "CL Training: Epoch 0095 Iter 0080 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0095 Iter 0100 / 0263 | Iter Loss 0.0155 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0095 Iter 0100 / 0263 | Iter Loss 0.0280 | Iter Mean Loss 0.0242\n",
      "CL Training: Epoch 0095 Iter 0100 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0095 Iter 0120 / 0263 | Iter Loss 0.0156 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0095 Iter 0120 / 0263 | Iter Loss 0.0318 | Iter Mean Loss 0.0251\n",
      "CL Training: Epoch 0095 Iter 0120 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0095 Iter 0140 / 0263 | Iter Loss 0.0222 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0095 Iter 0140 / 0263 | Iter Loss 0.0318 | Iter Mean Loss 0.0262\n",
      "CL Training: Epoch 0095 Iter 0140 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0095 Iter 0160 / 0263 | Iter Loss 0.0124 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0095 Iter 0160 / 0263 | Iter Loss 0.0329 | Iter Mean Loss 0.0272\n",
      "CL Training: Epoch 0095 Iter 0160 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0095 Iter 0180 / 0263 | Iter Loss 0.0271 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0095 Iter 0180 / 0263 | Iter Loss 0.0350 | Iter Mean Loss 0.0280\n",
      "CL Training: Epoch 0095 Iter 0180 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0095 Iter 0200 / 0263 | Iter Loss 0.0100 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0095 Iter 0200 / 0263 | Iter Loss 0.0375 | Iter Mean Loss 0.0290\n",
      "CL Training: Epoch 0095 Iter 0200 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0095 Iter 0220 / 0263 | Iter Loss 0.0169 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0095 Iter 0220 / 0263 | Iter Loss 0.0418 | Iter Mean Loss 0.0298\n",
      "CL Training: Epoch 0095 Iter 0220 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0095 Iter 0240 / 0263 | Iter Loss 0.0117 | Iter Mean Loss 0.0182\n",
      "KG Training: Epoch 0095 Iter 0240 / 0263 | Iter Loss 0.0487 | Iter Mean Loss 0.0308\n",
      "CL Training: Epoch 0095 Iter 0240 / 0263 | Iter Loss 0.0953 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0095 Iter 0260 / 0263 | Iter Loss 0.0143 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0095 Iter 0260 / 0263 | Iter Loss 0.0635 | Iter Mean Loss 0.0321\n",
      "CL Training: Epoch 0095 Iter 0260 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0947\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 3.026445 s\n",
      "Measure time: 0.017521 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 96, Hit Ratio:0.20138  |  Precision:0.12402  |  Recall:0.20405  |  NDCG:0.20619\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0096 Iter 0000 / 0263 | Iter Loss 0.0171 | Iter Mean Loss 0.0171\n",
      "KG Training: Epoch 0096 Iter 0000 / 0263 | Iter Loss 0.0180 | Iter Mean Loss 0.0180\n",
      "CL Training: Epoch 0096 Iter 0000 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0952\n",
      "CF Training: Epoch 0096 Iter 0020 / 0263 | Iter Loss 0.0229 | Iter Mean Loss 0.0168\n",
      "KG Training: Epoch 0096 Iter 0020 / 0263 | Iter Loss 0.0239 | Iter Mean Loss 0.0218\n",
      "CL Training: Epoch 0096 Iter 0020 / 0263 | Iter Loss 0.0951 | Iter Mean Loss 0.0951\n",
      "CF Training: Epoch 0096 Iter 0040 / 0263 | Iter Loss 0.0201 | Iter Mean Loss 0.0171\n",
      "KG Training: Epoch 0096 Iter 0040 / 0263 | Iter Loss 0.0238 | Iter Mean Loss 0.0232\n",
      "CL Training: Epoch 0096 Iter 0040 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0949\n",
      "CF Training: Epoch 0096 Iter 0060 / 0263 | Iter Loss 0.0165 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0096 Iter 0060 / 0263 | Iter Loss 0.0226 | Iter Mean Loss 0.0237\n",
      "CL Training: Epoch 0096 Iter 0060 / 0263 | Iter Loss 0.0950 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0096 Iter 0080 / 0263 | Iter Loss 0.0152 | Iter Mean Loss 0.0174\n",
      "KG Training: Epoch 0096 Iter 0080 / 0263 | Iter Loss 0.0273 | Iter Mean Loss 0.0243\n",
      "CL Training: Epoch 0096 Iter 0080 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0096 Iter 0100 / 0263 | Iter Loss 0.0221 | Iter Mean Loss 0.0175\n",
      "KG Training: Epoch 0096 Iter 0100 / 0263 | Iter Loss 0.0266 | Iter Mean Loss 0.0249\n",
      "CL Training: Epoch 0096 Iter 0100 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0096 Iter 0120 / 0263 | Iter Loss 0.0126 | Iter Mean Loss 0.0173\n",
      "KG Training: Epoch 0096 Iter 0120 / 0263 | Iter Loss 0.0341 | Iter Mean Loss 0.0258\n",
      "CL Training: Epoch 0096 Iter 0120 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0948\n",
      "CF Training: Epoch 0096 Iter 0140 / 0263 | Iter Loss 0.0190 | Iter Mean Loss 0.0172\n",
      "KG Training: Epoch 0096 Iter 0140 / 0263 | Iter Loss 0.0343 | Iter Mean Loss 0.0268\n",
      "CL Training: Epoch 0096 Iter 0140 / 0263 | Iter Loss 0.0941 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0096 Iter 0160 / 0263 | Iter Loss 0.0130 | Iter Mean Loss 0.0173\n",
      "KG Training: Epoch 0096 Iter 0160 / 0263 | Iter Loss 0.0425 | Iter Mean Loss 0.0279\n",
      "CL Training: Epoch 0096 Iter 0160 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0096 Iter 0180 / 0263 | Iter Loss 0.0158 | Iter Mean Loss 0.0173\n",
      "KG Training: Epoch 0096 Iter 0180 / 0263 | Iter Loss 0.0351 | Iter Mean Loss 0.0287\n",
      "CL Training: Epoch 0096 Iter 0180 / 0263 | Iter Loss 0.0945 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0096 Iter 0200 / 0263 | Iter Loss 0.0291 | Iter Mean Loss 0.0172\n",
      "KG Training: Epoch 0096 Iter 0200 / 0263 | Iter Loss 0.0356 | Iter Mean Loss 0.0294\n",
      "CL Training: Epoch 0096 Iter 0200 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0096 Iter 0220 / 0263 | Iter Loss 0.0157 | Iter Mean Loss 0.0172\n",
      "KG Training: Epoch 0096 Iter 0220 / 0263 | Iter Loss 0.0407 | Iter Mean Loss 0.0302\n",
      "CL Training: Epoch 0096 Iter 0220 / 0263 | Iter Loss 0.0943 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0096 Iter 0240 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0173\n",
      "KG Training: Epoch 0096 Iter 0240 / 0263 | Iter Loss 0.0427 | Iter Mean Loss 0.0311\n",
      "CL Training: Epoch 0096 Iter 0240 / 0263 | Iter Loss 0.0943 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0096 Iter 0260 / 0263 | Iter Loss 0.0242 | Iter Mean Loss 0.0171\n",
      "KG Training: Epoch 0096 Iter 0260 / 0263 | Iter Loss 0.0515 | Iter Mean Loss 0.0321\n",
      "CL Training: Epoch 0096 Iter 0260 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0946\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.955857 s\n",
      "Measure time: 0.018142 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 97, Hit Ratio:0.20306  |  Precision:0.12505  |  Recall:0.20647  |  NDCG:0.20966\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 63, Hit Ratio:0.21849  |  Precision:0.13455  |  Recall:0.22186  |  NDCG:0.2312\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "CF Training: Epoch 0097 Iter 0000 / 0263 | Iter Loss 0.0211 | Iter Mean Loss 0.0211\n",
      "KG Training: Epoch 0097 Iter 0000 / 0263 | Iter Loss 0.0176 | Iter Mean Loss 0.0176\n",
      "CL Training: Epoch 0097 Iter 0000 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0947\n",
      "CF Training: Epoch 0097 Iter 0020 / 0263 | Iter Loss 0.0164 | Iter Mean Loss 0.0188\n",
      "KG Training: Epoch 0097 Iter 0020 / 0263 | Iter Loss 0.0236 | Iter Mean Loss 0.0223\n",
      "CL Training: Epoch 0097 Iter 0020 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0097 Iter 0040 / 0263 | Iter Loss 0.0189 | Iter Mean Loss 0.0177\n",
      "KG Training: Epoch 0097 Iter 0040 / 0263 | Iter Loss 0.0247 | Iter Mean Loss 0.0233\n",
      "CL Training: Epoch 0097 Iter 0040 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0097 Iter 0060 / 0263 | Iter Loss 0.0231 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0097 Iter 0060 / 0263 | Iter Loss 0.0237 | Iter Mean Loss 0.0238\n",
      "CL Training: Epoch 0097 Iter 0060 / 0263 | Iter Loss 0.0943 | Iter Mean Loss 0.0945\n",
      "CF Training: Epoch 0097 Iter 0080 / 0263 | Iter Loss 0.0248 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0097 Iter 0080 / 0263 | Iter Loss 0.0242 | Iter Mean Loss 0.0241\n",
      "CL Training: Epoch 0097 Iter 0080 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0945\n",
      "CF Training: Epoch 0097 Iter 0100 / 0263 | Iter Loss 0.0163 | Iter Mean Loss 0.0181\n",
      "KG Training: Epoch 0097 Iter 0100 / 0263 | Iter Loss 0.0295 | Iter Mean Loss 0.0247\n",
      "CL Training: Epoch 0097 Iter 0100 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0945\n",
      "CF Training: Epoch 0097 Iter 0120 / 0263 | Iter Loss 0.0252 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0097 Iter 0120 / 0263 | Iter Loss 0.0270 | Iter Mean Loss 0.0253\n",
      "CL Training: Epoch 0097 Iter 0120 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0945\n",
      "CF Training: Epoch 0097 Iter 0140 / 0263 | Iter Loss 0.0192 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0097 Iter 0140 / 0263 | Iter Loss 0.0325 | Iter Mean Loss 0.0261\n",
      "CL Training: Epoch 0097 Iter 0140 / 0263 | Iter Loss 0.0943 | Iter Mean Loss 0.0945\n",
      "CF Training: Epoch 0097 Iter 0160 / 0263 | Iter Loss 0.0214 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0097 Iter 0160 / 0263 | Iter Loss 0.0319 | Iter Mean Loss 0.0269\n",
      "CL Training: Epoch 0097 Iter 0160 / 0263 | Iter Loss 0.0944 | Iter Mean Loss 0.0945\n",
      "CF Training: Epoch 0097 Iter 0180 / 0263 | Iter Loss 0.0178 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0097 Iter 0180 / 0263 | Iter Loss 0.0319 | Iter Mean Loss 0.0277\n",
      "CL Training: Epoch 0097 Iter 0180 / 0263 | Iter Loss 0.0947 | Iter Mean Loss 0.0945\n",
      "CF Training: Epoch 0097 Iter 0200 / 0263 | Iter Loss 0.0160 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0097 Iter 0200 / 0263 | Iter Loss 0.0392 | Iter Mean Loss 0.0285\n",
      "CL Training: Epoch 0097 Iter 0200 / 0263 | Iter Loss 0.0948 | Iter Mean Loss 0.0945\n",
      "CF Training: Epoch 0097 Iter 0220 / 0263 | Iter Loss 0.0195 | Iter Mean Loss 0.0180\n",
      "KG Training: Epoch 0097 Iter 0220 / 0263 | Iter Loss 0.0388 | Iter Mean Loss 0.0294\n",
      "CL Training: Epoch 0097 Iter 0220 / 0263 | Iter Loss 0.0952 | Iter Mean Loss 0.0946\n",
      "CF Training: Epoch 0097 Iter 0240 / 0263 | Iter Loss 0.0173 | Iter Mean Loss 0.0179\n",
      "KG Training: Epoch 0097 Iter 0240 / 0263 | Iter Loss 0.0376 | Iter Mean Loss 0.0303\n",
      "CL Training: Epoch 0097 Iter 0240 / 0263 | Iter Loss 0.0949 | Iter Mean Loss 0.0946\n"
     ]
    }
   ],
   "source": [
    "for params in product(*hyperparameters):\n",
    "    dataset, lr, lr_kg, lr_decay, reg, reg_kg, hyper_dim, input_dim, prob, drop_rate, n_layers, n_heads, n_self_att, cl_rate, aug_type, temp, use_contrast, use_attention_propagation = params\n",
    "    print(params)\n",
    "    args = {\n",
    "        'lr': lr,\n",
    "        'lr_kg': lr_kg,\n",
    "        'lr_decay': lr_decay,\n",
    "        'reg': reg,\n",
    "        'reg_kg': reg_kg,\n",
    "        'hyper_dim': hyper_dim,\n",
    "        'input_dim': input_dim,\n",
    "        'p': prob,\n",
    "        'drop_rate': drop_rate,\n",
    "        'n_layers': n_layers,\n",
    "        'input_dim': input_dim,\n",
    "        'hyper_dim': hyper_dim,\n",
    "        'relation_dim': 32,\n",
    "        'n_heads': n_heads,\n",
    "        'n_self_att': n_self_att,\n",
    "        'dataset': dataset,\n",
    "        'cl_rate': cl_rate,\n",
    "        'aug_type': aug_type,\n",
    "        'temp': temp,\n",
    "        'use_contrastive': use_contrast,\n",
    "        'use_attention_propagation': use_attention_propagation\n",
    "    }\n",
    "    rec = GraphRecommender(config, data, data_kg, knowledge_set, **args)\n",
    "    train_model_cf = Model(rec.config, rec.data, rec.data_kg, args).to(device)\n",
    "    train_model_kg = Model(rec.config, rec.data, rec.data_kg, args).to(device)\n",
    "    attention_user = Attention(in_size=args['hyper_dim'], hidden_size=args['hyper_dim']).to(device)\n",
    "    attention_item = Attention(in_size=args['hyper_dim'], hidden_size=args['hyper_dim']).to(device)\n",
    "\n",
    "    para_list = (\n",
    "        list(train_model_cf.parameters())\n",
    "        + list(train_model_kg.parameters())\n",
    "        + list(attention_user.parameters())\n",
    "        + list(attention_item.parameters())\n",
    "    )\n",
    "    \n",
    "    optimizer  = torch.optim.Adam(para_list, lr=lr)\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', factor=lr_decay, patience=10)\n",
    "\n",
    "    user_emb, item_emb = train(train_model_cf, train_model_kg, attention_user,attention_item, rec, args)\n",
    "    test(rec, user_emb, item_emb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966fb757-1ec9-46ce-afb0-dd6173234985",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del train_model_cf\n",
    "# del train_model_kg\n",
    "torch.cuda.empty_cache() # PyTorch thing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hungvv",
   "language": "python",
   "name": "hungvv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
