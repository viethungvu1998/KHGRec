{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e089b57-b508-49f7-bc17-59ede3c86ac5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jun/anaconda3/envs/hungvv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import HypergraphConv\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.init as init\n",
    "# from torch.nn.init import xavier_normal_, xavier_uniform_\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "from os.path import abspath\n",
    "import random\n",
    "import pandas as pd\n",
    "from util.sampler import  next_batch_pairwise\n",
    "from util.conf import OptionConf\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from scipy.sparse import coo_matrix\n",
    "from util.loss_torch import bpr_loss, l2_reg_loss, EmbLoss, contrastLoss, InfoNCE\n",
    "from util.init import *\n",
    "from base.torch_interface import TorchGraphInterface\n",
    "import os\n",
    "import numpy as np \n",
    "import time \n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from itertools import product\n",
    "\n",
    "from util.conf import ModelConf\n",
    "from base.recommender import Recommender\n",
    "from util.algorithm import find_k_largest\n",
    "from time import strftime, localtime\n",
    "from data.loader import FileIO\n",
    "from util.evaluation import ranking_evaluation\n",
    "from util.evaluation import early_stopping\n",
    "\n",
    "from data.ui_graph import Interaction\n",
    "from data.augmentor import GraphAugmentor, drop_edges\n",
    "from torch_geometric.nn import HypergraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4365d976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac47b4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb0f97",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Base Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc5eef39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GraphRecommender(Recommender):\n",
    "    def __init__(self, conf, data, data_kg,knowledge_set, **kwargs):\n",
    "        super(GraphRecommender, self).__init__(conf, data, data_kg, knowledge_set,**kwargs)\n",
    "        self.data = data\n",
    "        self.bestPerformance = []\n",
    "        top = self.ranking['-topN'].split(',')\n",
    "        self.topN = [int(num) for num in top]\n",
    "        self.max_N = max(self.topN)\n",
    "        \n",
    "        self.dataset = kwargs['dataset']\n",
    "        \n",
    "        # self.output = f\"./results/{self.model_name}/{self.dataset}/@{self.model_name}-inp_emb:{kwargs['input_dim']}-hyper_emb:{kwargs['hyper_dim']}-bs:{self.batch_size}-lr:{kwargs['lr']}-lrd:{kwargs['lr_decay']}-reg:{kwargs['reg']}-leaky:{kwargs['p']}-dropout:{kwargs['drop_rate']}-n_layers:{kwargs['n_layers']}-n_heads:{kwargs['n_heads']}-n_self_att:{kwargs['n_self_att']}/\"\n",
    "        self.output = f\"./results/HGNN_Attention_DropEdge/{self.dataset}/@{self.model_name}-inp_emb:{kwargs['input_dim']}-hyper_emb:{kwargs['hyper_dim']}-bs:{self.batch_size}-opt:{kwargs['optimizer']}-lr:{kwargs['lr']}-lrd:{kwargs['lr_decay']}-reg:{kwargs['reg']}-leaky:{kwargs['p']}-dropout:{kwargs['drop_rate']}-concat:{kwargs['concat']}-attention_mode:{kwargs['attention_mode']}-n_layers:{kwargs['n_layers']}-cl_rate:{kwargs['cl_rate']}-aug_type:{kwargs['aug_type']}-temp:{kwargs['temp']}-wdecay:{kwargs['weight_decay']}/\"\n",
    "        if not os.path.exists(self.output):\n",
    "            os.makedirs(self.output)\n",
    "\n",
    "    def print_model_info(self):\n",
    "        super(GraphRecommender, self).print_model_info()\n",
    "        # # print dataset statistics\n",
    "        print('Training Set Size: (user number: %d, item number %d, interaction number: %d)' % (self.data.training_size()))\n",
    "        print('Test Set Size: (user number: %d, item number %d, interaction number: %d)' % (self.data.test_size()))\n",
    "        print('=' * 80)\n",
    "\n",
    "    def build(self):\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self, u):\n",
    "        pass\n",
    "\n",
    "    def test(self, user_emb, item_emb):\n",
    "        def process_bar(num, total):\n",
    "            rate = float(num) / total\n",
    "            ratenum = int(50 * rate)\n",
    "            r = '\\rProgress: [{}{}]{}%'.format('+' * ratenum, ' ' * (50 - ratenum), ratenum*2)\n",
    "            sys.stdout.write(r)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # predict\n",
    "        rec_list = {}\n",
    "        user_count = len(self.data.test_set)\n",
    "        for i, user in enumerate(self.data.test_set):\n",
    "            # s_find_candidates = time.time()\n",
    "            \n",
    "            \n",
    "            # candidates = predict(user)\n",
    "            user_id  = self.data.get_user_id(user)\n",
    "            score = torch.matmul(user_emb[user_id], item_emb.transpose(0, 1))\n",
    "            candidates = score.cpu().numpy()\n",
    "            \n",
    "            # e_find_candidates = time.time()\n",
    "            # print(\"Calculate candidates time: %f s\" % (e_find_candidates - s_find_candidates))\n",
    "            # predictedItems = denormalize(predictedItems, self.data.rScale[-1], self.data.rScale[0])\n",
    "            rated_list, li = self.data.user_rated(user)\n",
    "            for item in rated_list:\n",
    "                candidates[self.data.item[item]] = -10e8\n",
    "            \n",
    "            # s_find_k_largest = time.time()\n",
    "            ids, scores = find_k_largest(self.max_N, candidates)\n",
    "            # e_find_k_largest = time.time()\n",
    "            # print(\"Find k largest candidates: %f s\" % (e_find_k_largest - s_find_k_largest))\n",
    "            item_names = [self.data.id2item[iid] for iid in ids]\n",
    "            rec_list[user] = list(zip(item_names, scores))\n",
    "            if i % 1000 == 0:\n",
    "                process_bar(i, user_count)\n",
    "        process_bar(user_count, user_count)\n",
    "        print('')\n",
    "        return rec_list\n",
    "\n",
    "    def evaluate(self, rec_list):\n",
    "        self.recOutput.append('userId: recommendations in (itemId, ranking score) pairs, * means the item is hit.\\n')\n",
    "        for user in self.data.test_set:\n",
    "            line = str(user) + ':'\n",
    "            for item in rec_list[user]:\n",
    "                line += ' (' + str(item[0]) + ',' + str(item[1]) + ')'\n",
    "                if item[0] in self.data.test_set[user]:\n",
    "                    line += '*'\n",
    "            line += '\\n'\n",
    "            self.recOutput.append(line)\n",
    "        current_time = strftime(\"%Y-%m-%d %H-%M-%S\", localtime(time.time()))\n",
    "        # output prediction result\n",
    "        out_dir = self.output\n",
    "        file_name = self.config['model.name'] + '@' + current_time + '-top-' + str(self.max_N) + 'items' + '.txt'\n",
    "        FileIO.write_file(out_dir, file_name, self.recOutput)\n",
    "        print('The result has been output to ', abspath(out_dir), '.')\n",
    "        file_name = self.config['model.name'] + '@' + current_time + '-performance' + '.txt'\n",
    "        self.result = ranking_evaluation(self.data.test_set, rec_list, self.topN)\n",
    "        self.model_log.add('###Evaluation Results###')\n",
    "        self.model_log.add(self.result)\n",
    "        FileIO.write_file(out_dir, file_name, self.result)\n",
    "        print('The result of %s:\\n%s' % (self.model_name, ''.join(self.result)))\n",
    "\n",
    "    def fast_evaluation(self, model, epoch, user_embed, item_embed, kwargs=None):\n",
    "        print('Evaluating the model...')\n",
    "        s_test = time.time()\n",
    "        rec_list = self.test(user_embed, item_embed)\n",
    "        e_test = time.time() \n",
    "        print(\"Test time: %f s\" % (e_test - s_test))\n",
    "        \n",
    "        s_measure = time.time()\n",
    "        measure = ranking_evaluation(self.data.test_set, rec_list, [self.max_N])\n",
    "        e_measure = time.time()\n",
    "        print(\"Measure time: %f s\" % (e_measure - s_measure))\n",
    "        \n",
    "        if len(self.bestPerformance) > 0:\n",
    "            count = 0\n",
    "            performance = {}\n",
    "            for m in measure[1:]:\n",
    "                k, v = m.strip().split(':')\n",
    "                performance[k] = float(v)\n",
    "            for k in self.bestPerformance[1]:\n",
    "                if self.bestPerformance[1][k] > performance[k]:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    count -= 1\n",
    "            if count < 0:\n",
    "                self.bestPerformance[1] = performance\n",
    "                self.bestPerformance[0] = epoch + 1\n",
    "                # try:\n",
    "                #     self.save(kwargs)\n",
    "                # except:\n",
    "                self.save(model)\n",
    "        else:\n",
    "            self.bestPerformance.append(epoch + 1)\n",
    "            performance = {}\n",
    "            for m in measure[1:]:\n",
    "                k, v = m.strip().split(':')\n",
    "                performance[k] = float(v)\n",
    "            self.bestPerformance.append(performance)\n",
    "            # try:\n",
    "            #     self.save(kwargs)\n",
    "            # except:\n",
    "            self.save(model)\n",
    "        print('-' * 120)\n",
    "        print('Real-Time Ranking Performance ' + ' (Top-' + str(self.max_N) + ' Item Recommendation)')\n",
    "        measure = [m.strip() for m in measure[1:]]\n",
    "        print('*Current Performance*')\n",
    "        print('Epoch:', str(epoch + 1) + ',', '  |  '.join(measure))\n",
    "        bp = ''\n",
    "        # for k in self.bestPerformance[1]:\n",
    "        #     bp+=k+':'+str(self.bestPerformance[1][k])+' | '\n",
    "        bp += 'Hit Ratio' + ':' + str(self.bestPerformance[1]['Hit Ratio']) + '  |  '\n",
    "        bp += 'Precision' + ':' + str(self.bestPerformance[1]['Precision']) + '  |  '\n",
    "        bp += 'Recall' + ':' + str(self.bestPerformance[1]['Recall']) + '  |  '\n",
    "        # bp += 'F1' + ':' + str(self.bestPerformance[1]['F1']) + ' | '\n",
    "        bp += 'NDCG' + ':' + str(self.bestPerformance[1]['NDCG'])\n",
    "        print('*Best Performance* ')\n",
    "        print('Epoch:fast_evaluation', str(self.bestPerformance[0]) + ',', bp)\n",
    "        print('-' * 120)\n",
    "        return measure\n",
    "    \n",
    "    def save(self, model):\n",
    "        with torch.no_grad():\n",
    "            self.best_user_emb, self.best_item_emb = model()\n",
    "        self.save_model(model)\n",
    "    \n",
    "    def save_model(self, model):\n",
    "        # save model \n",
    "        current_time = strftime(\"%Y-%m-%d\", localtime(time.time()))\n",
    "        out_dir = self.output\n",
    "        file_name =  self.config['model.name'] + '@' + current_time + '-weight' + '.pth'\n",
    "        weight_file = out_dir + '/' + file_name \n",
    "        torch.save(model.state_dict(), weight_file)\n",
    "\n",
    "    def save_loss(self, train_losses, rec_losses, reg_losses, cl_losses):\n",
    "        df_train_loss = pd.DataFrame(train_losses, columns = ['ep', 'loss'])\n",
    "        df_rec_loss = pd.DataFrame(rec_losses, columns = ['ep', 'loss'])\n",
    "        df_reg_loss = pd.DataFrame(reg_losses, columns = ['ep', 'loss'])\n",
    "        df_cl_loss =  pd.DataFrame(cl_losses, columns = ['ep', 'loss'])\n",
    "        df_train_loss.to_csv(self.output + '/train_loss.csv')\n",
    "        df_rec_loss.to_csv(self.output + '/rec_loss.csv')\n",
    "        df_reg_loss.to_csv(self.output + '/reg_loss.csv')\n",
    "        df_cl_loss.to_csv(self.output + '/cl_loss.csv')\n",
    "\n",
    "    def save_perfomance_training(self, log_train):\n",
    "        df_train_log = pd.DataFrame(log_train)\n",
    "        df_train_log.to_csv(self.output + '/train_performance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68fb744",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2a6ac98-28d2-4f92-938d-6570eda82c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseHyperGNN(torch.nn.Module):\n",
    "    def __init__(self, dropout, p, emb_dim, num_layers, use_attention, attention_mode, heads, use_norm=True, use_skip_connection=True):\n",
    "        super(BaseHyperGNN, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.dropout = dropout\n",
    "        self.num_layers = num_layers\n",
    "        self.ln = [nn.LayerNorm(emb_dim ).to(device) for i in range(num_layers)]\n",
    "        self.act = nn.LeakyReLU(p)\n",
    "        self.attention_mode = attention_mode\n",
    "        self.use_norm = use_norm\n",
    "        self.use_skip_connection = use_skip_connection\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t, hyperedge_attr=None):\n",
    "        if self.attention_mode:\n",
    "            if self.use_norm:\n",
    "                for i, conv in enumerate(self.convs[:-1]):\n",
    "                    if self.use_skip_connection:\n",
    "                        x = self.ln[i](conv(x, adj_t, hyperedge_attr=hyperedge_attr)) + x\n",
    "                    else:\n",
    "                        x = self.ln[i](conv(x, adj_t, hyperedge_attr=hyperedge_attr))\n",
    "                    x = self.act(x)\n",
    "                    x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "                if self.use_skip_connection:\n",
    "                    x = self.convs[-1](x, adj_t, hyperedge_attr=hyperedge_attr) + x\n",
    "                else:\n",
    "                    x = self.convs[-1](x, adj_t, hyperedge_attr=hyperedge_attr)\n",
    "                if self.num_layers == 1:\n",
    "                    if self.use_skip_connection:\n",
    "                        x = self.act(self.ln[0](self.convs[0](x, adj_t, hyperedge_attr=hyperedge_attr) + x) )\n",
    "                    else:\n",
    "                        x = self.act(self.ln[0](self.convs[0](x, adj_t, hyperedge_attr=hyperedge_attr)) )\n",
    "                    x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            else:\n",
    "                for i, conv in enumerate(self.convs[:-1]):\n",
    "                    if self.use_skip_connection:\n",
    "                        x = conv(x, adj_t, hyperedge_attr=hyperedge_attr) + x\n",
    "                    else:\n",
    "                        x = conv(x, adj_t, hyperedge_attr=hyperedge_attr)\n",
    "                    x = self.act(x)\n",
    "                    x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "                if self.use_skip_connection:\n",
    "                    x = self.convs[-1](x, adj_t, hyperedge_attr=hyperedge_attr) + x\n",
    "                else:\n",
    "                    x = self.convs[-1](x, adj_t, hyperedge_attr=hyperedge_attr)\n",
    "                if self.num_layers == 1:\n",
    "                    if self.use_skip_connection:\n",
    "                        x = self.act(self.convs[0](x, adj_t, hyperedge_attr=hyperedge_attr) + x)\n",
    "                    else:\n",
    "                        x = self.act(self.convs[0](x, adj_t, hyperedge_attr=hyperedge_attr))\n",
    "                    x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        else:\n",
    "            if self.use_norm:\n",
    "                for i, conv in enumerate(self.convs[:-1]):\n",
    "                    if self.use_skip_connection:\n",
    "                        x = self.ln[i](conv(x, adj_t)) + x\n",
    "                    else:\n",
    "                        x = self.ln[i](conv(x, adj_t))\n",
    "                    x = self.act(x)\n",
    "                    x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "                if self.use_skip_connection:\n",
    "                    x = self.convs[-1](x, adj_t) + x\n",
    "                else:\n",
    "                    x = self.convs[-1](x, adj_t)\n",
    "                if self.num_layers == 1:\n",
    "                    if self.use_skip_connection:\n",
    "                        x = self.act(self.ln[0](self.convs[0](x, adj_t) + x) )\n",
    "                    else:\n",
    "                        x = self.act(self.ln[0](self.convs[0](x, adj_t)))\n",
    "                    x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            else:\n",
    "                for i, conv in enumerate(self.convs[:-1]):\n",
    "                    if self.use_skip_connection:\n",
    "                        x = conv(x, adj_t) + x\n",
    "                    else:\n",
    "                        x = conv(x, adj_t)\n",
    "                    x = self.act(x)\n",
    "                    x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "                if self.use_skip_connection:\n",
    "                    x = self.convs[-1](x, adj_t) + x\n",
    "                else:\n",
    "                    x = self.convs[-1](x, adj_t)\n",
    "                if self.num_layers == 1:\n",
    "                    if self.use_skip_connection:\n",
    "                        x = self.act(self.convs[0](x, adj_t) + x )\n",
    "                    else:\n",
    "                        x = self.act(self.convs[0](x, adj_t))\n",
    "                    x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x\n",
    "\n",
    "\n",
    "class HyperGCN(BaseHyperGNN):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout, p, use_attention, attention_mode, heads, concat, use_norm, use_skip_connection):\n",
    "        super(HyperGCN, self).__init__(dropout, p, hidden_channels, num_layers, use_attention, attention_mode, heads, use_norm, use_skip_connection)\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            first_channels = in_channels if i == 0 else hidden_channels\n",
    "            second_channels = out_channels if i == num_layers - 1 else hidden_channels\n",
    "            self.convs.append(HypergraphConv(first_channels, second_channels, use_attention=use_attention, attention_mode='node', heads=heads, concat=concat, negative_slove=p, dropout=dropout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7280f55f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6346ae7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, config, data, args):\n",
    "        super(Model, self).__init__()\n",
    "        self.data = data\n",
    "        self._parse_args(args)\n",
    "\n",
    "        self.edge_index = data.edge_index.to(device)\n",
    "        self.edge_index_t  = data.edge_index_t.to(device)\n",
    "\n",
    "        if self.use_drop_edge:\n",
    "            self.edge_index_aug = drop_edges(self.edge_index)\n",
    "            self.edge_index_aug_t = drop_edges(self.edge_index_t)\n",
    "        \n",
    "        # adj = data.interaction_mat\n",
    "        # self.adj  = TorchGraphInterface.convert_sparse_mat_to_tensor(adj).to(device)\n",
    "        # self.sparse_norm_adj = TorchGraphInterface.convert_sparse_mat_to_tensor(data.norm_adj).to(device)\n",
    "        \n",
    "        self.embedding_dict = self._init_model()\n",
    "        \n",
    "        self.hgnn_u = HyperGCN(self.hyper_dim, self.hyper_dim, self.hyper_dim, self.layers, self.drop_rate, self.p, use_attention=True, attention_mode=args['attention_mode'], heads=args['n_heads'], concat=args['concat'], use_norm=args['use_norm'], use_skip_connection=args['use_skip_connection']) \n",
    "        self.hgnn_i = HyperGCN(self.hyper_dim, self.hyper_dim, self.hyper_dim, self.layers, self.drop_rate, self.p, use_attention=True, attention_mode=args['attention_mode'], heads=args['n_heads'], concat=args['concat'], use_norm=args['use_norm'], use_skip_connection=args['use_skip_connection']) \n",
    "        \n",
    "        self.fc_u = nn.Linear(self.input_dim, self.hyper_dim)\n",
    "        self.fc_i = nn.Linear(self.input_dim, self.hyper_dim)\n",
    "        \n",
    "        self.non_linear = nn.ReLU()\n",
    "        self.act = nn.LeakyReLU(self.p)\n",
    "        self.dropout = nn.Dropout(self.drop_rate)\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _parse_args(self, args):\n",
    "        self.input_dim = args['input_dim']\n",
    "        self.hyper_dim = args['hyper_dim']\n",
    "        self.p = args['p']\n",
    "        self.drop_rate = args['drop_rate'] \n",
    "        self.layers = args['n_layers']\n",
    "        self.temp = args['temp']\n",
    "        self.aug_type = args['aug_type']\n",
    "        self.use_drop_edge = args['use_drop_edge']\n",
    "\n",
    "    def _init_model(self):\n",
    "        initializer = init.xavier_uniform_\n",
    "        embedding_dict = nn.ParameterDict({\n",
    "            'user_emb': nn.Parameter(initializer(torch.empty(self.data.n_users, self.input_dim)).to(device)),\n",
    "            'item_emb': nn.Parameter(initializer(torch.empty(self.data.n_items, self.input_dim)).to(device))\n",
    "        })\n",
    "        return embedding_dict\n",
    "    \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            init.normal_(m.weight, std=0.01)\n",
    "            if m.bias is not None:\n",
    "                init.zeros_(m.bias)\n",
    "        # elif isinstance(m, nn.Parameter):\n",
    "        #     init.normal_(m.data, std=0.01)\n",
    "\n",
    "    def forward(self, perturbed_adj=None):\n",
    "        uEmbed = self.embedding_dict['user_emb']\n",
    "        iEmbed = self.embedding_dict['item_emb']\n",
    "\n",
    "        uEmbed = self.act(self.fc_u(uEmbed))\n",
    "        iEmbed = self.act(self.fc_i(iEmbed))\n",
    "        \n",
    "        embeds = torch.cat([uEmbed, iEmbed], 0)\n",
    "        all_embeddings = [embeds]\n",
    "        \n",
    "        if self.use_drop_edge:\n",
    "            hyperULat = self.hgnn_u(uEmbed, self.edge_index_aug, hyperedge_attr=iEmbed)\n",
    "            hyperILat = self.hgnn_i(iEmbed, self.edge_index_aug_t, hyperedge_attr=uEmbed)\n",
    "        else:\n",
    "            hyperULat = self.hgnn_u(uEmbed, self.edge_index, hyperedge_attr=iEmbed)\n",
    "            hyperILat = self.hgnn_i(iEmbed, self.edge_index_t, hyperedge_attr=uEmbed)\n",
    "        ego_embeddings = torch.cat([hyperULat, hyperILat], dim=0)\n",
    "        all_embeddings += [ego_embeddings]\n",
    "        \n",
    "        all_embeddings = torch.stack(all_embeddings, dim=1)\n",
    "        all_embeddings = torch.mean(all_embeddings, dim=1)\n",
    "        user_all_embeddings = all_embeddings[:self.data.n_users]\n",
    "        item_all_embeddings = all_embeddings[self.data.n_users:]\n",
    "        return user_all_embeddings, item_all_embeddings \n",
    "    \n",
    "    def cal_cl_loss(self, idxs, perturbed_mat1, perturbed_mat2):\n",
    "        if type(idxs[0]) is not list:\n",
    "            u_idx = torch.unique(idxs[0])\n",
    "        else:\n",
    "            u_idx = torch.unique(torch.Tensor(idxs[0]).to(device).type(torch.long))\n",
    "        if type(idxs[1]) is not list:\n",
    "            i_idx = torch.unique(idxs[1])\n",
    "        else:\n",
    "            i_idx = torch.unique(torch.Tensor(idxs[1]).to(device).type(torch.long))\n",
    "        user_view_1, item_view_1 = self.forward(perturbed_mat1)\n",
    "        user_view_2, item_view_2 = self.forward(perturbed_mat2)\n",
    "        view1 = torch.cat((user_view_1[u_idx],item_view_1[i_idx]),0)\n",
    "        view2 = torch.cat((user_view_2[u_idx],item_view_2[i_idx]),0)\n",
    "        return InfoNCE(view1,view2,self.temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1f87c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e80c2d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_loss(anchor_emb, pos_emb, neg_emb, reg):\n",
    "    calc_reg_loss = EmbLoss()\n",
    "    rec_loss = bpr_loss(anchor_emb, pos_emb, neg_emb)\n",
    "    reg_loss = reg * calc_reg_loss(anchor_emb, pos_emb, neg_emb)\n",
    "    return rec_loss, reg_loss \n",
    "\n",
    "def calculate_kg_loss(anchor_emb, pos_emb, neg_emb, reg):\n",
    "    calc_reg_loss = EmbLoss()\n",
    "    rec_loss = triplet_loss(anchor_emb, pos_emb, neg_emb)\n",
    "    reg_loss = reg * calc_reg_loss(anchor_emb, pos_emb, neg_emb)\n",
    "    return rec_loss, reg_loss \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45a91cdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(u, rec, user_emb, item_emb):\n",
    "    user_id  = rec.data.get_user_id(u)\n",
    "    score = torch.matmul(user_emb[user_id], item_emb.transpose(0, 1))\n",
    "    return score.cpu().numpy()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2080f56a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c4024c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_model, data):\n",
    "    lst_train_losses = []\n",
    "    lst_rec_losses = []\n",
    "    lst_reg_losses = []\n",
    "    lst_cl_losses = []\n",
    "    lst_performances = []\n",
    "    recall_list = []\n",
    "    \n",
    "    for ep in range(maxEpoch):\n",
    "        train_losses = []\n",
    "        rec_losses = []\n",
    "        reg_losses = []\n",
    "        cl_losses = []\n",
    "        \n",
    "        # dropped_adj1 = train_model.graph_reconstruction()\n",
    "        # dropped_adj2 = train_model.graph_reconstruction()\n",
    "        \n",
    "        train_model.train()\n",
    "        \n",
    "        for n, batch in enumerate(next_batch_pairwise(rec.data, batchSize)):\n",
    "            user_idx, pos_idx, neg_idx = batch\n",
    "            user_emb, item_emb = train_model()\n",
    "            anchor_emb = user_emb[user_idx]\n",
    "            pos_emb = item_emb[pos_idx]\n",
    "            neg_emb = item_emb[neg_idx]\n",
    "            \n",
    "            rec_loss, reg_loss = calculate_loss(anchor_emb, pos_emb, neg_emb, reg)\n",
    "            cl_loss = 0 \n",
    "            # cl_loss = cl_rate * train_model.cal_cl_loss([user_idx, pos_idx], dropped_adj1, dropped_adj2)\n",
    "            batch_loss = rec_loss + reg_loss \n",
    "            train_losses.append(batch_loss.item())\n",
    "            rec_losses.append(rec_loss.item())\n",
    "            reg_losses.append(reg_loss.item())\n",
    "            # cl_losses.append(cl_loss.item())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(train_model.parameters(), 4)\n",
    "            optimizer.step()\n",
    "\n",
    "        batch_train_loss = np.mean(train_losses)\n",
    "        scheduler.step(batch_train_loss)\n",
    "                \n",
    "        train_loss = np.mean(train_losses)\n",
    "        rec_loss = np.mean(rec_losses)\n",
    "        reg_loss = np.mean(reg_losses)\n",
    "        # cl_loss =  np.mean(cl_losses)\n",
    "        cl_loss = 0\n",
    "        \n",
    "        lst_train_losses.append([ep, train_loss])\n",
    "        lst_rec_losses.append([ep,rec_loss])\n",
    "        lst_reg_losses.append([ep, reg_loss])\n",
    "        lst_cl_losses.append([ep, cl_loss])\n",
    "\n",
    "        # Evaluation\n",
    "        train_model.eval()\n",
    "        with torch.no_grad():\n",
    "            user_emb, item_emb = train_model()\n",
    "            data_ep = rec.fast_evaluation(train_model, ep, user_emb, item_emb)\n",
    "\n",
    "            cur_recall =  float(data_ep[2].split(':')[1])\n",
    "            recall_list.append(cur_recall)\n",
    "            best_recall, should_stop = early_stopping(recall_list, 100)\n",
    "        if should_stop:\n",
    "            break\n",
    "\n",
    "        lst_performances.append(data_ep)\n",
    "\n",
    "    rec.save_loss(lst_train_losses, lst_rec_losses, lst_reg_losses, lst_cl_losses)\n",
    "    rec.save_perfomance_training(lst_performances)\n",
    "    user_emb, item_emb = rec.best_user_emb, rec.best_item_emb\n",
    "    return user_emb, item_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081217e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "184d99a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(rec, user_emb, item_emb):\n",
    "    def process_bar(num, total):\n",
    "        rate = float(num) / total\n",
    "        ratenum = int(50 * rate)\n",
    "        r = '\\rProgress: [{}{}]{}%'.format('+' * ratenum, ' ' * (50 - ratenum), ratenum*2)\n",
    "        sys.stdout.write(r)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    # predict\n",
    "    rec_list = {}\n",
    "    user_count = len(rec.data.test_set)\n",
    "    for i, user in enumerate(rec.data.test_set):\n",
    "        # s_find_candidates = time.time()\n",
    "        candidates = predict(user, rec, user_emb, item_emb)\n",
    "        # e_find_candidates = time.time()\n",
    "        # print(\"Calculate candidates time: %f s\" % (e_find_candidates - s_find_candidates))\n",
    "        # predictedItems = denormalize(predictedItems, self.data.rScale[-1], self.data.rScale[0])\n",
    "        rated_list, li = rec.data.user_rated(user)\n",
    "        for item in rated_list:\n",
    "            candidates[rec.data.item[item]] = -10e8\n",
    "\n",
    "        # s_find_k_largest = time.time()\n",
    "        ids, scores = find_k_largest(rec.max_N, candidates)\n",
    "        # e_find_k_largest = time.time()\n",
    "        # print(\"Find k largest candidates: %f s\" % (e_find_k_largest - s_find_k_largest))\n",
    "        item_names = [rec.data.id2item[iid] for iid in ids]\n",
    "        rec_list[user] = list(zip(item_names, scores))\n",
    "        if i % 1000 == 0:\n",
    "            process_bar(i, user_count)\n",
    "    process_bar(user_count, user_count)\n",
    "    print('')\n",
    "    rec.evaluate(rec_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d97fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a92d19f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = 'HGNN'\n",
    "if model not in ['HGNN', 'LightGCN']:\n",
    "    print(\"No model found.\")\n",
    "config = ModelConf('./conf/' + model + '.conf')\n",
    "\n",
    "dataset = ['lastfm']\n",
    "batchSize = 2048\n",
    "maxEpoch = 1000\n",
    "lRates = [0.01]\n",
    "lrDecays = [0.7]\n",
    "regs = [0.1]\n",
    "hyperDims = [128]\n",
    "inputDims = [32]\n",
    "ps = [0.1, 0.2, 0.3, 0.4]\n",
    "dropRates = [0.1, 0.2, 0.3, 0.4]\n",
    "nLayers = [2]\n",
    "nHeads = [2]\n",
    "nSelfAtt = [1]\n",
    "clRate = [0.01]\n",
    "augType = [1]\n",
    "temp = [0.3]\n",
    "w_decays= [0]\n",
    "optimizers = ['adamw']\n",
    "attention_modes = ['node']\n",
    "concats = [ False ]\n",
    "use_norms = [True]\n",
    "use_skip_connections = [True]\n",
    "use_drop_edges = [True]\n",
    "hyperparameters = [dataset, lRates, lrDecays, regs, hyperDims, inputDims, ps, dropRates, nLayers, nHeads, nSelfAtt, clRate, augType, temp, w_decays, optimizers, attention_modes, concats, use_norms, use_skip_connections, use_drop_edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "137ce797-824b-473a-9373-b477c550d524",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lastfm', 0.01, 0.7, 0.1, 128, 32, 0.1, 0.1, 2, 2, 1, 0.01, 1, 0.3, 0, 'adamw', 'node', False, True, True, True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 2.733875 s\n",
      "Measure time: 0.014916 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 1, Hit Ratio:0.05189  |  Precision:0.03195  |  Recall:0.05129  |  NDCG:0.04939\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 1, Hit Ratio:0.05189  |  Precision:0.03195  |  Recall:0.05129  |  NDCG:0.04939\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.174438 s\n",
      "Measure time: 0.014468 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 2, Hit Ratio:0.06365  |  Precision:0.0392  |  Recall:0.06415  |  NDCG:0.06158\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 2, Hit Ratio:0.06365  |  Precision:0.0392  |  Recall:0.06415  |  NDCG:0.06158\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.169880 s\n",
      "Measure time: 0.015127 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 3, Hit Ratio:0.0721  |  Precision:0.0444  |  Recall:0.07106  |  NDCG:0.06827\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 3, Hit Ratio:0.0721  |  Precision:0.0444  |  Recall:0.07106  |  NDCG:0.06827\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.172095 s\n",
      "Measure time: 0.015390 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 4, Hit Ratio:0.07623  |  Precision:0.04695  |  Recall:0.07605  |  NDCG:0.06699\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 4, Hit Ratio:0.07623  |  Precision:0.04695  |  Recall:0.07605  |  NDCG:0.06699\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.171672 s\n",
      "Measure time: 0.015063 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 5, Hit Ratio:0.08197  |  Precision:0.05048  |  Recall:0.08259  |  NDCG:0.07601\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 5, Hit Ratio:0.08197  |  Precision:0.05048  |  Recall:0.08259  |  NDCG:0.07601\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.172817 s\n",
      "Measure time: 0.015491 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 6, Hit Ratio:0.08524  |  Precision:0.05249  |  Recall:0.08413  |  NDCG:0.09022\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 6, Hit Ratio:0.08524  |  Precision:0.05249  |  Recall:0.08413  |  NDCG:0.09022\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.173943 s\n",
      "Measure time: 0.015376 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 7, Hit Ratio:0.09339  |  Precision:0.05751  |  Recall:0.093  |  NDCG:0.0952\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 7, Hit Ratio:0.09339  |  Precision:0.05751  |  Recall:0.093  |  NDCG:0.0952\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.174469 s\n",
      "Measure time: 0.015101 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 8, Hit Ratio:0.08589  |  Precision:0.05289  |  Recall:0.08612  |  NDCG:0.09434\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 7, Hit Ratio:0.09339  |  Precision:0.05751  |  Recall:0.093  |  NDCG:0.0952\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.175157 s\n",
      "Measure time: 0.015868 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 9, Hit Ratio:0.0952  |  Precision:0.05863  |  Recall:0.09548  |  NDCG:0.09725\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 9, Hit Ratio:0.0952  |  Precision:0.05863  |  Recall:0.09548  |  NDCG:0.09725\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Evaluating the model...\n",
      "Progress: [++++++++++++++++++++++++++++++++++++++++++++++++++]100%\n",
      "Test time: 0.175581 s\n",
      "Measure time: 0.015724 s\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Real-Time Ranking Performance  (Top-20 Item Recommendation)\n",
      "*Current Performance*\n",
      "Epoch: 10, Hit Ratio:0.09649  |  Precision:0.05942  |  Recall:0.09645  |  NDCG:0.10466\n",
      "*Best Performance* \n",
      "Epoch:fast_evaluation 10, Hit Ratio:0.09649  |  Precision:0.05942  |  Recall:0.09645  |  NDCG:0.10466\n",
      "------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 45\u001b[0m\n\u001b[1;32m     41\u001b[0m     optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(\n\u001b[1;32m     42\u001b[0m             train_model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr, momentum\u001b[39m=\u001b[39m\u001b[39m0.9\u001b[39m, weight_decay\u001b[39m=\u001b[39mw_decay, nesterov\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m     43\u001b[0m         )\n\u001b[1;32m     44\u001b[0m scheduler \u001b[39m=\u001b[39m ReduceLROnPlateau(optimizer, \u001b[39m'\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39mlr_decay, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m user_emb, item_emb \u001b[39m=\u001b[39m train(train_model, rec\u001b[39m.\u001b[39;49mdata)\n\u001b[1;32m     46\u001b[0m test(rec, user_emb, item_emb)\n",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_model, data)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39m# cl_losses.append(cl_loss.item())\u001b[39;00m\n\u001b[1;32m     36\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 37\u001b[0m batch_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     38\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(train_model\u001b[39m.\u001b[39mparameters(), \u001b[39m4\u001b[39m)\n\u001b[1;32m     39\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/hungvv/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/hungvv/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for params in product(*hyperparameters):\n",
    "    dataset, lr, lr_decay, reg, hyper_dim, input_dim, prob, drop_rate, n_layers, n_heads, n_self_att, cl_rate, aug_type, temp, w_decay, opt, attention_mode, concat, use_norm, use_skip_connection, use_drop_edge= params\n",
    "    print(params)\n",
    "    args = {\n",
    "        'lr': lr,\n",
    "        'lr_decay': lr_decay,\n",
    "        'reg': reg,\n",
    "        'hyper_dim': hyper_dim,\n",
    "        'input_dim': input_dim,\n",
    "        'p': prob,\n",
    "        'drop_rate': drop_rate,\n",
    "        'n_layers': n_layers,\n",
    "        'input_dim': input_dim,\n",
    "        'hyper_dim': hyper_dim,\n",
    "        'n_heads': n_heads,\n",
    "        'n_self_att': n_self_att,\n",
    "        'dataset': dataset,\n",
    "        'cl_rate': cl_rate,\n",
    "        'aug_type': aug_type,\n",
    "        'temp': temp,\n",
    "        'weight_decay': w_decay,\n",
    "        'optimizer': opt,\n",
    "        'attention_mode': attention_mode,\n",
    "        'concat': concat,\n",
    "        'use_norm': use_norm,\n",
    "        'use_skip_connection': use_skip_connection,\n",
    "        'use_drop_edge': use_drop_edge\n",
    "    }\n",
    "    training_data = FileIO.load_data_set('./dataset/' + dataset + '/' +config['training.set'], config['model.type'])\n",
    "    test_data = FileIO.load_data_set('./dataset/' + dataset + '/'  +config['test.set'], config['model.type'])\n",
    "    knowledge_set = FileIO.load_kg_data('./dataset/' + dataset +'/'+ dataset +'.kg')\n",
    "    data = Interaction(config, training_data, test_data)\n",
    "\n",
    "    rec = GraphRecommender(config, data, data, knowledge_set, **args)\n",
    "    train_model = Model(rec.config, rec.data, args).to(device)\n",
    "    if opt == 'adam':\n",
    "        optimizer  = torch.optim.Adam(train_model.parameters(), lr=lr)\n",
    "    elif opt =='adamw': \n",
    "        optimizer  = torch.optim.AdamW(train_model.parameters(), lr=lr)\n",
    "    elif opt == 'sgd':\n",
    "        optimizer = torch.optim.SGD(\n",
    "                train_model.parameters(), lr=lr, momentum=0.9, weight_decay=w_decay, nesterov=True\n",
    "            )\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', factor=lr_decay, patience=10)\n",
    "    user_emb, item_emb = train(train_model, rec.data)\n",
    "    test(rec, user_emb, item_emb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hungvv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
