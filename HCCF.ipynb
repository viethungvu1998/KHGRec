{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f75a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jun/anaconda3/envs/hungvv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.init import xavier_normal_, xavier_uniform_\n",
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "from os.path import abspath\n",
    "\n",
    "from base.graph_recommender import GraphRecommender\n",
    "from util.sampler import next_batch_pairwise_kg, next_batch_pairwise\n",
    "from util.conf import OptionConf\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from scipy.sparse import coo_matrix\n",
    "from util.loss_torch import bpr_loss, l2_reg_loss, EmbLoss, contrastLoss\n",
    "from util.init import *\n",
    "from base.torch_interface import TorchGraphInterface\n",
    "import os\n",
    "import numpy as np \n",
    "import time \n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from data.loader import FileIO\n",
    "from util.conf import ModelConf\n",
    "from base.recommender import Recommender\n",
    "from data.ui_graph import Interaction\n",
    "# from data.knowledge import Knowledge\n",
    "from util.algorithm import find_k_largest\n",
    "from time import strftime, localtime\n",
    "from data.loader import FileIO\n",
    "from util.evaluation import ranking_evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4591bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1561df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerProduct(usrEmbeds, itmEmbeds):\n",
    "\treturn torch.sum(usrEmbeds * itmEmbeds, dim=-1)\n",
    "\n",
    "def pairPredict(ancEmbeds, posEmbeds, negEmbeds):\n",
    "\treturn innerProduct(ancEmbeds, posEmbeds) - innerProduct(ancEmbeds, negEmbeds)\n",
    "\n",
    "def calcRegLoss(model):\n",
    "\tret = 0\n",
    "\tfor W in model.parameters():\n",
    "\t\tret += W.norm(2).square()\n",
    "\t# ret += (model.usrStruct + model.itmStruct)\n",
    "\treturn ret\n",
    "\n",
    "def contrastLoss(embeds1, embeds2, nodes, temp):\n",
    "\tembeds1 = F.normalize(embeds1 + 1e-8, p=2)\n",
    "\tembeds2 = F.normalize(embeds2 + 1e-8, p=2)\n",
    "\tpckEmbeds1 = embeds1[nodes]\n",
    "\tpckEmbeds2 = embeds2[nodes]\n",
    "\tnume = torch.exp(torch.sum(pckEmbeds1 * pckEmbeds2, dim=-1) / temp)\n",
    "\tdeno = torch.exp(pckEmbeds1 @ pckEmbeds2.T / temp).sum(-1) + 1e-8\n",
    "\treturn -torch.log(nume / deno).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2896c836",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphRecommender(Recommender):\n",
    "    def __init__(self, conf, training_set, test_set, **kwargs):\n",
    "        super(GraphRecommender, self).__init__(conf, training_set, test_set, **kwargs)\n",
    "        self.data = Interaction(conf, training_set, test_set)\n",
    "        self.bestPerformance = []\n",
    "        top = self.ranking['-topN'].split(',')\n",
    "        self.topN = [int(num) for num in top]\n",
    "        self.max_N = max(self.topN)\n",
    "\n",
    "    def print_model_info(self):\n",
    "        super(GraphRecommender, self).print_model_info()\n",
    "        # # print dataset statistics\n",
    "        print('Training Set Size: (user number: %d, item number %d, interaction number: %d)' % (self.data.training_size()))\n",
    "        print('Test Set Size: (user number: %d, item number %d, interaction number: %d)' % (self.data.test_size()))\n",
    "        print('=' * 80)\n",
    "\n",
    "    def build(self):\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self, u):\n",
    "        pass\n",
    "\n",
    "    def test(self, user_emb, item_emb):\n",
    "        def process_bar(num, total):\n",
    "            rate = float(num) / total\n",
    "            ratenum = int(50 * rate)\n",
    "            r = '\\rProgress: [{}{}]{}%'.format('+' * ratenum, ' ' * (50 - ratenum), ratenum*2)\n",
    "            sys.stdout.write(r)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # predict\n",
    "        rec_list = {}\n",
    "        user_count = len(self.data.test_set)\n",
    "        for i, user in enumerate(self.data.test_set):\n",
    "            # s_find_candidates = time.time()\n",
    "            \n",
    "            \n",
    "            # candidates = predict(user)\n",
    "            user_id  = self.data.get_user_id(user)\n",
    "            score = torch.matmul(user_emb[user_id], item_emb.transpose(0, 1))\n",
    "            candidates = score.cpu().numpy()\n",
    "            \n",
    "            # e_find_candidates = time.time()\n",
    "            # print(\"Calculate candidates time: %f s\" % (e_find_candidates - s_find_candidates))\n",
    "            # predictedItems = denormalize(predictedItems, self.data.rScale[-1], self.data.rScale[0])\n",
    "            rated_list, li = self.data.user_rated(user)\n",
    "            for item in rated_list:\n",
    "                candidates[self.data.item[item]] = -10e8\n",
    "            \n",
    "            # s_find_k_largest = time.time()\n",
    "            ids, scores = find_k_largest(self.max_N, candidates)\n",
    "            # e_find_k_largest = time.time()\n",
    "            # print(\"Find k largest candidates: %f s\" % (e_find_k_largest - s_find_k_largest))\n",
    "            item_names = [self.data.id2item[iid] for iid in ids]\n",
    "            rec_list[user] = list(zip(item_names, scores))\n",
    "            if i % 1000 == 0:\n",
    "                process_bar(i, user_count)\n",
    "        process_bar(user_count, user_count)\n",
    "        print('')\n",
    "        return rec_list\n",
    "\n",
    "    def evaluate(self, rec_list):\n",
    "        self.recOutput.append('userId: recommendations in (itemId, ranking score) pairs, * means the item is hit.\\n')\n",
    "        for user in self.data.test_set:\n",
    "            line = str(user) + ':'\n",
    "            for item in rec_list[user]:\n",
    "                line += ' (' + str(item[0]) + ',' + str(item[1]) + ')'\n",
    "                if item[0] in self.data.test_set[user]:\n",
    "                    line += '*'\n",
    "            line += '\\n'\n",
    "            self.recOutput.append(line)\n",
    "        current_time = strftime(\"%Y-%m-%d %H-%M-%S\", localtime(time.time()))\n",
    "        # output prediction result\n",
    "        out_dir = self.output['-dir']\n",
    "        file_name = self.config['model.name'] + '@' + current_time + '-top-' + str(self.max_N) + 'items' + '.txt'\n",
    "        FileIO.write_file(out_dir, file_name, self.recOutput)\n",
    "        print('The result has been output to ', abspath(out_dir), '.')\n",
    "        file_name = self.config['model.name'] + '@' + current_time + '-performance' + '.txt'\n",
    "        self.result = ranking_evaluation(self.data.test_set, rec_list, self.topN)\n",
    "        self.model_log.add('###Evaluation Results###')\n",
    "        self.model_log.add(self.result)\n",
    "        FileIO.write_file(out_dir, file_name, self.result)\n",
    "        print('The result of %s:\\n%s' % (self.model_name, ''.join(self.result)))\n",
    "\n",
    "    def fast_evaluation(self, epoch, user_embed, item_embed, kwargs=None):\n",
    "        print('Evaluating the model...')\n",
    "        s_test = time.time()\n",
    "        rec_list = self.test(user_embed, item_embed)\n",
    "        e_test = time.time() \n",
    "        print(\"Test time: %f s\" % (e_test - s_test))\n",
    "        \n",
    "        s_measure = time.time()\n",
    "        measure = ranking_evaluation(self.data.test_set, rec_list, [self.max_N])\n",
    "        e_measure = time.time()\n",
    "        print(\"Measure time: %f s\" % (e_measure - s_measure))\n",
    "        \n",
    "        if len(self.bestPerformance) > 0:\n",
    "            count = 0\n",
    "            performance = {}\n",
    "            for m in measure[1:]:\n",
    "                k, v = m.strip().split(':')\n",
    "                performance[k] = float(v)\n",
    "            for k in self.bestPerformance[1]:\n",
    "                if self.bestPerformance[1][k] > performance[k]:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    count -= 1\n",
    "            if count < 0:\n",
    "                self.bestPerformance[1] = performance\n",
    "                self.bestPerformance[0] = epoch + 1\n",
    "                try:\n",
    "                    self.save(kwargs)\n",
    "                except:\n",
    "                    self.save()\n",
    "        else:\n",
    "            self.bestPerformance.append(epoch + 1)\n",
    "            performance = {}\n",
    "            for m in measure[1:]:\n",
    "                k, v = m.strip().split(':')\n",
    "                performance[k] = float(v)\n",
    "            self.bestPerformance.append(performance)\n",
    "            try:\n",
    "                self.save(kwargs)\n",
    "            except:\n",
    "                self.save()\n",
    "        print('-' * 120)\n",
    "        print('Real-Time Ranking Performance ' + ' (Top-' + str(self.max_N) + ' Item Recommendation)')\n",
    "        measure = [m.strip() for m in measure[1:]]\n",
    "        print('*Current Performance*')\n",
    "        print('Epoch:', str(epoch + 1) + ',', '  |  '.join(measure))\n",
    "        bp = ''\n",
    "        # for k in self.bestPerformance[1]:\n",
    "        #     bp+=k+':'+str(self.bestPerformance[1][k])+' | '\n",
    "        bp += 'Hit Ratio' + ':' + str(self.bestPerformance[1]['Hit Ratio']) + '  |  '\n",
    "        bp += 'Precision' + ':' + str(self.bestPerformance[1]['Precision']) + '  |  '\n",
    "        bp += 'Recall' + ':' + str(self.bestPerformance[1]['Recall']) + '  |  '\n",
    "        # bp += 'F1' + ':' + str(self.bestPerformance[1]['F1']) + ' | '\n",
    "        bp += 'NDCG' + ':' + str(self.bestPerformance[1]['NDCG'])\n",
    "        print('*Best Performance* ')\n",
    "        print('Epoch:fast_evaluation', str(self.bestPerformance[0]) + ',', bp)\n",
    "        print('-' * 120)\n",
    "        return measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df785a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HCCFModel(nn.Module):\n",
    "    def __init__(self, config, data):\n",
    "        super(HCCFModel, self).__init__()\n",
    "        self.data = data\n",
    "        self._parse_args(config)\n",
    "\n",
    "        init = nn.init.xavier_uniform_\n",
    "        adj = self.data.bi_interaction_mat\n",
    "        self.adj  = TorchGraphInterface.convert_sparse_mat_to_tensor(adj).to(device) \n",
    "        \n",
    "        # init embedding\n",
    "        self.user_embedding = nn.Parameter(init(torch.zeros(self.data.user_num, self.input_dim)))\n",
    "        self.item_embedding = nn.Parameter(init(torch.zeros(self.data.item_num, self.input_dim)))\n",
    "\n",
    "        self.uHyper = nn.Parameter(init(torch.zeros(self.input_dim, self.hyper_dim)))\n",
    "        self.iHyper = nn.Parameter(init(torch.zeros(self.input_dim, self.hyper_dim)))\n",
    "\n",
    "        self.edgeDropper = SpAdjDropEdge()\n",
    "        self.gcnLayer = GCNLayer(self.leaky)\n",
    "        self.hgnnLayer = HGNNLayer(self.leaky, self.hyper_dim)\n",
    "        \n",
    "    def _parse_args(self, config):\n",
    "        self.gnn_layer = int(config['gnn_layer'])\n",
    "        self.input_dim = int(config['embedding.size'])\n",
    "        self.hyper_dim = int(config['hyper.size'])\n",
    "        self.drop_rate = float(config['dropout'])\n",
    "        self.leaky = float(config['leaky'])\n",
    "        self.temp = float(config['temp'])\n",
    "\n",
    "    def calculate_loss(self, ancs, poss, negs, keep_rate):\n",
    "        uEmbeds, iEmbeds, gcnEmbedsLst, hyperEmbedsLst = self.forward(keep_rate)\n",
    "\n",
    "        ancEmbeds = uEmbeds[ancs]\n",
    "        posEmbeds = iEmbeds[poss]\n",
    "        negEmbeds = iEmbeds[negs]\n",
    "        scoreDiff = pairPredict(ancEmbeds, posEmbeds, negEmbeds)\n",
    "        bprLoss = - (scoreDiff).sigmoid().log().mean()\n",
    "\n",
    "        sslLoss = 0\n",
    "        for i in range(self.gnn_layer):\n",
    "            embeds1 = gcnEmbedsLst[i].detach()\n",
    "            embeds2 = hyperEmbedsLst[i]\n",
    "            sslLoss += contrastLoss(embeds1[:self.data.user_num], embeds2[:self.data.user_num], torch.unique(ancs), self.temp) + contrastLoss(embeds1[self.data.user_num:], embeds2[self.data.user_num:], torch.unique(poss), self.temp)\n",
    "        return bprLoss, sslLoss\n",
    "\n",
    "        \n",
    "    def forward(self, keep_rate):\n",
    "        uEmbed = self.user_embedding   \n",
    "        iEmbed = self.item_embedding      \n",
    "        \n",
    "        # print(\"uEmbed: \")\n",
    "        # print(uEmbed)  \n",
    "        embeds = torch.cat((uEmbed, iEmbed), dim=0)\n",
    "        lats = [embeds]\n",
    "        gnnLats = []\n",
    "        hyperLats = []\n",
    "        uuHyper = uEmbed @ self.uHyper\n",
    "        iiHyper = iEmbed @ self.iHyper\n",
    "\n",
    "        for i in range(self.gnn_layer):\n",
    "            dropped_edge = self.edgeDropper(self.adj, keep_rate)\n",
    "            temEmbeds = self.gcnLayer(dropped_edge.to_dense(), lats[-1])\n",
    "            # if torch.any(torch.isnan(lats[-1])):\n",
    "            #     import pdb; pdb.set_trace()\n",
    "            hyperULat = self.hgnnLayer(F.dropout(uuHyper, p=1-keep_rate), lats[-1][:self.data.user_num])\n",
    "            hyperILat = self.hgnnLayer(F.dropout(iiHyper, p=1-keep_rate), lats[-1][self.data.user_num:])\n",
    "            gnnLats.append(temEmbeds)\n",
    "            hyperLats.append(torch.cat([hyperULat, hyperILat], dim=0))\n",
    "            lats.append(temEmbeds + hyperLats[-1])\n",
    "        embeds = sum(lats)\n",
    "        user_embed =  embeds[:self.data.user_num]\n",
    "        item_embed = embeds[self.data.user_num:]\n",
    "        # print(user_embed)\n",
    "        # print(item_embed)\n",
    "        return user_embed, item_embed, gnnLats, hyperLats\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "\tdef __init__(self, leaky):\n",
    "\t\tsuper(GCNLayer, self).__init__()\n",
    "\t\tself.act = nn.LeakyReLU(negative_slope=leaky)\n",
    "\n",
    "\tdef forward(self, adj, embeds):\n",
    "\t\treturn self.act(torch.spmm(adj, embeds))\n",
    "\n",
    "class HGNNLayer(nn.Module):\n",
    "    def __init__(self, leaky,  hyper_dim):\n",
    "        super(HGNNLayer, self).__init__()\n",
    "        self.hyper_dim = hyper_dim\n",
    "        self.act = nn.LeakyReLU(negative_slope=leaky)\n",
    "        self.fc1 = nn.Linear(hyper_dim, hyper_dim ,bias=False) \n",
    "        self.fc2 = nn.Linear(hyper_dim, hyper_dim ,bias=False)  \n",
    "        self.fc3 = nn.Linear(hyper_dim, hyper_dim ,bias=False)  \n",
    "\n",
    "    def forward(self, adj, embeds):\n",
    "        \n",
    "        lat1 = self.act(adj.T @ embeds)\n",
    "        lat2 = self.act(self.fc1(lat1.T).T) +  lat1\n",
    "        lat3 = self.act(self.fc2(lat2.T).T) + lat2\n",
    "        lat4 = self.act(self.fc3(lat3.T).T) + lat3 \n",
    "        ret = self.act(adj @ lat4)\n",
    "        return ret\n",
    "\n",
    "class SpAdjDropEdge(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(SpAdjDropEdge, self).__init__()\n",
    "\n",
    "\tdef forward(self, adj, keepRate):\n",
    "\t\tif keepRate == 1.0:\n",
    "\t\t\treturn adj\n",
    "\t\tvals = adj._values()\n",
    "\t\tidxs = adj._indices()\n",
    "\t\tedgeNum = vals.size()\n",
    "\t\tmask = ((torch.rand(edgeNum) + keepRate).floor()).type(torch.bool)\n",
    "\t\tnewVals = vals[mask] / keepRate\n",
    "\t\tnewIdxs = idxs[:, mask]\n",
    "\t\treturn torch.sparse.FloatTensor(newIdxs, newVals, adj.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26444507",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HCCF(GraphRecommender):\n",
    "    def __init__(self, conf, training_set, test_set, **kwargs):\n",
    "        GraphRecommender.__init__(self, conf, training_set, test_set, **kwargs)\n",
    "        # config = OptionConf(self.config['HGNN'])\n",
    "\n",
    "        self.reg_loss = EmbLoss() \n",
    "        self.model = HCCFModel(self.config, self.data )\n",
    "\n",
    "        self._parse_config(self.config)\n",
    "        self.model.to(device)\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lRate)\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, 'min', factor=self.lr_decay,patience=7)\n",
    "\n",
    "    def _parse_config(self, config):\n",
    "        self.lRate = float(config['learnRate'])\n",
    "        self.lr_decay = float(config['learnRateDecay'])\n",
    "        self.maxEpoch = int(config['num.max.epoch'])\n",
    "        self.batchSize = int(config['batch_size'])\n",
    "        self.reg = float(config['reg.lambda'])\n",
    "        self.embeddingSize = int(config['embedding.size'])\n",
    "        self.hyperDim = int(config['hyper.size'])\n",
    "        self.dropRate = float(config['dropout'])\n",
    "        self.negSlove = float(config['leaky'])\n",
    "        self.nLayers = int(config['gnn_layer'])\n",
    "\n",
    "    def train(self):\n",
    "        model = self.model \n",
    "\n",
    "        for ep in range(self.maxEpoch):\n",
    "            for n, batch in enumerate(next_batch_pairwise(self.data, self.batchSize)):\n",
    "                user_idx, pos_idx, neg_idx = batch\n",
    "                model.train()\n",
    "                # s_model = time.time()\n",
    "                rec_user_emb, rec_item_emb, _, _ = model(keep_rate=1- self.dropRate)\n",
    "                bpr_loss, ssl_loss = model.calculate_loss(user_idx, pos_idx, neg_idx, keep_rate= 1-self.dropRate)\n",
    "                batch_loss = bpr_loss + ssl_loss \n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                batch_loss.backward()\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "                self.optimizer.step()\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                self.user_emb, self.item_emb, _, _ = model(keep_rate=1)\n",
    "            \n",
    "            s_eval = time.time()\n",
    "            self.fast_evaluation(ep)\n",
    "            e_eval = time.time()\n",
    "            print(\"Eval time: %f s\" % (e_eval - s_eval))\n",
    "\n",
    "        self.user_emb, self.item_emb = self.best_user_emb, self.best_item_emb\n",
    "\n",
    "    def save(self):\n",
    "        with torch.no_grad():\n",
    "            self.best_user_emb, self.best_item_emb, _,_ = self.model(keep_rate=1)\n",
    "\n",
    "    def predict(self, u):\n",
    "        user_id  = self.data.get_user_id(u)\n",
    "        score = torch.matmul(self.user_emb[user_id], self.item_emb.transpose(0, 1))\n",
    "        return score.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af445cea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m training_data \u001b[38;5;241m=\u001b[39m FileIO\u001b[38;5;241m.\u001b[39mload_data_set(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining.set\u001b[39m\u001b[38;5;124m'\u001b[39m], config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.type\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     18\u001b[0m test_data \u001b[38;5;241m=\u001b[39m FileIO\u001b[38;5;241m.\u001b[39mload_data_set(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.set\u001b[39m\u001b[38;5;124m'\u001b[39m], config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.type\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 20\u001b[0m rec \u001b[38;5;241m=\u001b[39m GraphRecommender(config, training_data, test_data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[43margs\u001b[49m)\n\u001b[1;32m     21\u001b[0m train_model \u001b[38;5;241m=\u001b[39m HCCF(rec\u001b[38;5;241m.\u001b[39mdata, embeddingSize, args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     22\u001b[0m optimizer  \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(train_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlRate)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "model = 'HCCF'\n",
    "config = ModelConf('./conf/' + model + '.conf')\n",
    "\n",
    "lRate = float(config['learnRate'])\n",
    "lr_decay = float(config['learnRateDecay'])\n",
    "maxEpoch = int(config['num.max.epoch'])\n",
    "batchSize = int(config['batch_size'])\n",
    "reg = float(config['reg.lambda'])\n",
    "embeddingSize = int(config['embedding.size'])\n",
    "hyperDim = int(config['hyper.size'])\n",
    "dropRate = float(config['dropout'])\n",
    "negSlove = float(config['leaky'])\n",
    "nLayers = int(config['gnn_layer'])\n",
    "\n",
    "# ss_rate = float(config['ss_rate'])\n",
    "\n",
    "training_data = FileIO.load_data_set(config['training.set'], config['model.type'])\n",
    "test_data = FileIO.load_data_set(config['test.set'], config['model.type'])\n",
    "\n",
    "rec = GraphRecommender(config, training_data, test_data, **args)\n",
    "train_model = HCCF(rec.data, embeddingSize, args['n_layers'])\n",
    "optimizer  = torch.optim.Adam(train_model.parameters(), lr=lRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adfd69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in range(maxEpoch):\n",
    "    for n, batch in enumerate(next_batch_pairwise(rec.data, batchSize)):\n",
    "        user_idx, pos_idx, neg_idx = batch\n",
    "        train_model.train()\n",
    "        # s_model = time.time()\n",
    "        rec_user_emb, rec_item_emb, _, _ = train_model(keep_rate=1- dropRate)\n",
    "        bpr_loss, ssl_loss = train_model.calculate_loss(user_idx, pos_idx, neg_idx, keep_rate= 1- dropRate)\n",
    "        batch_loss = bpr_loss + ssl_loss \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
    "        optimizer.step()\n",
    "    \n",
    "    train_model.eval()\n",
    "    with torch.no_grad():\n",
    "        user_emb, item_emb, _, _ = train_model(keep_rate=1)\n",
    "\n",
    "    s_eval = time.time()\n",
    "    rec.fast_evaluation(ep)\n",
    "    e_eval = time.time()\n",
    "    print(\"Eval time: %f s\" % (e_eval - s_eval))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
